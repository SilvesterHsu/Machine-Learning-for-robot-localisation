{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torch\n",
    "## Check GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-22T01:53:33.354176Z",
     "start_time": "2020-08-22T01:53:31.824209Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "the rosdep view is empty: call 'sudo rosdep init' and 'rosdep update'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Device 1 : TITAN Xp\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from torchlib.utils import list_device,set_device\n",
    "\n",
    "# S1: check GPU\n",
    "#list_device()\n",
    "\n",
    "# S2: default parameters\n",
    "set_device(1)\n",
    "np.set_printoptions(precision = 2)\n",
    "torch.set_default_dtype(torch.float32)\n",
    "torch.set_printoptions(precision=4)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.set_printoptions(sci_mode=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-22T01:53:33.372183Z",
     "start_time": "2020-08-22T01:53:33.355779Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "'''Training Parameters'''\n",
    "parser.add_argument('--batch_size', type=int, default=60, help='minibatch size')\n",
    "parser.add_argument('--num_epochs', type=int, default=200, help='number of epochs')\n",
    "parser.add_argument('--grad_clip', type=float, default=5., help='clip gradients at this value')\n",
    "parser.add_argument('--learning_rate', type=float, default=0.00004, help='learning rate')\n",
    "parser.add_argument('--learning_rate_clip', type=float, default=0.0000001, help='learning rate clip')\n",
    "parser.add_argument('--decay_rate', type=float, default=.98, help='decay rate for rmsprop')\n",
    "parser.add_argument('--weight_decay', type=float, default=.0001, help='decay rate for rmsprop')\n",
    "parser.add_argument('--batch_norm_decay', type=float, default=.999, help='decay rate for rmsprop')\n",
    "parser.add_argument('--keep_prob', type=float, default=1.0, help='dropout keep probability')\n",
    "parser.add_argument('--lamda_weights', type=float, default=0.01, help='weight of rotation error')\n",
    "parser.add_argument('--data_argumentation', type=bool, default=True, help='whether do data argument')\n",
    "parser.add_argument('--is_normalization', type=bool, default=True, help='whether do data normalization')\n",
    "parser.add_argument('--target_image_size', default=[300, 300], nargs=2, type=int, help='Input images will be resized to this for data argumentation.')\n",
    "\n",
    "'''Configure'''\n",
    "parser.add_argument('--network', type=str, default='vggnet_localization')\n",
    "parser.add_argument('--model_dir', type=str, default='/notebooks/global_localization/dual_resnet_torch', help='rnn, gru, or lstm')\n",
    "\n",
    "\n",
    "parser.add_argument('--train_dataset', type=str, default = ['/notebooks/michigan_nn_data/2012_01_08',\n",
    "                                                            '/notebooks/michigan_nn_data/2012_01_15',\n",
    "                                                            '/notebooks/michigan_nn_data/2012_01_22',\n",
    "                                                            '/notebooks/michigan_nn_data/2012_02_02',\n",
    "                                                            '/notebooks/michigan_nn_data/2012_02_04',\n",
    "                                                            '/notebooks/michigan_nn_data/2012_02_05',\n",
    "                                                            '/notebooks/michigan_nn_data/2012_03_31',\n",
    "                                                            '/notebooks/michigan_nn_data/2012_09_28'])\n",
    "'''\n",
    "#parser.add_argument('--train_dataset', type=str, default = ['/notebooks/michigan_nn_data/test'])\n",
    "parser.add_argument('--train_dataset', type=str, default = ['/notebooks/michigan_nn_data/2012_01_08'])\n",
    "'''\n",
    "parser.add_argument('--norm_tensor', type=str, default = ['/notebooks/global_localization/norm_mean_std.pt'])\n",
    "\n",
    "parser.add_argument('--seed', default=1337, type=int)\n",
    "parser.add_argument('--save_every', type=int, default=3000, help='save frequency')\n",
    "parser.add_argument('--display', type=int, default=20, help='display frequency')\n",
    "parser.add_argument('--tensorboard', type=bool, default=True, help='open tensorboard')\n",
    "parser.add_argument('--cuda_device', type=int, default=1, help='cuda device')\n",
    "\n",
    "sys.argv = ['']\n",
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-22T01:56:48.820996Z",
     "start_time": "2020-08-22T01:53:33.376330Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16446/16446 [00:23<00:00, 695.32it/s]\n",
      "100%|██████████| 22584/22584 [00:32<00:00, 685.79it/s]\n",
      "100%|██████████| 18655/18655 [00:26<00:00, 706.54it/s]\n",
      "100%|██████████| 17310/17310 [00:24<00:00, 706.22it/s]\n",
      "100%|██████████| 10766/10766 [00:15<00:00, 702.89it/s]\n",
      "100%|██████████| 14878/14878 [00:23<00:00, 639.28it/s]\n",
      "100%|██████████| 13452/13452 [00:21<00:00, 624.79it/s]\n",
      "100%|██████████| 14037/14037 [00:27<00:00, 515.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load norm and std: /notebooks/global_localization/norm_mean_std.pt\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import tf.transformations as tf_tran\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchlib import resnet, vggnet, cnn_auxiliary\n",
    "from torchlib.cnn_auxiliary import normalize, denormalize, get_relative_pose, translational_rotational_loss\n",
    "from torchlib.utils import LocalizationDataset, display_loss, data2tensorboard\n",
    "import time\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "dataset = LocalizationDataset(dataset_dirs = args.train_dataset, \\\n",
    "                              image_size = args.target_image_size, \\\n",
    "                              transform = transform, get_pair = True)\n",
    "\n",
    "[args.norm_mean, args.norm_std] = torch.load(*args.norm_tensor)\n",
    "print('Load norm and std:',*args.norm_tensor)\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=args.batch_size, \\\n",
    "                        shuffle=True, num_workers=0, \\\n",
    "                        drop_last=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-22T01:56:49.712506Z",
     "start_time": "2020-08-22T01:56:48.848905Z"
    },
    "code_folding": [
     3,
     20,
     21,
     36,
     67
    ],
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torchlib.GPs import Backbone, NN, BaseModule\n",
    "        \n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.backbone = Backbone()\n",
    "        self.nn = NN()\n",
    "        \n",
    "    def forward(self, *args):\n",
    "        outputs = []\n",
    "        for input_data in args:\n",
    "            dense_feat = self.backbone(input_data)\n",
    "            output, feature_t, feature_r = self.nn(dense_feat)\n",
    "            outputs += [output]\n",
    "        if len(args)>1:\n",
    "            return outputs\n",
    "        else:\n",
    "            return output, feature_t, feature_r\n",
    "        \n",
    "class PosePredictor(BaseModule):\n",
    "    def __init__(self, norm_mean, norm_std, args, is_training=True, mixed_precision=True):\n",
    "        super().__init__(norm_mean, norm_std, args)\n",
    "        self.model = Model().to(self.device)\n",
    "        self.mixed_precision = mixed_precision\n",
    "        if self.mixed_precision:\n",
    "            self.scaler = GradScaler()\n",
    "        if is_training:\n",
    "            self.optimizer = optim.Adam(self.model.parameters(), \n",
    "                                        lr=args.learning_rate, \n",
    "                                        weight_decay=args.weight_decay)\n",
    "            self.scheduler = optim.lr_scheduler.LambdaLR(optimizer=self.optimizer,\n",
    "                                                             lr_lambda=lambda epoch: args.decay_rate**epoch)\n",
    "        else:\n",
    "            self.disable_requires_grad(self.model)\n",
    "    \n",
    "    def train(self,x0, x1, y0, y1):\n",
    "        # Step 0: zero grad\n",
    "        self.optimizer.zero_grad()\n",
    "        \n",
    "        start = time.time()\n",
    "        # Step 1: get data\n",
    "        x0,x1,y0,y1 = x0.to(self.device),x1.to(self.device),y0.to(self.device),y1.to(self.device)\n",
    "        if args.is_normalization:\n",
    "            y0, y1 = [normalize(y,self.norm_mean, self.norm_std) for y in [y0,y1]]\n",
    "            \n",
    "        # Step 2: training\n",
    "        assert trainer.model.training == True\n",
    "        \n",
    "        if self.mixed_precision:\n",
    "            with autocast():\n",
    "                global_loss, consistent_loss = self._loss(x0, x1, y0, y1)\n",
    "                single_loss = global_loss + consistent_loss\n",
    "                \n",
    "            self.scaler.scale(single_loss).backward()\n",
    "            self.scaler.step(self.optimizer)\n",
    "            self.scaler.update()\n",
    "        else:\n",
    "            global_loss, consistent_loss = self._loss(x0, x1, y0, y1)\n",
    "            single_loss = global_loss + consistent_loss\n",
    "            \n",
    "            single_loss.backward()\n",
    "            self.optimizer.step()\n",
    "        batch_time = time.time() - start\n",
    "        \n",
    "        return float(single_loss), float(global_loss), float(consistent_loss), batch_time\n",
    "    \n",
    "    def _loss(self,x0, x1, y0, y1):\n",
    "        # target relative\n",
    "        relative_target_normed = get_relative_pose(y0, y1)\n",
    "        # forward output\n",
    "        global_output0,global_output1 = self.model(x0, x1)\n",
    "        # output relative\n",
    "        relative_consistence = get_relative_pose(global_output0,global_output1)\n",
    "        \n",
    "        # target loss\n",
    "        global_loss = translational_rotational_loss(pred=global_output1, gt=y1, \\\n",
    "                                                    lamda=args.lamda_weights)\n",
    "        # relative loss\n",
    "        geometry_consistent_loss = translational_rotational_loss(pred=relative_consistence, \\\n",
    "                                                                 gt=relative_target_normed, \\\n",
    "                                                                 lamda=args.lamda_weights)        \n",
    "        \n",
    "        return global_loss, geometry_consistent_loss\n",
    "    \n",
    "    def eval_forward(self,x,y,output_denormalize = True):\n",
    "        # Step 1: get data\n",
    "        x,y = x.to(self.device),y.to(self.device)\n",
    "        \n",
    "        # Step 2: forward\n",
    "        assert trainer.model.training == False\n",
    "        \n",
    "        if self.mixed_precision:\n",
    "            with autocast():\n",
    "                output,_,_ = self.model(x)\n",
    "            self.scaler.scale(output)\n",
    "        else:\n",
    "            output,_,_ = self.model(x)\n",
    "\n",
    "        if args.is_normalization and output_denormalize:\n",
    "            output = denormalize(output, self.norm_mean, self.norm_std)\n",
    "            \n",
    "        # Step 3: split output\n",
    "        trans_target, rot_target = torch.split(y, [3, 4], dim=1)\n",
    "        trans_prediction, rot_prediction = torch.split(output, [3, 4], dim=1)\n",
    "        return trans_prediction, rot_prediction, trans_target, rot_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-22T01:56:57.459286Z",
     "start_time": "2020-08-22T01:56:49.714071Z"
    },
    "code_folding": [
     1
    ],
    "run_control": {
     "marked": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded model to TITAN Xp.\n"
     ]
    }
   ],
   "source": [
    "trainer = PosePredictor(args.norm_mean,args.norm_std,args,mixed_precision=True)\n",
    "'''\n",
    "state_dict = torch.load(os.path.join(trainer.args.model_dir, 'pretrained.pth'))\n",
    "for key in list(state_dict):\n",
    "    if 'resnet' not in key:\n",
    "        state_dict.pop(key)\n",
    "trainer.model.backbone.load_state_dict(state_dict)\n",
    "\n",
    "state_dict = torch.load(os.path.join(trainer.args.model_dir, 'pretrained.pth'))\n",
    "for key in list(state_dict):\n",
    "    if 'resnet' in key:\n",
    "        state_dict.pop(key)\n",
    "trainer.model.nn.load_state_dict(state_dict)\n",
    "'''\n",
    "#trainer.load_model('pretrained_re.pth')\n",
    "trainer.load_model('model-4-9000.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-22T01:56:58.058306Z",
     "start_time": "2020-08-22T01:56:57.465104Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "if args.tensorboard:\n",
    "    import os\n",
    "    os.system('rm -rf runs/nn')\n",
    "    from torch.utils.tensorboard import SummaryWriter\n",
    "    writer = SummaryWriter('runs/nn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-22T01:52:57.055940Z",
     "start_time": "2020-08-21T22:41:32.518243Z"
    },
    "code_folding": [],
    "run_control": {
     "marked": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2135/2135 [40:34<00:00,  1.14s/it, ave=0.00493, loss=0.00266, lr=2.99e-5]\n",
      " 41%|████      | 865/2135 [16:16<32:36,  1.54s/it, ave=0.00339, loss=0.00322, lr=2.44e-5]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model to model-1-3000.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2135/2135 [40:08<00:00,  1.13s/it, ave=0.00305, loss=0.0022, lr=1.7e-5]  \n",
      " 81%|████████  | 1730/2135 [32:30<10:13,  1.51s/it, ave=-inf, loss=0.00228, lr=1.13e-5]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model to model-2-6000.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2135/2135 [40:06<00:00,  1.13s/it, ave=-inf, loss=0.00195, lr=9.69e-6]\n",
      "100%|██████████| 2135/2135 [40:03<00:00,  1.13s/it, ave=0.00234, loss=0.00221, lr=5.8e-6] \n",
      " 22%|██▏       | 460/2135 [08:38<43:52,  1.57s/it, ave=0.00198, loss=0.00201, lr=5.23e-6]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model to model-4-9000.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 1623/2135 [30:31<09:37,  1.13s/it, ave=0.00196, loss=0.00211, lr=3.85e-6]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-afa23eb443d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0my0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsistent_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-4ee41e016a5b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, x0, x1, y0, y1)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msingle_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/cuda/amp/grad_scaler.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"No inf checks were recorded for this optimizer.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/cuda/amp/grad_scaler.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"No inf checks were recorded for this optimizer.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.model.train()\n",
    "for e in range(args.num_epochs):\n",
    "    minibatch_iter = tqdm(dataloader)\n",
    "    train_loss = 0.\n",
    "    for b, data in enumerate(minibatch_iter):\n",
    "        x0, x1 = data['image']\n",
    "        y0, y1 = data['target']\n",
    "        \n",
    "        loss, global_loss, consistent_loss, batch_time = trainer.train(x0,x1,y0,y1)\n",
    "        \n",
    "        train_loss += loss\n",
    "        ave_loss = train_loss/(b+1)\n",
    "        step = e*len(dataloader)+(b+1)\n",
    "        # display data\n",
    "        minibatch_iter.set_postfix(ave = ave_loss, loss=loss,lr=trainer.scheduler.get_last_lr()[-1])\n",
    "        # tensorboard\n",
    "        trainer.data2tensorboard(writer,'training loss',{'item loss':loss,'batch loss':ave_loss},step)\n",
    "        trainer.data2tensorboard(writer,'loss',{'global_loss':global_loss,'con_loss':consistent_loss},step)\n",
    "        # save model\n",
    "        trainer.save_model_step(e,step)\n",
    "        # step scheduler\n",
    "        trainer.schedule_step(step,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-22T01:53:09.734317Z",
     "start_time": "2020-08-22T01:53:08.605909Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model to model-4-9000.pth\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model('model-4-9000.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-22T01:57:00.460440Z",
     "start_time": "2020-08-22T01:56:58.062420Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2135 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "trainer.model.eval()\n",
    "for e in range(args.num_epochs):\n",
    "    minibatch_iter = tqdm(dataloader)\n",
    "    train_loss = 0.\n",
    "    for b, data in enumerate(minibatch_iter):\n",
    "        x0, x1 = data['image']\n",
    "        y0, y1 = data['target']\n",
    "        break\n",
    "    break\n",
    "\n",
    "trans_pred, rot_pred, trans_gt, rot_gt = trainer.eval_forward(x1,y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-22T01:57:00.525232Z",
     "start_time": "2020-08-22T01:57:00.464509Z"
    },
    "cell_style": "split"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-227.8852,  298.3793,  -11.5725],\n",
       "        [-265.9245,  294.6809,  -11.5931],\n",
       "        [-158.7016,  289.1761,  -10.8763],\n",
       "        [  81.0451,  335.2351,   -1.8201],\n",
       "        [-221.0486,  680.6127,  -12.7616],\n",
       "        [-228.3527,  294.8529,  -11.4491],\n",
       "        [  49.0243,  319.8821,   -1.8567],\n",
       "        [  79.6427, -114.6460,    3.3934],\n",
       "        [-180.6721,  443.6521,  -12.0779],\n",
       "        [-290.6996,  718.1135,  -14.0764],\n",
       "        [-306.0089,  510.8268,  -12.1899],\n",
       "        [ -78.1238,  509.9667,  -11.0946],\n",
       "        [-230.8068,  722.2421,  -13.3287],\n",
       "        [ -77.8901,  423.5793,   -9.8433],\n",
       "        [-312.3195,  332.5258,  -11.3507],\n",
       "        [-307.6450,  376.9290,  -11.5497],\n",
       "        [-122.0574,  342.4600,   -9.9376],\n",
       "        [-181.1396,  631.2423,  -12.8873],\n",
       "        [ -78.7374,  492.2054,  -10.9643],\n",
       "        [ -45.6356,  547.0375,  -11.5108],\n",
       "        [-313.2544,  498.8712,  -12.1350],\n",
       "        [-181.2564,  547.7255,  -12.5055],\n",
       "        [ -48.2651,  191.5536,   -3.7408],\n",
       "        [  34.6500,  151.8164,   -2.9131],\n",
       "        [  35.2344,  430.9655,   -1.9481],\n",
       "        [   7.5376,  140.2909,   -3.2835],\n",
       "        [  73.6826,  245.4825,   -2.2637],\n",
       "        [-221.3408,  658.9379,  -12.5261],\n",
       "        [-187.1581,  303.1100,  -11.1609],\n",
       "        [-308.2293,  533.8777,  -12.5558],\n",
       "        [-305.5414,  456.6828,  -12.1213],\n",
       "        [-228.7032,  433.7608,  -12.2722],\n",
       "        [-220.1137,  570.7765,  -11.8309],\n",
       "        [   9.7580,  186.9090,   -5.0602],\n",
       "        [-167.6418,  286.0798,  -10.8694],\n",
       "        [  46.8039,  194.9940,   -1.8978],\n",
       "        [-213.7446,  315.0655,  -11.3507],\n",
       "        [-177.6336,  622.2972,  -12.9559],\n",
       "        [-124.3144,  346.4596,   -9.9490],\n",
       "        [  77.6560,  262.0826,   -2.0122],\n",
       "        [ -53.4071,  268.5335,   -7.4715],\n",
       "        [ -45.5187,  455.9517,  -10.6304],\n",
       "        [-175.7638,  291.8425,  -10.9071],\n",
       "        [-245.2395,  702.8036,  -13.6053],\n",
       "        [  37.9222,  140.8070,   -2.8856],\n",
       "        [-175.5301,  296.2291,  -10.8900],\n",
       "        [-191.1899,  417.0962,  -13.0337],\n",
       "        [  86.3040,  -74.7368,    3.1922],\n",
       "        [-240.9155,  707.9642,  -13.5916],\n",
       "        [ -67.9566,  540.9307,  -11.4536],\n",
       "        [-161.8862,  283.2414,  -10.7711],\n",
       "        [-277.0266,  537.8342,  -11.9956],\n",
       "        [-232.3260,  444.2757,  -12.3729],\n",
       "        [-194.2283,  518.8258,  -12.4483],\n",
       "        [-212.4007,  394.9322,  -14.5291],\n",
       "        [  75.4356,  409.0810,   -1.5411],\n",
       "        [  42.4799,  145.6236,   -2.8582],\n",
       "        [ -15.1341,  -58.2227,    0.8873],\n",
       "        [  68.7744,  148.2039,   -2.2591],\n",
       "        [   1.4022,  149.0641,   -3.5213]], device='cuda:1',\n",
       "       grad_fn=<SplitWithSizesBackward>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-22T01:57:00.540414Z",
     "start_time": "2020-08-22T01:57:00.526911Z"
    },
    "cell_style": "split"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  -227.3721,    297.0538,    -11.4755],\n",
       "        [  -264.0753,    293.0129,    -11.6201],\n",
       "        [  -161.6675,    289.3199,    -10.8695],\n",
       "        [    78.0840,    336.1534,     -1.8981],\n",
       "        [  -222.2333,    682.1813,    -12.7351],\n",
       "        [  -224.3706,    290.0993,    -11.2488],\n",
       "        [    41.9049,    321.4871,     -2.0554],\n",
       "        [    77.3525,   -112.4034,      3.3006],\n",
       "        [  -181.4014,    442.3022,    -12.1979],\n",
       "        [  -289.9712,    719.1344,    -14.0224],\n",
       "        [  -305.6146,    502.3324,    -12.1577],\n",
       "        [   -77.8624,    511.5924,    -11.1464],\n",
       "        [  -232.5992,    723.0673,    -13.3120],\n",
       "        [   -77.8685,    422.3000,     -9.8042],\n",
       "        [  -312.3104,    333.0648,    -11.3198],\n",
       "        [  -309.7926,    376.4880,    -11.5557],\n",
       "        [  -124.5346,    346.8696,    -10.0322],\n",
       "        [  -181.2222,    628.6738,    -12.9665],\n",
       "        [   -76.1468,    490.9180,    -10.9430],\n",
       "        [   -45.5542,    550.0789,    -11.4370],\n",
       "        [  -308.0393,    497.3351,    -12.0402],\n",
       "        [  -180.3725,    548.5873,    -12.4817],\n",
       "        [   -45.1047,    186.7234,     -3.6575],\n",
       "        [    35.5078,    149.8426,     -2.9871],\n",
       "        [    40.9814,    435.3944,     -1.9332],\n",
       "        [     6.3143,    140.8126,     -3.3198],\n",
       "        [    71.9887,    241.5840,     -2.2732],\n",
       "        [  -220.9024,    662.0023,    -12.5131],\n",
       "        [  -187.7134,    304.8638,    -11.1387],\n",
       "        [  -310.1946,    531.7966,    -12.6028],\n",
       "        [  -305.4981,    461.1570,    -12.0504],\n",
       "        [  -223.1171,    432.9388,    -12.2857],\n",
       "        [  -223.7801,    585.8582,    -11.7519],\n",
       "        [    15.8478,    186.0051,     -5.3540],\n",
       "        [  -165.7251,    286.3987,    -10.8234],\n",
       "        [    43.6754,    193.8730,     -1.8508],\n",
       "        [  -210.9132,    321.5896,    -11.0626],\n",
       "        [  -176.5809,    622.7274,    -12.9898],\n",
       "        [  -122.3888,    352.7112,     -9.9498],\n",
       "        [    78.1855,    265.4554,     -1.9996],\n",
       "        [   -55.5325,    268.0675,     -7.3613],\n",
       "        [   -47.6315,    452.0746,    -10.3927],\n",
       "        [  -172.6056,    290.9989,    -10.8114],\n",
       "        [  -241.1163,    707.7333,    -13.5202],\n",
       "        [    35.9095,    139.9924,     -2.9410],\n",
       "        [  -170.5051,    292.8890,    -10.8346],\n",
       "        [  -192.6450,    417.2324,    -13.1981],\n",
       "        [    79.6530,    -72.6626,      3.1378],\n",
       "        [  -242.1869,    707.1165,    -13.9114],\n",
       "        [   -69.7635,    540.0588,    -11.4345],\n",
       "        [  -167.0255,    282.5100,    -10.7981],\n",
       "        [  -279.2435,    542.7194,    -12.0593],\n",
       "        [  -234.1688,    442.4488,    -12.3909],\n",
       "        [  -194.9431,    524.2333,    -12.5485],\n",
       "        [  -216.1318,    395.1051,    -14.4938],\n",
       "        [    77.5086,    406.4619,     -1.4781],\n",
       "        [    40.1190,    144.4788,     -2.8843],\n",
       "        [   -15.6876,    -62.4810,      1.0224],\n",
       "        [    69.8317,    143.3664,     -2.3157],\n",
       "        [    -0.1497,    146.5952,     -3.5063]], device='cuda:1')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans_gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-22T01:57:00.570855Z",
     "start_time": "2020-08-22T01:57:00.544870Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(20.6180, device='cuda:1', grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum((trans_pred - trans_gt)**2,dim=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
