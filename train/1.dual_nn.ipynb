{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torch\n",
    "## Check GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-14T10:39:41.862394Z",
     "start_time": "2020-08-14T10:39:39.969451Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "the rosdep view is empty: call 'sudo rosdep init' and 'rosdep update'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Device 1 : TITAN Xp\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from torchlib.utils import list_device,set_device\n",
    "\n",
    "# S1: check GPU\n",
    "#list_device()\n",
    "\n",
    "# S2: default parameters\n",
    "set_device(1)\n",
    "np.set_printoptions(precision = 2)\n",
    "torch.set_default_dtype(torch.float32)\n",
    "torch.set_printoptions(precision=4)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.set_printoptions(sci_mode=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-14T10:39:41.878090Z",
     "start_time": "2020-08-14T10:39:41.864067Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "'''Training Parameters'''\n",
    "parser.add_argument('--batch_size', type=int, default=60, help='minibatch size')\n",
    "parser.add_argument('--num_epochs', type=int, default=200, help='number of epochs')\n",
    "parser.add_argument('--grad_clip', type=float, default=5., help='clip gradients at this value')\n",
    "parser.add_argument('--learning_rate', type=float, default=0.000005, help='learning rate')\n",
    "parser.add_argument('--learning_rate_clip', type=float, default=0.0000001, help='learning rate clip')\n",
    "parser.add_argument('--decay_rate', type=float, default=.9, help='decay rate for rmsprop')\n",
    "parser.add_argument('--weight_decay', type=float, default=.0001, help='decay rate for rmsprop')\n",
    "parser.add_argument('--batch_norm_decay', type=float, default=.999, help='decay rate for rmsprop')\n",
    "parser.add_argument('--keep_prob', type=float, default=1.0, help='dropout keep probability')\n",
    "parser.add_argument('--lamda_weights', type=float, default=0.01, help='weight of rotation error')\n",
    "parser.add_argument('--data_argumentation', type=bool, default=True, help='whether do data argument')\n",
    "parser.add_argument('--is_normalization', type=bool, default=True, help='whether do data normalization')\n",
    "parser.add_argument('--target_image_size', default=[300, 300], nargs=2, type=int, help='Input images will be resized to this for data argumentation.')\n",
    "\n",
    "'''Configure'''\n",
    "parser.add_argument('--network', type=str, default='vggnet_localization')\n",
    "parser.add_argument('--model_dir', type=str, default='/notebooks/global_localization/dual_resnet_torch', help='rnn, gru, or lstm')\n",
    "\n",
    "\n",
    "parser.add_argument('--train_dataset', type=str, default = ['/notebooks/michigan_nn_data/2012_01_08',\n",
    "                                                            '/notebooks/michigan_nn_data/2012_01_15',\n",
    "                                                            '/notebooks/michigan_nn_data/2012_01_22',\n",
    "                                                            '/notebooks/michigan_nn_data/2012_02_02',\n",
    "                                                            '/notebooks/michigan_nn_data/2012_02_04',\n",
    "                                                            '/notebooks/michigan_nn_data/2012_02_05',\n",
    "                                                            '/notebooks/michigan_nn_data/2012_03_31',\n",
    "                                                            '/notebooks/michigan_nn_data/2012_09_28'])\n",
    "'''\n",
    "#parser.add_argument('--train_dataset', type=str, default = ['/notebooks/michigan_nn_data/test'])\n",
    "parser.add_argument('--train_dataset', type=str, default = ['/notebooks/michigan_nn_data/2012_01_08'])\n",
    "'''\n",
    "parser.add_argument('--norm_tensor', type=str, default = ['/notebooks/global_localization/norm_mean_std.pt'])\n",
    "\n",
    "parser.add_argument('--seed', default=1337, type=int)\n",
    "parser.add_argument('--save_every', type=int, default=3000, help='save frequency')\n",
    "parser.add_argument('--display', type=int, default=20, help='display frequency')\n",
    "parser.add_argument('--tensorboard', type=bool, default=True, help='open tensorboard')\n",
    "parser.add_argument('--cuda_device', type=int, default=1, help='cuda device')\n",
    "\n",
    "sys.argv = ['']\n",
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-14T10:42:50.093157Z",
     "start_time": "2020-08-14T10:39:41.880301Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16446/16446 [00:22<00:00, 722.95it/s]\n",
      "100%|██████████| 22584/22584 [00:31<00:00, 715.98it/s]\n",
      "100%|██████████| 18655/18655 [00:25<00:00, 719.23it/s]\n",
      "100%|██████████| 17310/17310 [00:24<00:00, 721.11it/s]\n",
      "100%|██████████| 10766/10766 [00:14<00:00, 723.18it/s]\n",
      "100%|██████████| 14878/14878 [00:22<00:00, 659.56it/s]\n",
      "100%|██████████| 13452/13452 [00:20<00:00, 665.05it/s]\n",
      "100%|██████████| 14037/14037 [00:25<00:00, 548.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save norm and std: /notebooks/global_localization/norm_mean_std.pt\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import tf.transformations as tf_tran\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchlib import resnet, vggnet, cnn_auxiliary\n",
    "from torchlib.cnn_auxiliary import normalize, denormalize, get_relative_pose, translational_rotational_loss\n",
    "from torchlib.utils import LocalizationDataset, display_loss, data2tensorboard\n",
    "import time\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "dataset = LocalizationDataset(dataset_dirs = args.train_dataset, \\\n",
    "                              image_size = args.target_image_size, \\\n",
    "                              transform = transform, get_pair = True)\n",
    "if len(args.train_dataset)>7:\n",
    "    [args.norm_mean, args.norm_std] = [torch.tensor(x) for x in dataset.get_norm()]\n",
    "    torch.save([args.norm_mean, args.norm_std], *args.norm_tensor)\n",
    "    print('Save norm and std:',*args.norm_tensor)\n",
    "else:\n",
    "    [args.norm_mean, args.norm_std] = torch.load(*args.norm_tensor)\n",
    "    print('Load norm and std:',*args.norm_tensor)\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=args.batch_size, \\\n",
    "                        shuffle=True, num_workers=0, \\\n",
    "                        drop_last=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-14T10:42:50.552017Z",
     "start_time": "2020-08-14T10:42:50.117033Z"
    },
    "code_folding": [
     3,
     36,
     67
    ],
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torchlib.GPs import Backbone, NN, BaseModule\n",
    "        \n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.backbone = Backbone()\n",
    "        self.nn = NN()\n",
    "        \n",
    "    def forward(self, *args):\n",
    "        outputs = []\n",
    "        for input_data in args:\n",
    "            dense_feat = self.backbone(input_data)\n",
    "            output, feature_t, feature_r = self.nn(dense_feat)\n",
    "            outputs += [output]\n",
    "        if len(args)>1:\n",
    "            return outputs\n",
    "        else:\n",
    "            return output, feature_t, feature_r\n",
    "        \n",
    "class PosePredictor(BaseModule):\n",
    "    def __init__(self, norm_mean, norm_std, args, is_training=True, mixed_precision=True):\n",
    "        super().__init__(norm_mean, norm_std, args)\n",
    "        self.model = Model().to(self.device)\n",
    "        self.mixed_precision = mixed_precision\n",
    "        if self.mixed_precision:\n",
    "            self.scaler = GradScaler()\n",
    "        if is_training:\n",
    "            self.optimizer = optim.Adam(self.model.parameters(), \n",
    "                                        lr=args.learning_rate, \n",
    "                                        weight_decay=args.weight_decay)\n",
    "            self.scheduler = optim.lr_scheduler.LambdaLR(optimizer=self.optimizer,\n",
    "                                                             lr_lambda=lambda epoch: args.decay_rate**epoch)\n",
    "        else:\n",
    "            self.disable_requires_grad(self.model)\n",
    "    \n",
    "    def train(self,x0, x1, y0, y1):\n",
    "        # Step 0: zero grad\n",
    "        self.optimizer.zero_grad()\n",
    "        \n",
    "        start = time.time()\n",
    "        # Step 1: get data\n",
    "        x0,x1,y0,y1 = x0.to(self.device),x1.to(self.device),y0.to(self.device),y1.to(self.device)\n",
    "        if args.is_normalization:\n",
    "            y0, y1 = [normalize(y,self.norm_mean, self.norm_std) for y in [y0,y1]]\n",
    "            \n",
    "        # Step 2: training\n",
    "        assert trainer.model.training == True\n",
    "        \n",
    "        if self.mixed_precision:\n",
    "            with autocast():\n",
    "                global_loss, consistent_loss = self._loss(x0, x1, y0, y1)\n",
    "                single_loss = global_loss + consistent_loss\n",
    "                \n",
    "            self.scaler.scale(single_loss).backward()\n",
    "            self.scaler.step(self.optimizer)\n",
    "            self.scaler.update()\n",
    "        else:\n",
    "            global_loss, consistent_loss = self._loss(x0, x1, y0, y1)\n",
    "            single_loss = global_loss + consistent_loss\n",
    "            \n",
    "            single_loss.backward()\n",
    "            self.optimizer.step()\n",
    "        batch_time = time.time() - start\n",
    "        \n",
    "        return float(single_loss), float(global_loss), float(consistent_loss), batch_time\n",
    "    \n",
    "    def _loss(self,x0, x1, y0, y1):\n",
    "        # target relative\n",
    "        relative_target_normed = get_relative_pose(y0, y1)\n",
    "        # forward output\n",
    "        global_output0,global_output1 = self.model(x0, x1)\n",
    "        # output relative\n",
    "        relative_consistence = get_relative_pose(global_output0,global_output1)\n",
    "        \n",
    "        # target loss\n",
    "        global_loss = translational_rotational_loss(pred=global_output1, gt=y1, \\\n",
    "                                                    lamda=args.lamda_weights)\n",
    "        # relative loss\n",
    "        geometry_consistent_loss = translational_rotational_loss(pred=relative_consistence, \\\n",
    "                                                                 gt=relative_target_normed, \\\n",
    "                                                                 lamda=args.lamda_weights)        \n",
    "        \n",
    "        return global_loss, geometry_consistent_loss\n",
    "    \n",
    "    def eval_forward(self,x,y,output_denormalize = True):\n",
    "        # Step 1: get data\n",
    "        x,y = x.to(self.device),y.to(self.device)\n",
    "        \n",
    "        # Step 2: forward\n",
    "        assert trainer.model.training == False\n",
    "        \n",
    "        if self.mixed_precision:\n",
    "            with autocast():\n",
    "                output,_,_ = self.model(x)\n",
    "            self.scaler.scale(output)\n",
    "        else:\n",
    "            output,_,_ = self.model(x)\n",
    "\n",
    "        if args.is_normalization and output_denormalize:\n",
    "            output = denormalize(output, self.norm_mean, self.norm_std)\n",
    "            \n",
    "        # Step 3: split output\n",
    "        trans_target, rot_target = torch.split(y, [3, 4], dim=1)\n",
    "        trans_prediction, rot_prediction = torch.split(output, [3, 4], dim=1)\n",
    "        return trans_prediction, rot_prediction, trans_target, rot_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-14T10:42:57.981024Z",
     "start_time": "2020-08-14T10:42:50.554066Z"
    },
    "code_folding": [
     1,
     15,
     31,
     41,
     46,
     74,
     92
    ],
    "run_control": {
     "marked": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded model to TITAN Xp.\n"
     ]
    }
   ],
   "source": [
    "trainer = PosePredictor(args.norm_mean,args.norm_std,args,mixed_precision=True)\n",
    "trainer.load_model('pretrained.pth')\n",
    "#trainer.load_model('model-12-27000.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-14T10:42:58.896525Z",
     "start_time": "2020-08-14T10:42:57.987746Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "if args.tensorboard:\n",
    "    import os\n",
    "    os.system('rm -rf runs/nn')\n",
    "    from torch.utils.tensorboard import SummaryWriter\n",
    "    writer = SummaryWriter('runs/nn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-14T10:43:30.070137Z",
     "start_time": "2020-08-14T10:42:58.898602Z"
    },
    "code_folding": [],
    "run_control": {
     "marked": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 24/2135 [00:30<44:56,  1.28s/it, ave=0.0015, loss=0.00187, lr=5e-6]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-f5e3dcc232d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0my0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsistent_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-3ccf1e1bb9e2>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, x0, x1, y0, y1)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;31m# Step 0: zero grad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mzero_grad\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m                     \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m                     \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.model.train()\n",
    "for e in range(args.num_epochs):\n",
    "    minibatch_iter = tqdm(dataloader)\n",
    "    train_loss = 0.\n",
    "    for b, data in enumerate(minibatch_iter):\n",
    "        x0, x1 = data['image']\n",
    "        y0, y1 = data['target']\n",
    "        \n",
    "        loss, global_loss, consistent_loss, batch_time = trainer.train(x0,x1,y0,y1)\n",
    "        \n",
    "        train_loss += loss\n",
    "        ave_loss = train_loss/(b+1)\n",
    "        step = e*len(dataloader)+(b+1)\n",
    "        # display data\n",
    "        minibatch_iter.set_postfix(ave = ave_loss, loss=loss,lr=trainer.scheduler.get_last_lr()[-1])\n",
    "        # tensorboard\n",
    "        trainer.data2tensorboard(writer,'training loss',{'item loss':loss,'batch loss':ave_loss},step)\n",
    "        trainer.data2tensorboard(writer,'loss',{'global_loss':global_loss,'con_loss':consistent_loss},step)\n",
    "        # save model\n",
    "        trainer.save_model_step(e,step)\n",
    "        # step scheduler\n",
    "        trainer.schedule_step(step,150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
