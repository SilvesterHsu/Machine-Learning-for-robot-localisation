{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torch\n",
    "## Check GPU¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-06T11:48:10.031331Z",
     "start_time": "2020-07-06T11:48:10.029340Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "#from apex import amp,optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-06T11:48:10.048323Z",
     "start_time": "2020-07-06T11:48:10.032774Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TITAN Xp\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    print(torch.cuda.get_device_name(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set torch default parameters¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-06T11:48:10.289262Z",
     "start_time": "2020-07-06T11:48:10.049915Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "torch.set_default_dtype(torch.float32)\n",
    "torch.set_printoptions(precision=8)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter('runs/train_cnn_gp_torch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-06T11:48:10.306380Z",
     "start_time": "2020-07-06T11:48:10.290848Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "'''Training Parameters'''\n",
    "parser.add_argument('--batch_size', type=int, default=300, help='minibatch size')\n",
    "parser.add_argument('--num_epochs', type=int, default=200, help='number of epochs')\n",
    "parser.add_argument('--grad_clip', type=float, default=5., help='clip gradients at this value')\n",
    "parser.add_argument('--learning_rate', type=float, default=0.0014, help='learning rate')\n",
    "parser.add_argument('--learning_rate_clip', type=float, default=0.0000001, help='learning rate clip')\n",
    "parser.add_argument('--decay_rate', type=float, default=.8, help='decay rate for rmsprop')\n",
    "parser.add_argument('--weight_decay', type=float, default=.0001, help='decay rate for rmsprop')\n",
    "parser.add_argument('--batch_norm_decay', type=float, default=.999, help='decay rate for rmsprop')\n",
    "parser.add_argument('--keep_prob', type=float, default=1.0, help='dropout keep probability')\n",
    "parser.add_argument('--lamda_weights', type=float, default=.01, help='lamda weight')\n",
    "parser.add_argument('--data_argumentation', type=bool, default=True, help='whether do data argument')\n",
    "parser.add_argument('--is_normalization', type=bool, default=True, help='whether do data nomalization')\n",
    "parser.add_argument('--target_image_size', default=[300, 300], nargs=2, type=int, help='Input images will be resized to this for data argumentation.')\n",
    "parser.add_argument('--output_dim', default=3, type=int, help='output dimention.')\n",
    "parser.add_argument('--feat_dim', default=128, type=int, help='feature dimention.')\n",
    "\n",
    "'''Configure'''\n",
    "parser.add_argument('--network', type=str, default='vggnet_localization')\n",
    "parser.add_argument('--model_dir', type=str, default='/notebooks/global_localization/gp_net_torch', help='rnn, gru, or lstm')\n",
    "'''\n",
    "parser.add_argument('--train_dataset', type=str, default = ['/notebooks/michigan_nn_data/2012_01_08',\n",
    "                                                            '/notebooks/michigan_nn_data/2012_01_15',\n",
    "                                                            '/notebooks/michigan_nn_data/2012_01_22',\n",
    "                                                            '/notebooks/michigan_nn_data/2012_02_02',\n",
    "                                                            '/notebooks/michigan_nn_data/2012_02_04',\n",
    "                                                            '/notebooks/michigan_nn_data/2012_02_05',\n",
    "                                                            '/notebooks/michigan_nn_data/2012_03_31',\n",
    "                                                            '/notebooks/michigan_nn_data/2012_09_28'])\n",
    "'''\n",
    "parser.add_argument('--train_dataset', type=str, default = ['/notebooks/michigan_nn_data/test'])\n",
    "\n",
    "parser.add_argument('--seed', default=1337, type=int)\n",
    "parser.add_argument('--save_every', type=int, default=2000, help='save frequency')\n",
    "parser.add_argument('--display', type=int, default=50, help='display frequency')\n",
    "\n",
    "sys.argv = ['']\n",
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-06T11:48:20.012485Z",
     "start_time": "2020-07-06T11:48:10.308108Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "the rosdep view is empty: call 'sudo rosdep init' and 'rosdep update'\n",
      "100%|██████████| 5593/5593 [00:08<00:00, 627.95it/s]\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import tf.transformations as tf_tran\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "#import gpflow.multioutput.kernels as mk\n",
    "import gpytorch\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchlib import resnet, vggnet\n",
    "from torchlib.utils import LocalizationDataset\n",
    "import time\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "dataset = LocalizationDataset(dataset_dirs = args.train_dataset, \\\n",
    "                              image_size = args.target_image_size, \\\n",
    "                              transform = transform,\n",
    "                              get_pair = False)\n",
    "[args.norm_mean, args.norm_std] = [torch.tensor(x) for x in dataset.get_norm()]\n",
    "#torch.save([args.norm_mean, args.norm_std], '/notebooks/global_localization/norm_mean_std.pt')\n",
    "\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=args.batch_size, \\\n",
    "                        shuffle=True, num_workers=0, \\\n",
    "                        drop_last=True, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-06T11:48:20.038001Z",
     "start_time": "2020-07-06T11:48:20.014059Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-112.99884796,  368.48632812,   -9.70891380]),\n",
       " tensor([ 64.78961945, 167.54393005,   3.75537634]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.norm_mean, args.norm_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-06T11:48:20.054527Z",
     "start_time": "2020-07-06T11:48:20.039418Z"
    },
    "code_folding": [
     0,
     19,
     47
    ],
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "def normalize(target, norm_mean, norm_std):\n",
    "    target_trans = target[:,:3]\n",
    "    target_trans = torch.div(torch.sub(target_trans,norm_mean),norm_std)\n",
    "    target_normed = torch.cat([target_trans,target[:,3:]],dim=1)\n",
    "    return target_normed \n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.resnet = resnet.resnet50(pretrained=True)\n",
    "        self.global_context = vggnet.vggnet(input_channel=2048,opt=\"context\")\n",
    "        self.global_regressor = vggnet.vggnet(opt=\"regressor\")\n",
    "        \n",
    "    def forward(self,input_data):\n",
    "        dense_feat = self.resnet(input_data)\n",
    "        global_context_feat = self.global_context(dense_feat)\n",
    "        global_output, trans_feat, rot_feat = self.global_regressor(global_context_feat)\n",
    "        return global_output, trans_feat, rot_feat\n",
    "    \n",
    "class MultitaskGPModel(gpytorch.models.ApproximateGP):\n",
    "    def __init__(self, inducing_points):\n",
    "        # We have to mark the CholeskyVariationalDistribution as batch\n",
    "        # so that we learn a variational distribution for each task\n",
    "        variational_distribution = gpytorch.variational.CholeskyVariationalDistribution(\n",
    "            inducing_points.size(-2), batch_shape=torch.Size([3])\n",
    "        )\n",
    "\n",
    "        # We have to wrap the VariationalStrategy in a MultitaskVariationalStrategy\n",
    "        # so that the output will be a MultitaskMultivariateNormal rather than a batch output\n",
    "        variational_strategy = gpytorch.variational.MultitaskVariationalStrategy(\n",
    "            gpytorch.variational.VariationalStrategy(\n",
    "                self, inducing_points, variational_distribution, learn_inducing_locations=True\n",
    "            ), num_tasks=3\n",
    "        )\n",
    "\n",
    "        super().__init__(variational_strategy)\n",
    "\n",
    "        # The mean and covariance modules should be marked as batch\n",
    "        # so we learn a different set of hyperparameters\n",
    "        #self.net = Model()\n",
    "        #self.net.load_state_dict(torch.load(os.path.join(args.model_dir,'model-23-96000.pth')))\n",
    "        self.mean_module = gpytorch.means.ConstantMean(batch_shape=torch.Size([1]))\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(\n",
    "            gpytorch.kernels.RBFKernel(batch_shape=torch.Size([1])),\n",
    "            batch_shape=torch.Size([1])\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # The forward function should be written as if we were dealing with each output\n",
    "        # dimension in batch\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "    \n",
    "class GPModel(gpytorch.Module):\n",
    "    def __init__(self, inducing_points):\n",
    "        super(GPModel, self).__init__()\n",
    "        self.net = Model()\n",
    "        #self.net.load_state_dict(torch.load(os.path.join('/notebooks/global_localization/dual_resnet_torch','model-23-96000.pth')))\n",
    "        self.gp = MultitaskGPModel(inducing_points)\n",
    "        self.likelihood = gpytorch.likelihoods.MultitaskGaussianLikelihood(num_tasks=3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        global_output, trans_feat, _ = self.net(x)\n",
    "        _, rot_pred = torch.split(global_output, [3, 4], dim=1)\n",
    "        output = self.gp(trans_feat)\n",
    "        \n",
    "        return output,rot_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creat Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-06T11:48:23.665734Z",
     "start_time": "2020-07-06T11:48:20.056059Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nstate_dict = torch.load(os.path.join('/notebooks/global_localization/dual_resnet_torch','pretrained.pth'))\\nfor name,param in state_dict.items():\\n    print(name, param.shape)\\nprint('Parameters layer:',len(state_dict.keys()))\\nmodel.net.load_state_dict(state_dict)\\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = torch.device(\"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.set_device(device)\n",
    "\n",
    "model = GPModel(torch.zeros(3, args.batch_size, 128)).to(device)\n",
    "# Load Resnet\n",
    "'''\n",
    "state_dict = torch.load(os.path.join('/notebooks/global_localization/dual_resnet_torch','pretrained.pth'))\n",
    "for name,param in state_dict.items():\n",
    "    print(name, param.shape)\n",
    "print('Parameters layer:',len(state_dict.keys()))\n",
    "model.net.load_state_dict(state_dict)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-06T11:48:27.326904Z",
     "start_time": "2020-07-06T11:48:26.825537Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "net.resnet.conv1.weight torch.Size([64, 1, 7, 7])\n",
      "net.resnet.bn1.weight torch.Size([64])\n",
      "net.resnet.bn1.bias torch.Size([64])\n",
      "net.resnet.bn1.running_mean torch.Size([64])\n",
      "net.resnet.bn1.running_var torch.Size([64])\n",
      "net.resnet.bn1.num_batches_tracked torch.Size([])\n",
      "net.resnet.layer1.0.conv1.weight torch.Size([64, 64, 1, 1])\n",
      "net.resnet.layer1.0.bn1.weight torch.Size([64])\n",
      "net.resnet.layer1.0.bn1.bias torch.Size([64])\n",
      "net.resnet.layer1.0.bn1.running_mean torch.Size([64])\n",
      "net.resnet.layer1.0.bn1.running_var torch.Size([64])\n",
      "net.resnet.layer1.0.bn1.num_batches_tracked torch.Size([])\n",
      "net.resnet.layer1.0.conv2.weight torch.Size([64, 64, 3, 3])\n",
      "net.resnet.layer1.0.bn2.weight torch.Size([64])\n",
      "net.resnet.layer1.0.bn2.bias torch.Size([64])\n",
      "net.resnet.layer1.0.bn2.running_mean torch.Size([64])\n",
      "net.resnet.layer1.0.bn2.running_var torch.Size([64])\n",
      "net.resnet.layer1.0.bn2.num_batches_tracked torch.Size([])\n",
      "net.resnet.layer1.0.conv3.weight torch.Size([256, 64, 1, 1])\n",
      "net.resnet.layer1.0.bn3.weight torch.Size([256])\n",
      "net.resnet.layer1.0.bn3.bias torch.Size([256])\n",
      "net.resnet.layer1.0.bn3.running_mean torch.Size([256])\n",
      "net.resnet.layer1.0.bn3.running_var torch.Size([256])\n",
      "net.resnet.layer1.0.bn3.num_batches_tracked torch.Size([])\n",
      "net.resnet.layer1.0.downsample.0.weight torch.Size([256, 64, 1, 1])\n",
      "net.resnet.layer1.0.downsample.1.weight torch.Size([256])\n",
      "net.resnet.layer1.0.downsample.1.bias torch.Size([256])\n",
      "net.resnet.layer1.0.downsample.1.running_mean torch.Size([256])\n",
      "net.resnet.layer1.0.downsample.1.running_var torch.Size([256])\n",
      "net.resnet.layer1.0.downsample.1.num_batches_tracked torch.Size([])\n",
      "net.resnet.layer1.1.conv1.weight torch.Size([64, 256, 1, 1])\n",
      "net.resnet.layer1.1.bn1.weight torch.Size([64])\n",
      "net.resnet.layer1.1.bn1.bias torch.Size([64])\n",
      "net.resnet.layer1.1.bn1.running_mean torch.Size([64])\n",
      "net.resnet.layer1.1.bn1.running_var torch.Size([64])\n",
      "net.resnet.layer1.1.bn1.num_batches_tracked torch.Size([])\n",
      "net.resnet.layer1.1.conv2.weight torch.Size([64, 64, 3, 3])\n",
      "net.resnet.layer1.1.bn2.weight torch.Size([64])\n",
      "net.resnet.layer1.1.bn2.bias torch.Size([64])\n",
      "net.resnet.layer1.1.bn2.running_mean torch.Size([64])\n",
      "net.resnet.layer1.1.bn2.running_var torch.Size([64])\n",
      "net.resnet.layer1.1.bn2.num_batches_tracked torch.Size([])\n",
      "net.resnet.layer1.1.conv3.weight torch.Size([256, 64, 1, 1])\n",
      "net.resnet.layer1.1.bn3.weight torch.Size([256])\n",
      "net.resnet.layer1.1.bn3.bias torch.Size([256])\n",
      "net.resnet.layer1.1.bn3.running_mean torch.Size([256])\n",
      "net.resnet.layer1.1.bn3.running_var torch.Size([256])\n",
      "net.resnet.layer1.1.bn3.num_batches_tracked torch.Size([])\n",
      "net.resnet.layer1.2.conv1.weight torch.Size([64, 256, 1, 1])\n",
      "net.resnet.layer1.2.bn1.weight torch.Size([64])\n",
      "net.resnet.layer1.2.bn1.bias torch.Size([64])\n",
      "net.resnet.layer1.2.bn1.running_mean torch.Size([64])\n",
      "net.resnet.layer1.2.bn1.running_var torch.Size([64])\n",
      "net.resnet.layer1.2.bn1.num_batches_tracked torch.Size([])\n",
      "net.resnet.layer1.2.conv2.weight torch.Size([64, 64, 3, 3])\n",
      "net.resnet.layer1.2.bn2.weight torch.Size([64])\n",
      "net.resnet.layer1.2.bn2.bias torch.Size([64])\n",
      "net.resnet.layer1.2.bn2.running_mean torch.Size([64])\n",
      "net.resnet.layer1.2.bn2.running_var torch.Size([64])\n",
      "net.resnet.layer1.2.bn2.num_batches_tracked torch.Size([])\n",
      "net.resnet.layer1.2.conv3.weight torch.Size([256, 64, 1, 1])\n",
      "net.resnet.layer1.2.bn3.weight torch.Size([256])\n",
      "net.resnet.layer1.2.bn3.bias torch.Size([256])\n",
      "net.resnet.layer1.2.bn3.running_mean torch.Size([256])\n",
      "net.resnet.layer1.2.bn3.running_var torch.Size([256])\n",
      "net.resnet.layer1.2.bn3.num_batches_tracked torch.Size([])\n",
      "net.resnet.layer2.0.conv1.weight torch.Size([128, 256, 1, 1])\n",
      "net.resnet.layer2.0.bn1.weight torch.Size([128])\n",
      "net.resnet.layer2.0.bn1.bias torch.Size([128])\n",
      "net.resnet.layer2.0.bn1.running_mean torch.Size([128])\n",
      "net.resnet.layer2.0.bn1.running_var torch.Size([128])\n",
      "net.resnet.layer2.0.bn1.num_batches_tracked torch.Size([])\n",
      "net.resnet.layer2.0.conv2.weight torch.Size([128, 128, 3, 3])\n",
      "net.resnet.layer2.0.bn2.weight torch.Size([128])\n",
      "net.resnet.layer2.0.bn2.bias torch.Size([128])\n",
      "net.resnet.layer2.0.bn2.running_mean torch.Size([128])\n",
      "net.resnet.layer2.0.bn2.running_var torch.Size([128])\n",
      "net.resnet.layer2.0.bn2.num_batches_tracked torch.Size([])\n",
      "net.resnet.layer2.0.conv3.weight torch.Size([512, 128, 1, 1])\n",
      "net.resnet.layer2.0.bn3.weight torch.Size([512])\n",
      "net.resnet.layer2.0.bn3.bias torch.Size([512])\n",
      "net.resnet.layer2.0.bn3.running_mean torch.Size([512])\n",
      "net.resnet.layer2.0.bn3.running_var torch.Size([512])\n",
      "net.resnet.layer2.0.bn3.num_batches_tracked torch.Size([])\n",
      "net.resnet.layer2.0.downsample.0.weight torch.Size([512, 256, 1, 1])\n",
      "net.resnet.layer2.0.downsample.1.weight torch.Size([512])\n",
      "net.resnet.layer2.0.downsample.1.bias torch.Size([512])\n",
      "net.resnet.layer2.0.downsample.1.running_mean torch.Size([512])\n",
      "net.resnet.layer2.0.downsample.1.running_var torch.Size([512])\n",
      "net.resnet.layer2.0.downsample.1.num_batches_tracked torch.Size([])\n",
      "net.resnet.layer2.1.conv1.weight torch.Size([128, 512, 1, 1])\n",
      "net.resnet.layer2.1.bn1.weight torch.Size([128])\n",
      "net.resnet.layer2.1.bn1.bias torch.Size([128])\n",
      "net.resnet.layer2.1.bn1.running_mean torch.Size([128])\n",
      "net.resnet.layer2.1.bn1.running_var torch.Size([128])\n",
      "net.resnet.layer2.1.bn1.num_batches_tracked torch.Size([])\n",
      "net.resnet.layer2.1.conv2.weight torch.Size([128, 128, 3, 3])\n",
      "net.resnet.layer2.1.bn2.weight torch.Size([128])\n",
      "net.resnet.layer2.1.bn2.bias torch.Size([128])\n",
      "net.resnet.layer2.1.bn2.running_mean torch.Size([128])\n",
      "net.resnet.layer2.1.bn2.running_var torch.Size([128])\n",
      "net.resnet.layer2.1.bn2.num_batches_tracked torch.Size([])\n",
      "net.resnet.layer2.1.conv3.weight torch.Size([512, 128, 1, 1])\n",
      "net.resnet.layer2.1.bn3.weight torch.Size([512])\n",
      "net.resnet.layer2.1.bn3.bias torch.Size([512])\n",
      "net.resnet.layer2.1.bn3.running_mean torch.Size([512])\n",
      "net.resnet.layer2.1.bn3.running_var torch.Size([512])\n",
      "net.resnet.layer2.1.bn3.num_batches_tracked torch.Size([])\n",
      "net.resnet.layer2.2.conv1.weight torch.Size([128, 512, 1, 1])\n",
      "net.resnet.layer2.2.bn1.weight torch.Size([128])\n",
      "net.resnet.layer2.2.bn1.bias torch.Size([128])\n",
      "net.resnet.layer2.2.bn1.running_mean torch.Size([128])\n",
      "net.resnet.layer2.2.bn1.running_var torch.Size([128])\n",
      "net.resnet.layer2.2.bn1.num_batches_tracked torch.Size([])\n",
      "net.resnet.layer2.2.conv2.weight torch.Size([128, 128, 3, 3])\n",
      "net.resnet.layer2.2.bn2.weight torch.Size([128])\n",
      "net.resnet.layer2.2.bn2.bias torch.Size([128])\n",
      "net.resnet.layer2.2.bn2.running_mean torch.Size([128])\n",
      "net.resnet.layer2.2.bn2.running_var torch.Size([128])\n",
      "net.resnet.layer2.2.bn2.num_batches_tracked torch.Size([])\n",
      "net.resnet.layer2.2.conv3.weight torch.Size([512, 128, 1, 1])\n",
      "net.resnet.layer2.2.bn3.weight torch.Size([512])\n",
      "net.resnet.layer2.2.bn3.bias torch.Size([512])\n",
      "net.resnet.layer2.2.bn3.running_mean torch.Size([512])\n",
      "net.resnet.layer2.2.bn3.running_var torch.Size([512])\n",
      "net.resnet.layer2.2.bn3.num_batches_tracked torch.Size([])\n",
      "net.resnet.layer2.3.conv1.weight torch.Size([128, 512, 1, 1])\n",
      "net.resnet.layer2.3.bn1.weight torch.Size([128])\n",
      "net.resnet.layer2.3.bn1.bias torch.Size([128])\n",
      "net.resnet.layer2.3.bn1.running_mean torch.Size([128])\n",
      "net.resnet.layer2.3.bn1.running_var torch.Size([128])\n",
      "net.resnet.layer2.3.bn1.num_batches_tracked torch.Size([])\n",
      "net.resnet.layer2.3.conv2.weight torch.Size([128, 128, 3, 3])\n",
      "net.resnet.layer2.3.bn2.weight torch.Size([128])\n",
      "net.resnet.layer2.3.bn2.bias torch.Size([128])\n",
      "net.resnet.layer2.3.bn2.running_mean torch.Size([128])\n",
      "net.resnet.layer2.3.bn2.running_var torch.Size([128])\n",
      "net.resnet.layer2.3.bn2.num_batches_tracked torch.Size([])\n",
      "net.resnet.layer2.3.conv3.weight torch.Size([512, 128, 1, 1])\n",
      "net.resnet.layer2.3.bn3.weight torch.Size([512])\n",
      "net.resnet.layer2.3.bn3.bias torch.Size([512])\n",
      "net.resnet.layer2.3.bn3.running_mean torch.Size([512])\n",
      "net.resnet.layer2.3.bn3.running_var torch.Size([512])\n",
      "net.resnet.layer2.3.bn3.num_batches_tracked torch.Size([])\n",
      "net.resnet.layer3.0.conv1.weight torch.Size([256, 512, 1, 1])\n",
      "net.resnet.layer3.0.bn1.weight torch.Size([256])\n",
      "net.resnet.layer3.0.bn1.bias torch.Size([256])\n",
      "net.resnet.layer3.0.bn1.running_mean torch.Size([256])\n",
      "net.resnet.layer3.0.bn1.running_var torch.Size([256])\n",
      "net.resnet.layer3.0.bn1.num_batches_tracked torch.Size([])\n",
      "net.resnet.layer3.0.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "net.resnet.layer3.0.bn2.weight torch.Size([256])\n",
      "net.resnet.layer3.0.bn2.bias torch.Size([256])\n",
      "net.resnet.layer3.0.bn2.running_mean torch.Size([256])\n",
      "net.resnet.layer3.0.bn2.running_var torch.Size([256])\n",
      "net.resnet.layer3.0.bn2.num_batches_tracked torch.Size([])\n",
      "net.resnet.layer3.0.conv3.weight torch.Size([1024, 256, 1, 1])\n",
      "net.resnet.layer3.0.bn3.weight torch.Size([1024])\n",
      "net.resnet.layer3.0.bn3.bias torch.Size([1024])\n",
      "net.resnet.layer3.0.bn3.running_mean torch.Size([1024])\n",
      "net.resnet.layer3.0.bn3.running_var torch.Size([1024])\n",
      "net.resnet.layer3.0.bn3.num_batches_tracked torch.Size([])\n",
      "net.resnet.layer3.0.downsample.0.weight torch.Size([1024, 512, 1, 1])\n",
      "net.resnet.layer3.0.downsample.1.weight torch.Size([1024])\n",
      "net.resnet.layer3.0.downsample.1.bias torch.Size([1024])\n",
      "net.resnet.layer3.0.downsample.1.running_mean torch.Size([1024])\n",
      "net.resnet.layer3.0.downsample.1.running_var torch.Size([1024])\n",
      "net.resnet.layer3.0.downsample.1.num_batches_tracked torch.Size([])\n",
      "net.resnet.layer3.1.conv1.weight torch.Size([256, 1024, 1, 1])\n",
      "net.resnet.layer3.1.bn1.weight torch.Size([256])\n",
      "net.resnet.layer3.1.bn1.bias torch.Size([256])\n",
      "net.resnet.layer3.1.bn1.running_mean torch.Size([256])\n",
      "net.resnet.layer3.1.bn1.running_var torch.Size([256])\n",
      "net.resnet.layer3.1.bn1.num_batches_tracked torch.Size([])\n",
      "net.resnet.layer3.1.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "net.resnet.layer3.1.bn2.weight torch.Size([256])\n",
      "net.resnet.layer3.1.bn2.bias torch.Size([256])\n",
      "net.resnet.layer3.1.bn2.running_mean torch.Size([256])\n",
      "net.resnet.layer3.1.bn2.running_var torch.Size([256])\n",
      "net.resnet.layer3.1.bn2.num_batches_tracked torch.Size([])\n",
      "net.resnet.layer3.1.conv3.weight torch.Size([1024, 256, 1, 1])\n",
      "net.resnet.layer3.1.bn3.weight torch.Size([1024])\n",
      "net.resnet.layer3.1.bn3.bias torch.Size([1024])\n",
      "net.resnet.layer3.1.bn3.running_mean torch.Size([1024])\n",
      "net.resnet.layer3.1.bn3.running_var torch.Size([1024])\n",
      "net.resnet.layer3.1.bn3.num_batches_tracked torch.Size([])\n",
      "net.resnet.layer3.2.conv1.weight torch.Size([256, 1024, 1, 1])\n",
      "net.resnet.layer3.2.bn1.weight torch.Size([256])\n",
      "net.resnet.layer3.2.bn1.bias torch.Size([256])\n",
      "net.resnet.layer3.2.bn1.running_mean torch.Size([256])\n",
      "net.resnet.layer3.2.bn1.running_var torch.Size([256])\n",
      "net.resnet.layer3.2.bn1.num_batches_tracked torch.Size([])\n",
      "net.resnet.layer3.2.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "net.resnet.layer3.2.bn2.weight torch.Size([256])\n",
      "net.resnet.layer3.2.bn2.bias torch.Size([256])\n",
      "net.resnet.layer3.2.bn2.running_mean torch.Size([256])\n",
      "net.resnet.layer3.2.bn2.running_var torch.Size([256])\n",
      "net.resnet.layer3.2.bn2.num_batches_tracked torch.Size([])\n",
      "net.resnet.layer3.2.conv3.weight torch.Size([1024, 256, 1, 1])\n",
      "net.resnet.layer3.2.bn3.weight torch.Size([1024])\n",
      "net.resnet.layer3.2.bn3.bias torch.Size([1024])\n",
      "net.resnet.layer3.2.bn3.running_mean torch.Size([1024])\n",
      "net.resnet.layer3.2.bn3.running_var torch.Size([1024])\n",
      "net.resnet.layer3.2.bn3.num_batches_tracked torch.Size([])\n",
      "net.resnet.layer3.3.conv1.weight torch.Size([256, 1024, 1, 1])\n",
      "net.resnet.layer3.3.bn1.weight torch.Size([256])\n",
      "net.resnet.layer3.3.bn1.bias torch.Size([256])\n",
      "net.resnet.layer3.3.bn1.running_mean torch.Size([256])\n",
      "net.resnet.layer3.3.bn1.running_var torch.Size([256])\n",
      "net.resnet.layer3.3.bn1.num_batches_tracked torch.Size([])\n",
      "net.resnet.layer3.3.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "net.resnet.layer3.3.bn2.weight torch.Size([256])\n",
      "net.resnet.layer3.3.bn2.bias torch.Size([256])\n",
      "net.resnet.layer3.3.bn2.running_mean torch.Size([256])\n",
      "net.resnet.layer3.3.bn2.running_var torch.Size([256])\n",
      "net.resnet.layer3.3.bn2.num_batches_tracked torch.Size([])\n",
      "net.resnet.layer3.3.conv3.weight torch.Size([1024, 256, 1, 1])\n",
      "net.resnet.layer3.3.bn3.weight torch.Size([1024])\n",
      "net.resnet.layer3.3.bn3.bias torch.Size([1024])\n",
      "net.resnet.layer3.3.bn3.running_mean torch.Size([1024])\n",
      "net.resnet.layer3.3.bn3.running_var torch.Size([1024])\n",
      "net.resnet.layer3.3.bn3.num_batches_tracked torch.Size([])\n",
      "net.resnet.layer3.4.conv1.weight torch.Size([256, 1024, 1, 1])\n",
      "net.resnet.layer3.4.bn1.weight torch.Size([256])\n",
      "net.resnet.layer3.4.bn1.bias torch.Size([256])\n",
      "net.resnet.layer3.4.bn1.running_mean torch.Size([256])\n",
      "net.resnet.layer3.4.bn1.running_var torch.Size([256])\n",
      "net.resnet.layer3.4.bn1.num_batches_tracked torch.Size([])\n",
      "net.resnet.layer3.4.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "net.resnet.layer3.4.bn2.weight torch.Size([256])\n",
      "net.resnet.layer3.4.bn2.bias torch.Size([256])\n",
      "net.resnet.layer3.4.bn2.running_mean torch.Size([256])\n",
      "net.resnet.layer3.4.bn2.running_var torch.Size([256])\n",
      "net.resnet.layer3.4.bn2.num_batches_tracked torch.Size([])\n",
      "net.resnet.layer3.4.conv3.weight torch.Size([1024, 256, 1, 1])\n",
      "net.resnet.layer3.4.bn3.weight torch.Size([1024])\n",
      "net.resnet.layer3.4.bn3.bias torch.Size([1024])\n",
      "net.resnet.layer3.4.bn3.running_mean torch.Size([1024])\n",
      "net.resnet.layer3.4.bn3.running_var torch.Size([1024])\n",
      "net.resnet.layer3.4.bn3.num_batches_tracked torch.Size([])\n",
      "net.resnet.layer3.5.conv1.weight torch.Size([256, 1024, 1, 1])\n",
      "net.resnet.layer3.5.bn1.weight torch.Size([256])\n",
      "net.resnet.layer3.5.bn1.bias torch.Size([256])\n",
      "net.resnet.layer3.5.bn1.running_mean torch.Size([256])\n",
      "net.resnet.layer3.5.bn1.running_var torch.Size([256])\n",
      "net.resnet.layer3.5.bn1.num_batches_tracked torch.Size([])\n",
      "net.resnet.layer3.5.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "net.resnet.layer3.5.bn2.weight torch.Size([256])\n",
      "net.resnet.layer3.5.bn2.bias torch.Size([256])\n",
      "net.resnet.layer3.5.bn2.running_mean torch.Size([256])\n",
      "net.resnet.layer3.5.bn2.running_var torch.Size([256])\n",
      "net.resnet.layer3.5.bn2.num_batches_tracked torch.Size([])\n",
      "net.resnet.layer3.5.conv3.weight torch.Size([1024, 256, 1, 1])\n",
      "net.resnet.layer3.5.bn3.weight torch.Size([1024])\n",
      "net.resnet.layer3.5.bn3.bias torch.Size([1024])\n",
      "net.resnet.layer3.5.bn3.running_mean torch.Size([1024])\n",
      "net.resnet.layer3.5.bn3.running_var torch.Size([1024])\n",
      "net.resnet.layer3.5.bn3.num_batches_tracked torch.Size([])\n",
      "net.resnet.layer4.0.conv1.weight torch.Size([512, 1024, 1, 1])\n",
      "net.resnet.layer4.0.bn1.weight torch.Size([512])\n",
      "net.resnet.layer4.0.bn1.bias torch.Size([512])\n",
      "net.resnet.layer4.0.bn1.running_mean torch.Size([512])\n",
      "net.resnet.layer4.0.bn1.running_var torch.Size([512])\n",
      "net.resnet.layer4.0.bn1.num_batches_tracked torch.Size([])\n",
      "net.resnet.layer4.0.conv2.weight torch.Size([512, 512, 3, 3])\n",
      "net.resnet.layer4.0.bn2.weight torch.Size([512])\n",
      "net.resnet.layer4.0.bn2.bias torch.Size([512])\n",
      "net.resnet.layer4.0.bn2.running_mean torch.Size([512])\n",
      "net.resnet.layer4.0.bn2.running_var torch.Size([512])\n",
      "net.resnet.layer4.0.bn2.num_batches_tracked torch.Size([])\n",
      "net.resnet.layer4.0.conv3.weight torch.Size([2048, 512, 1, 1])\n",
      "net.resnet.layer4.0.bn3.weight torch.Size([2048])\n",
      "net.resnet.layer4.0.bn3.bias torch.Size([2048])\n",
      "net.resnet.layer4.0.bn3.running_mean torch.Size([2048])\n",
      "net.resnet.layer4.0.bn3.running_var torch.Size([2048])\n",
      "net.resnet.layer4.0.bn3.num_batches_tracked torch.Size([])\n",
      "net.resnet.layer4.0.downsample.0.weight torch.Size([2048, 1024, 1, 1])\n",
      "net.resnet.layer4.0.downsample.1.weight torch.Size([2048])\n",
      "net.resnet.layer4.0.downsample.1.bias torch.Size([2048])\n",
      "net.resnet.layer4.0.downsample.1.running_mean torch.Size([2048])\n",
      "net.resnet.layer4.0.downsample.1.running_var torch.Size([2048])\n",
      "net.resnet.layer4.0.downsample.1.num_batches_tracked torch.Size([])\n",
      "net.resnet.layer4.1.conv1.weight torch.Size([512, 2048, 1, 1])\n",
      "net.resnet.layer4.1.bn1.weight torch.Size([512])\n",
      "net.resnet.layer4.1.bn1.bias torch.Size([512])\n",
      "net.resnet.layer4.1.bn1.running_mean torch.Size([512])\n",
      "net.resnet.layer4.1.bn1.running_var torch.Size([512])\n",
      "net.resnet.layer4.1.bn1.num_batches_tracked torch.Size([])\n",
      "net.resnet.layer4.1.conv2.weight torch.Size([512, 512, 3, 3])\n",
      "net.resnet.layer4.1.bn2.weight torch.Size([512])\n",
      "net.resnet.layer4.1.bn2.bias torch.Size([512])\n",
      "net.resnet.layer4.1.bn2.running_mean torch.Size([512])\n",
      "net.resnet.layer4.1.bn2.running_var torch.Size([512])\n",
      "net.resnet.layer4.1.bn2.num_batches_tracked torch.Size([])\n",
      "net.resnet.layer4.1.conv3.weight torch.Size([2048, 512, 1, 1])\n",
      "net.resnet.layer4.1.bn3.weight torch.Size([2048])\n",
      "net.resnet.layer4.1.bn3.bias torch.Size([2048])\n",
      "net.resnet.layer4.1.bn3.running_mean torch.Size([2048])\n",
      "net.resnet.layer4.1.bn3.running_var torch.Size([2048])\n",
      "net.resnet.layer4.1.bn3.num_batches_tracked torch.Size([])\n",
      "net.resnet.layer4.2.conv1.weight torch.Size([512, 2048, 1, 1])\n",
      "net.resnet.layer4.2.bn1.weight torch.Size([512])\n",
      "net.resnet.layer4.2.bn1.bias torch.Size([512])\n",
      "net.resnet.layer4.2.bn1.running_mean torch.Size([512])\n",
      "net.resnet.layer4.2.bn1.running_var torch.Size([512])\n",
      "net.resnet.layer4.2.bn1.num_batches_tracked torch.Size([])\n",
      "net.resnet.layer4.2.conv2.weight torch.Size([512, 512, 3, 3])\n",
      "net.resnet.layer4.2.bn2.weight torch.Size([512])\n",
      "net.resnet.layer4.2.bn2.bias torch.Size([512])\n",
      "net.resnet.layer4.2.bn2.running_mean torch.Size([512])\n",
      "net.resnet.layer4.2.bn2.running_var torch.Size([512])\n",
      "net.resnet.layer4.2.bn2.num_batches_tracked torch.Size([])\n",
      "net.resnet.layer4.2.conv3.weight torch.Size([2048, 512, 1, 1])\n",
      "net.resnet.layer4.2.bn3.weight torch.Size([2048])\n",
      "net.resnet.layer4.2.bn3.bias torch.Size([2048])\n",
      "net.resnet.layer4.2.bn3.running_mean torch.Size([2048])\n",
      "net.resnet.layer4.2.bn3.running_var torch.Size([2048])\n",
      "net.resnet.layer4.2.bn3.num_batches_tracked torch.Size([])\n",
      "net.global_context.context.squeeze.0.weight torch.Size([128, 2048, 1, 1])\n",
      "net.global_context.context.squeeze.0.bias torch.Size([128])\n",
      "net.global_context.context.context5_1.0.weight torch.Size([128, 128, 3, 3])\n",
      "net.global_context.context.context5_1.0.bias torch.Size([128])\n",
      "net.global_context.context.context5_2.0.weight torch.Size([128, 128, 3, 3])\n",
      "net.global_context.context.context5_2.0.bias torch.Size([128])\n",
      "net.global_context.context.context5_3.0.weight torch.Size([128, 128, 3, 3])\n",
      "net.global_context.context.context5_3.0.bias torch.Size([128])\n",
      "net.global_context.context.context5_4.0.weight torch.Size([128, 128, 3, 3])\n",
      "net.global_context.context.context5_4.0.bias torch.Size([128])\n",
      "net.global_context.context.squeeze2.0.weight torch.Size([64, 128, 1, 1])\n",
      "net.global_context.context.squeeze2.0.bias torch.Size([64])\n",
      "net.global_regressor.regressor.fc1_trans.0.weight torch.Size([4096, 6400])\n",
      "net.global_regressor.regressor.fc1_trans.0.bias torch.Size([4096])\n",
      "net.global_regressor.regressor.fc2_trans.0.weight torch.Size([4096, 4096])\n",
      "net.global_regressor.regressor.fc2_trans.0.bias torch.Size([4096])\n",
      "net.global_regressor.regressor.fc3_trans.0.weight torch.Size([128, 4096])\n",
      "net.global_regressor.regressor.fc3_trans.0.bias torch.Size([128])\n",
      "net.global_regressor.regressor.logits_t.weight torch.Size([3, 128])\n",
      "net.global_regressor.regressor.logits_t.bias torch.Size([3])\n",
      "net.global_regressor.regressor.fc1_rot.0.weight torch.Size([4096, 6400])\n",
      "net.global_regressor.regressor.fc1_rot.0.bias torch.Size([4096])\n",
      "net.global_regressor.regressor.fc2_rot.0.weight torch.Size([4096, 4096])\n",
      "net.global_regressor.regressor.fc2_rot.0.bias torch.Size([4096])\n",
      "net.global_regressor.regressor.fc3_rot.0.weight torch.Size([128, 4096])\n",
      "net.global_regressor.regressor.fc3_rot.0.bias torch.Size([128])\n",
      "net.global_regressor.regressor.logits_r.weight torch.Size([4, 128])\n",
      "net.global_regressor.regressor.logits_r.bias torch.Size([4])\n",
      "gp.variational_strategy.base_variational_strategy.inducing_points torch.Size([3, 300, 128])\n",
      "gp.variational_strategy.base_variational_strategy.variational_params_initialized torch.Size([])\n",
      "gp.variational_strategy.base_variational_strategy.updated_strategy torch.Size([])\n",
      "gp.variational_strategy.base_variational_strategy._variational_distribution.variational_mean torch.Size([3, 300])\n",
      "gp.variational_strategy.base_variational_strategy._variational_distribution.chol_variational_covar torch.Size([3, 300, 300])\n",
      "gp.mean_module.constant torch.Size([1, 1])\n",
      "gp.covar_module.raw_outputscale torch.Size([1])\n",
      "gp.covar_module.base_kernel.raw_lengthscale torch.Size([1, 1, 1])\n",
      "likelihood.raw_noise torch.Size([1])\n",
      "likelihood.noise_covar.raw_noise torch.Size([3])\n",
      "Parameters layer: 356\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict = torch.load(os.path.join(args.model_dir,'pretrained.pth'))\n",
    "for name,param in state_dict.items():\n",
    "    print(name, param.shape)\n",
    "print('Parameters layer:',len(state_dict.keys()))\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T07:46:31.357680Z",
     "start_time": "2020-06-27T07:46:31.348303Z"
    },
    "run_control": {
     "marked": true
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "net.global_context.context.squeeze.0.weight torch.Size([128, 2048, 1, 1])\n",
      "net.global_context.context.squeeze.0.bias torch.Size([128])\n",
      "net.global_context.context.context5_1.0.weight torch.Size([128, 128, 3, 3])\n",
      "net.global_context.context.context5_1.0.bias torch.Size([128])\n",
      "net.global_context.context.context5_2.0.weight torch.Size([128, 128, 3, 3])\n",
      "net.global_context.context.context5_2.0.bias torch.Size([128])\n",
      "net.global_context.context.context5_3.0.weight torch.Size([128, 128, 3, 3])\n",
      "net.global_context.context.context5_3.0.bias torch.Size([128])\n",
      "net.global_context.context.context5_4.0.weight torch.Size([128, 128, 3, 3])\n",
      "net.global_context.context.context5_4.0.bias torch.Size([128])\n",
      "net.global_context.context.squeeze2.0.weight torch.Size([64, 128, 1, 1])\n",
      "net.global_context.context.squeeze2.0.bias torch.Size([64])\n",
      "net.global_regressor.regressor.fc1_trans.0.weight torch.Size([4096, 6400])\n",
      "net.global_regressor.regressor.fc1_trans.0.bias torch.Size([4096])\n",
      "net.global_regressor.regressor.fc2_trans.0.weight torch.Size([4096, 4096])\n",
      "net.global_regressor.regressor.fc2_trans.0.bias torch.Size([4096])\n",
      "net.global_regressor.regressor.fc3_trans.0.weight torch.Size([128, 4096])\n",
      "net.global_regressor.regressor.fc3_trans.0.bias torch.Size([128])\n",
      "net.global_regressor.regressor.logits_t.weight torch.Size([3, 128])\n",
      "net.global_regressor.regressor.logits_t.bias torch.Size([3])\n",
      "net.global_regressor.regressor.fc1_rot.0.weight torch.Size([4096, 6400])\n",
      "net.global_regressor.regressor.fc1_rot.0.bias torch.Size([4096])\n",
      "net.global_regressor.regressor.fc2_rot.0.weight torch.Size([4096, 4096])\n",
      "net.global_regressor.regressor.fc2_rot.0.bias torch.Size([4096])\n",
      "net.global_regressor.regressor.fc3_rot.0.weight torch.Size([128, 4096])\n",
      "net.global_regressor.regressor.fc3_rot.0.bias torch.Size([128])\n",
      "net.global_regressor.regressor.logits_r.weight torch.Size([4, 128])\n",
      "net.global_regressor.regressor.logits_r.bias torch.Size([4])\n",
      "gp.variational_strategy.base_variational_strategy.inducing_points torch.Size([3, 300, 128])\n",
      "gp.variational_strategy.base_variational_strategy._variational_distribution.variational_mean torch.Size([3, 300])\n",
      "gp.variational_strategy.base_variational_strategy._variational_distribution.chol_variational_covar torch.Size([3, 300, 300])\n",
      "gp.mean_module.constant torch.Size([1, 1])\n",
      "gp.covar_module.raw_outputscale torch.Size([1])\n",
      "gp.covar_module.base_kernel.raw_lengthscale torch.Size([1, 1, 1])\n",
      "likelihood.raw_noise torch.Size([1])\n",
      "likelihood.noise_covar.raw_noise torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "# Disable resnet\n",
    "for param in model.net.resnet.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "#for param in model.net.parameters():\n",
    "#    param.requires_grad = False\n",
    "    \n",
    "# Display Learn parameters\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print (name, param.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T07:46:31.366653Z",
     "start_time": "2020-06-27T07:46:31.359881Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "args.norm_mean = args.norm_mean.to(device)\n",
    "args.norm_std = args.norm_std.to(device)\n",
    "\n",
    "optimizer = optim.Adam([\n",
    "    {'params': model.gp.parameters(), \\\n",
    "     'lr': args.learning_rate,'weight_decay':args.weight_decay},\n",
    "    {'params': model.likelihood.parameters(), \\\n",
    "     'lr': args.learning_rate,'weight_decay':args.weight_decay},\n",
    "    {'params': model.net.global_regressor.parameters(), \\\n",
    "     'lr': args.learning_rate * 0.1,'weight_decay':args.weight_decay},\n",
    "    {'params': model.net.global_context.parameters(), \\\n",
    "     'lr': args.learning_rate * 0.01,'weight_decay':args.weight_decay},\n",
    "])\n",
    "'''\n",
    "optimizer = optim.Adam([\n",
    "    {'params': model.gp.parameters(), \\\n",
    "     'lr': args.learning_rate,'weight_decay':args.weight_decay},\n",
    "    {'params': model.likelihood.parameters(), \\\n",
    "     'lr': args.learning_rate,'weight_decay':args.weight_decay},\n",
    "])\n",
    "'''\n",
    "scheduler = optim.lr_scheduler.LambdaLR(optimizer=optimizer, lr_lambda=lambda epoch: args.decay_rate**epoch)\n",
    "#mll = gpytorch.mlls.VariationalELBO(model.likelihood, model.gp, num_data=len(dataset.Targets))\n",
    "mll = gpytorch.mlls.PredictiveLogLikelihood(model.likelihood, model.gp, num_data=len(dataset.Targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T07:46:31.374168Z",
     "start_time": "2020-06-27T07:46:31.368081Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN model parameters: 860864\n",
      "Regressor model parameters: 87049351\n",
      "GP model parameters: 386103\n",
      "Likelihood parameters: 4\n"
     ]
    }
   ],
   "source": [
    "print('CNN model parameters:', sum(param.numel() for param in model.net.global_context.parameters()))\n",
    "print('Regressor model parameters:', sum(param.numel() for param in model.net.global_regressor.parameters()))\n",
    "print('GP model parameters:', sum(param.numel() for param in model.gp.parameters()))\n",
    "print('Likelihood parameters:', sum(param.numel() for param in model.likelihood.parameters()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T07:48:29.783959Z",
     "start_time": "2020-06-27T07:48:29.769982Z"
    },
    "code_folding": [],
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "def train(e):\n",
    "    train_loss = 0.\n",
    "    with gpytorch.settings.num_likelihood_samples(100):\n",
    "        for b, data in enumerate(dataloader, 0):\n",
    "            start = time.time()\n",
    "            with torch.no_grad():\n",
    "                x,y = data.values()\n",
    "                x,y = x.to(device),y.to(device)\n",
    "                # normalize targets\n",
    "                y = normalize(y,args.norm_mean, args.norm_std)\n",
    "                trans_target, rot_target = torch.split(y, [3, 4], dim=1)\n",
    "                \n",
    "            optimizer.zero_grad()\n",
    "            output,rot_pred = model(x)\n",
    "            trans_loss = -mll(output, trans_target)\n",
    "            rot_loss = 1. - torch.mean(torch.square(torch.sum(torch.mul(rot_pred,rot_target),dim=1)))\n",
    "            total_loss = trans_loss + args.lamda_weights * rot_loss\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            end = time.time()\n",
    "            with torch.no_grad():\n",
    "                train_loss += float(total_loss)\n",
    "                lr = scheduler.get_last_lr()[0]\n",
    "                writer.add_scalars('training loss',\n",
    "                  {'item loss':float(total_loss),\n",
    "                  'batch loss':train_loss/(b+1)},\n",
    "                  e * len(dataloader) + (b+1))\n",
    "                if ((b+1)%args.display == 0):\n",
    "                     print(\n",
    "                        \"{}/{} (epoch {}), train_loss = {}, time/batch = {:.3f}, learning rate = {:.9f}\"\n",
    "                        .format(\n",
    "                        e * len(dataloader) + (b+1),\n",
    "                        args.num_epochs * len(dataloader),\n",
    "                        e,\n",
    "                        train_loss/(b+1),\n",
    "                        end - start,\n",
    "                        lr)) # scheduler.get_last_lr()[0]\n",
    "                if (e * len(dataloader) + (b+1)) % args.save_every == 0:\n",
    "                    checkpoint_path = os.path.join(args.model_dir, 'model-{}-{}.pth'.format(e, e * len(dataloader) + (b+1)))\n",
    "                    torch.save(model.state_dict(),checkpoint_path)\n",
    "                    print('saving model to model-{}-{}.pth'.format(e, e * len(dataloader) + (b+1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T07:48:30.508786Z",
     "start_time": "2020-06-27T07:48:30.485600Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultitaskGaussianLikelihood(\n",
       "  (noise_covar): MultitaskHomoskedasticNoise(\n",
       "    (raw_noise_constraint): GreaterThan(1.000E-04)\n",
       "  )\n",
       "  (raw_noise_constraint): GreaterThan(1.000E-04)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.net.resnet.eval()\n",
    "model.net.global_context.train()\n",
    "model.net.global_regressor.train()\n",
    "model.gp.train()\n",
    "model.likelihood.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-27T07:48:46.914287Z",
     "start_time": "2020-06-27T07:48:31.410247Z"
    },
    "run_control": {
     "marked": true
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([300, 3])\n",
      "torch.Size([300, 3])\n",
      "torch.Size([300, 3])\n",
      "torch.Size([300, 3])\n",
      "torch.Size([300, 3])\n",
      "torch.Size([300, 3])\n",
      "torch.Size([300, 3])\n",
      "torch.Size([300, 3])\n",
      "torch.Size([300, 3])\n",
      "torch.Size([300, 3])\n",
      "torch.Size([300, 3])\n",
      "torch.Size([300, 3])\n",
      "torch.Size([300, 3])\n",
      "torch.Size([300, 3])\n",
      "torch.Size([300, 3])\n",
      "torch.Size([300, 3])\n",
      "torch.Size([300, 3])\n",
      "torch.Size([300, 3])\n"
     ]
    }
   ],
   "source": [
    "#for e in range(args.num_epochs):\n",
    "for e in range(1):\n",
    "    train(e)\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "nbTranslate": {
   "displayLangs": [
    "en"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
