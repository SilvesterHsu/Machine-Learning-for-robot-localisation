{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-25T19:49:24.467509Z",
     "start_time": "2020-07-25T19:49:22.817452Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "the rosdep view is empty: call 'sudo rosdep init' and 'rosdep update'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import gpytorch\n",
    "import argparse\n",
    "import time\n",
    "import pickle\n",
    "import scipy.io as sio\n",
    "\n",
    "from torch.distributions import Normal\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "import roslib\n",
    "import rospy\n",
    "import tf as tf_ros\n",
    "from nav_msgs.msg import Odometry, Path\n",
    "from sensor_msgs.msg import Image\n",
    "from cv_bridge import CvBridge\n",
    "from geometry_msgs.msg import PoseStamped, PoseArray, Pose\n",
    "import math\n",
    "import cv2\n",
    "import copy\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-25T19:49:24.886206Z",
     "start_time": "2020-07-25T19:49:24.469578Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ List Devices ------------\n",
      "Device 0 :\n",
      "GeForce RTX 2060\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n",
      "\n",
      "Device 1 :\n",
      "TITAN Xp\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from torchlib.utils import list_device,set_device\n",
    "\n",
    "list_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set torch default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-25T19:49:24.891124Z",
     "start_time": "2020-07-25T19:49:24.887733Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Device 1 : TITAN Xp\n"
     ]
    }
   ],
   "source": [
    "set_device(1)\n",
    "torch.set_default_dtype(torch.float32)\n",
    "torch.set_printoptions(precision=4)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.set_printoptions(sci_mode=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-25T19:49:24.901171Z",
     "start_time": "2020-07-25T19:49:24.892452Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--batch_size', type=int, default=300, help='size of mini batch')\n",
    "parser.add_argument('--is_normalization', type=bool, default=True, help='whether do data normalization')\n",
    "parser.add_argument('--target_image_size', default=[300, 300], nargs=2, type=int, help='Input images will be resized to this for data argumentation.')\n",
    "parser.add_argument('--output_dim', default=3, type=int, help='output dimention.')\n",
    "parser.add_argument('--feat_dim', default=128, type=int, help='feature dimention.')\n",
    "parser.add_argument('--model_dir', type=str, default='/notebooks/global_localization/gps_net_torch', help='rnn, gru, or lstm')\n",
    "\n",
    "parser.add_argument('--test_dataset', type=str, default=[# '/notebooks/michigan_nn_data/2012_01_08',\n",
    "                                                         # '/notebooks/michigan_nn_data/2012_01_15',\n",
    "                                                         # '/notebooks/michigan_nn_data/2012_01_22',\n",
    "                                                         # '/notebooks/michigan_nn_data/2012_02_02',\n",
    "                                                         # '/notebooks/michigan_nn_data/2012_02_04',\n",
    "                                                         # '/notebooks/michigan_nn_data/2012_02_05',\n",
    "                                                         '/notebooks/michigan_nn_data/2012_02_12',\n",
    "                                                         # '/notebooks/michigan_nn_data/2012_03_31',\n",
    "                                                         '/notebooks/michigan_nn_data/2012_04_29',\n",
    "                                                         '/notebooks/michigan_nn_data/2012_05_11',\n",
    "                                                         '/notebooks/michigan_nn_data/2012_06_15',\n",
    "                                                         '/notebooks/michigan_nn_data/2012_08_04',\n",
    "                                                         # '/notebooks/michigan_nn_data/2012_09_28'])\n",
    "                                                         '/notebooks/michigan_nn_data/2012_10_28',\n",
    "                                                         '/notebooks/michigan_nn_data/2012_11_16',\n",
    "                                                         '/notebooks/michigan_nn_data/2012_12_01'\n",
    "                                                        ] )\n",
    "\n",
    "parser.add_argument('--train_dataset', type=str, default = ['/notebooks/michigan_nn_data/test'])\n",
    "parser.add_argument('--norm_tensor', type=str, default = ['/notebooks/global_localization/norm_mean_std.pt'])\n",
    "\n",
    "#parser.add_argument('--map_dataset', type=str, default='/home/kevin/data/michigan_gt/training')\n",
    "parser.add_argument('--enable_ros', type=bool, default=False, help='put data into ros')\n",
    "\n",
    "sys.argv = ['']\n",
    "args = parser.parse_args()\n",
    "\n",
    "if args.enable_ros:\n",
    "    rospy.init_node('global_localization_tf_broadcaster_cnn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-25T19:51:24.382185Z",
     "start_time": "2020-07-25T19:49:24.902372Z"
    },
    "run_control": {
     "marked": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14301/14301 [00:18<00:00, 772.87it/s]\n",
      "100%|██████████| 7008/7008 [00:09<00:00, 763.50it/s]\n",
      "100%|██████████| 12852/12852 [00:16<00:00, 775.46it/s]\n",
      "100%|██████████| 9567/9567 [00:12<00:00, 769.09it/s]\n",
      "100%|██████████| 13580/13580 [00:17<00:00, 783.12it/s]\n",
      "100%|██████████| 14835/14835 [00:19<00:00, 777.18it/s]\n",
      "100%|██████████| 7114/7114 [00:09<00:00, 764.64it/s]\n",
      "100%|██████████| 12683/12683 [00:16<00:00, 764.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load norm and std: /notebooks/global_localization/norm_mean_std.pt\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import tf.transformations as tf_tran\n",
    "from tqdm import tqdm\n",
    "#from PIL import Image\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchlib import resnet, vggnet, cnn_auxiliary\n",
    "from torchlib.cnn_auxiliary import normalize, denormalize, denormalize_navie, get_relative_pose, translational_rotational_loss\n",
    "from torchlib.utils import LocalizationDataset, display_loss, data2tensorboard\n",
    "import time\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "dataset = LocalizationDataset(dataset_dirs = args.test_dataset, \\\n",
    "                              image_size = args.target_image_size, \\\n",
    "                              transform = transform,\n",
    "                              get_pair = False, mode='evaluate')\n",
    "if len(args.train_dataset)>7:\n",
    "    [args.norm_mean, args.norm_std] = [torch.tensor(x) for x in dataset.get_norm()]\n",
    "    torch.save([args.norm_mean, args.norm_std], *args.norm_tensor)\n",
    "    print('Save norm and std:',*args.norm_tensor)\n",
    "else:\n",
    "    [args.norm_mean, args.norm_std] = torch.load(*args.norm_tensor)\n",
    "    print('Load norm and std:',*args.norm_tensor)\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=args.batch_size, \\\n",
    "                        shuffle=False, num_workers=0, \\\n",
    "                        drop_last=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-25T19:51:24.485520Z",
     "start_time": "2020-07-25T19:51:24.407828Z"
    },
    "code_folding": [
     0,
     8,
     19,
     40,
     56
    ],
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "class Backbone(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.resnet = resnet.resnet50(pretrained=True)\n",
    "    def forward(self,input_data):\n",
    "        dense_feat = self.resnet(input_data)\n",
    "        return dense_feat\n",
    "    \n",
    "class NN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.global_context = vggnet.vggnet(input_channel=2048,opt=\"context\")\n",
    "        self.global_regressor = vggnet.vggnet(opt=\"regressor\")\n",
    "        \n",
    "    def forward(self,input_data):\n",
    "        context_feat = self.global_context(input_data)\n",
    "        output,feature_t, feature_r = self.global_regressor(context_feat)\n",
    "        return output, feature_t, feature_r\n",
    "\n",
    "class GP(gpytorch.models.ApproximateGP):\n",
    "    def __init__(self, inducing_points, output_dim=3):\n",
    "        variational_distribution = gpytorch.variational.CholeskyVariationalDistribution(\n",
    "            inducing_points.size(-2), batch_shape=torch.Size([output_dim])\n",
    "        )\n",
    "        variational_strategy = gpytorch.variational.MultitaskVariationalStrategy(\n",
    "            gpytorch.variational.VariationalStrategy(\n",
    "                self, inducing_points, variational_distribution, learn_inducing_locations=True\n",
    "            ), num_tasks=output_dim\n",
    "        )\n",
    "        super().__init__(variational_strategy)\n",
    "        self.mean_module = gpytorch.means.ConstantMean(batch_shape=torch.Size([output_dim]))\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(\n",
    "            gpytorch.kernels.RBFKernel(batch_shape=torch.Size([output_dim])),\n",
    "            batch_shape=torch.Size([output_dim]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "class GPNode(nn.Module):\n",
    "    def __init__(self,inducing_points, seed):\n",
    "        super().__init__()\n",
    "        output_dim = inducing_points.shape[0]\n",
    "        sub_feat_dim = inducing_points.shape[-1]\n",
    "        torch.manual_seed(seed)\n",
    "        \n",
    "        #self.feat_index = torch.randint(high=args.feat_dim, size=(sub_feat_dim,))\n",
    "        self.feat_index = torch.randperm(args.feat_dim)[:sub_feat_dim]\n",
    "        self.gp = GP(inducing_points)\n",
    "        self.likelihood = gpytorch.likelihoods.MultitaskGaussianLikelihood(num_tasks=output_dim) \n",
    "        \n",
    "    def forward(self,input_data):\n",
    "        output = self.gp(input_data)\n",
    "        return output\n",
    "    \n",
    "class Model(nn.Module):\n",
    "    def __init__(self,gp_args):\n",
    "        super().__init__()\n",
    "        self.backbone = Backbone()\n",
    "        self.nn = NN()\n",
    "        self.gps = nn.ModuleList()\n",
    "        \n",
    "        self.num_gp = gp_args['num_gp']\n",
    "        #self.sub_batch_rate = gp_args['sub_rate']\n",
    "        self.sub_feat_rate = gp_args['feat_rate']\n",
    "        #self.sub_batch_size = int(args.batch_size*self.sub_batch_rate)\n",
    "        self.sub_feat_dim = int(args.feat_dim*self.sub_feat_rate)\n",
    "        \n",
    "        for i in range(self.num_gp):\n",
    "            #inducing_points = torch.zeros(args.output_dim, self.sub_batch_size, self.sub_feat_dim)\n",
    "            inducing_points = torch.zeros(args.output_dim, args.batch_size, self.sub_feat_dim)\n",
    "            # use i as seed to fix sub features\n",
    "            gp = GPNode(inducing_points,seed=i)\n",
    "            self.gps.append(gp)\n",
    "        \n",
    "    def forward_nn(self, input_data):\n",
    "        dense_feat = self.backbone(input_data)\n",
    "        output, feature_t, feature_r = self.nn(dense_feat)\n",
    "        rot_pred = torch.split(output, [3, 4], dim=1)[1] # 4-dimention            \n",
    "        return feature_t, rot_pred\n",
    "    \n",
    "    def forward_gp(self,gp,trans_feat):\n",
    "        sub_trans_feat = trans_feat[:,gp.feat_index]\n",
    "        trans_pred = gp(sub_trans_feat)\n",
    "        return trans_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-25T19:51:30.030075Z",
     "start_time": "2020-07-25T19:51:24.487681Z"
    },
    "code_folding": [
     0,
     1,
     15,
     38,
     55,
     60,
     83,
     121,
     125,
     140,
     146,
     151
    ],
    "run_control": {
     "marked": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters layer: 546\n",
      "Model Structure:\n",
      "backbone.resnet.conv1.weight torch.Size([64, 1, 7, 7])\n",
      "backbone.resnet.bn1.weight torch.Size([64])\n",
      "backbone.resnet.bn1.bias torch.Size([64])\n",
      "backbone.resnet.layer1.0.conv1.weight torch.Size([64, 64, 1, 1])\n",
      "backbone.resnet.layer1.0.bn1.weight torch.Size([64])\n",
      "backbone.resnet.layer1.0.bn1.bias torch.Size([64])\n",
      "backbone.resnet.layer1.0.conv2.weight torch.Size([64, 64, 3, 3])\n",
      "backbone.resnet.layer1.0.bn2.weight torch.Size([64])\n",
      "backbone.resnet.layer1.0.bn2.bias torch.Size([64])\n",
      "backbone.resnet.layer1.0.conv3.weight torch.Size([256, 64, 1, 1])\n",
      "backbone.resnet.layer1.0.bn3.weight torch.Size([256])\n",
      "backbone.resnet.layer1.0.bn3.bias torch.Size([256])\n",
      "backbone.resnet.layer1.0.downsample.0.weight torch.Size([256, 64, 1, 1])\n",
      "backbone.resnet.layer1.0.downsample.1.weight torch.Size([256])\n",
      "backbone.resnet.layer1.0.downsample.1.bias torch.Size([256])\n",
      "backbone.resnet.layer1.1.conv1.weight torch.Size([64, 256, 1, 1])\n",
      "backbone.resnet.layer1.1.bn1.weight torch.Size([64])\n",
      "backbone.resnet.layer1.1.bn1.bias torch.Size([64])\n",
      "backbone.resnet.layer1.1.conv2.weight torch.Size([64, 64, 3, 3])\n",
      "backbone.resnet.layer1.1.bn2.weight torch.Size([64])\n",
      "backbone.resnet.layer1.1.bn2.bias torch.Size([64])\n",
      "backbone.resnet.layer1.1.conv3.weight torch.Size([256, 64, 1, 1])\n",
      "backbone.resnet.layer1.1.bn3.weight torch.Size([256])\n",
      "backbone.resnet.layer1.1.bn3.bias torch.Size([256])\n",
      "backbone.resnet.layer1.2.conv1.weight torch.Size([64, 256, 1, 1])\n",
      "backbone.resnet.layer1.2.bn1.weight torch.Size([64])\n",
      "backbone.resnet.layer1.2.bn1.bias torch.Size([64])\n",
      "backbone.resnet.layer1.2.conv2.weight torch.Size([64, 64, 3, 3])\n",
      "backbone.resnet.layer1.2.bn2.weight torch.Size([64])\n",
      "backbone.resnet.layer1.2.bn2.bias torch.Size([64])\n",
      "backbone.resnet.layer1.2.conv3.weight torch.Size([256, 64, 1, 1])\n",
      "backbone.resnet.layer1.2.bn3.weight torch.Size([256])\n",
      "backbone.resnet.layer1.2.bn3.bias torch.Size([256])\n",
      "backbone.resnet.layer2.0.conv1.weight torch.Size([128, 256, 1, 1])\n",
      "backbone.resnet.layer2.0.bn1.weight torch.Size([128])\n",
      "backbone.resnet.layer2.0.bn1.bias torch.Size([128])\n",
      "backbone.resnet.layer2.0.conv2.weight torch.Size([128, 128, 3, 3])\n",
      "backbone.resnet.layer2.0.bn2.weight torch.Size([128])\n",
      "backbone.resnet.layer2.0.bn2.bias torch.Size([128])\n",
      "backbone.resnet.layer2.0.conv3.weight torch.Size([512, 128, 1, 1])\n",
      "backbone.resnet.layer2.0.bn3.weight torch.Size([512])\n",
      "backbone.resnet.layer2.0.bn3.bias torch.Size([512])\n",
      "backbone.resnet.layer2.0.downsample.0.weight torch.Size([512, 256, 1, 1])\n",
      "backbone.resnet.layer2.0.downsample.1.weight torch.Size([512])\n",
      "backbone.resnet.layer2.0.downsample.1.bias torch.Size([512])\n",
      "backbone.resnet.layer2.1.conv1.weight torch.Size([128, 512, 1, 1])\n",
      "backbone.resnet.layer2.1.bn1.weight torch.Size([128])\n",
      "backbone.resnet.layer2.1.bn1.bias torch.Size([128])\n",
      "backbone.resnet.layer2.1.conv2.weight torch.Size([128, 128, 3, 3])\n",
      "backbone.resnet.layer2.1.bn2.weight torch.Size([128])\n",
      "backbone.resnet.layer2.1.bn2.bias torch.Size([128])\n",
      "backbone.resnet.layer2.1.conv3.weight torch.Size([512, 128, 1, 1])\n",
      "backbone.resnet.layer2.1.bn3.weight torch.Size([512])\n",
      "backbone.resnet.layer2.1.bn3.bias torch.Size([512])\n",
      "backbone.resnet.layer2.2.conv1.weight torch.Size([128, 512, 1, 1])\n",
      "backbone.resnet.layer2.2.bn1.weight torch.Size([128])\n",
      "backbone.resnet.layer2.2.bn1.bias torch.Size([128])\n",
      "backbone.resnet.layer2.2.conv2.weight torch.Size([128, 128, 3, 3])\n",
      "backbone.resnet.layer2.2.bn2.weight torch.Size([128])\n",
      "backbone.resnet.layer2.2.bn2.bias torch.Size([128])\n",
      "backbone.resnet.layer2.2.conv3.weight torch.Size([512, 128, 1, 1])\n",
      "backbone.resnet.layer2.2.bn3.weight torch.Size([512])\n",
      "backbone.resnet.layer2.2.bn3.bias torch.Size([512])\n",
      "backbone.resnet.layer2.3.conv1.weight torch.Size([128, 512, 1, 1])\n",
      "backbone.resnet.layer2.3.bn1.weight torch.Size([128])\n",
      "backbone.resnet.layer2.3.bn1.bias torch.Size([128])\n",
      "backbone.resnet.layer2.3.conv2.weight torch.Size([128, 128, 3, 3])\n",
      "backbone.resnet.layer2.3.bn2.weight torch.Size([128])\n",
      "backbone.resnet.layer2.3.bn2.bias torch.Size([128])\n",
      "backbone.resnet.layer2.3.conv3.weight torch.Size([512, 128, 1, 1])\n",
      "backbone.resnet.layer2.3.bn3.weight torch.Size([512])\n",
      "backbone.resnet.layer2.3.bn3.bias torch.Size([512])\n",
      "backbone.resnet.layer3.0.conv1.weight torch.Size([256, 512, 1, 1])\n",
      "backbone.resnet.layer3.0.bn1.weight torch.Size([256])\n",
      "backbone.resnet.layer3.0.bn1.bias torch.Size([256])\n",
      "backbone.resnet.layer3.0.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "backbone.resnet.layer3.0.bn2.weight torch.Size([256])\n",
      "backbone.resnet.layer3.0.bn2.bias torch.Size([256])\n",
      "backbone.resnet.layer3.0.conv3.weight torch.Size([1024, 256, 1, 1])\n",
      "backbone.resnet.layer3.0.bn3.weight torch.Size([1024])\n",
      "backbone.resnet.layer3.0.bn3.bias torch.Size([1024])\n",
      "backbone.resnet.layer3.0.downsample.0.weight torch.Size([1024, 512, 1, 1])\n",
      "backbone.resnet.layer3.0.downsample.1.weight torch.Size([1024])\n",
      "backbone.resnet.layer3.0.downsample.1.bias torch.Size([1024])\n",
      "backbone.resnet.layer3.1.conv1.weight torch.Size([256, 1024, 1, 1])\n",
      "backbone.resnet.layer3.1.bn1.weight torch.Size([256])\n",
      "backbone.resnet.layer3.1.bn1.bias torch.Size([256])\n",
      "backbone.resnet.layer3.1.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "backbone.resnet.layer3.1.bn2.weight torch.Size([256])\n",
      "backbone.resnet.layer3.1.bn2.bias torch.Size([256])\n",
      "backbone.resnet.layer3.1.conv3.weight torch.Size([1024, 256, 1, 1])\n",
      "backbone.resnet.layer3.1.bn3.weight torch.Size([1024])\n",
      "backbone.resnet.layer3.1.bn3.bias torch.Size([1024])\n",
      "backbone.resnet.layer3.2.conv1.weight torch.Size([256, 1024, 1, 1])\n",
      "backbone.resnet.layer3.2.bn1.weight torch.Size([256])\n",
      "backbone.resnet.layer3.2.bn1.bias torch.Size([256])\n",
      "backbone.resnet.layer3.2.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "backbone.resnet.layer3.2.bn2.weight torch.Size([256])\n",
      "backbone.resnet.layer3.2.bn2.bias torch.Size([256])\n",
      "backbone.resnet.layer3.2.conv3.weight torch.Size([1024, 256, 1, 1])\n",
      "backbone.resnet.layer3.2.bn3.weight torch.Size([1024])\n",
      "backbone.resnet.layer3.2.bn3.bias torch.Size([1024])\n",
      "backbone.resnet.layer3.3.conv1.weight torch.Size([256, 1024, 1, 1])\n",
      "backbone.resnet.layer3.3.bn1.weight torch.Size([256])\n",
      "backbone.resnet.layer3.3.bn1.bias torch.Size([256])\n",
      "backbone.resnet.layer3.3.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "backbone.resnet.layer3.3.bn2.weight torch.Size([256])\n",
      "backbone.resnet.layer3.3.bn2.bias torch.Size([256])\n",
      "backbone.resnet.layer3.3.conv3.weight torch.Size([1024, 256, 1, 1])\n",
      "backbone.resnet.layer3.3.bn3.weight torch.Size([1024])\n",
      "backbone.resnet.layer3.3.bn3.bias torch.Size([1024])\n",
      "backbone.resnet.layer3.4.conv1.weight torch.Size([256, 1024, 1, 1])\n",
      "backbone.resnet.layer3.4.bn1.weight torch.Size([256])\n",
      "backbone.resnet.layer3.4.bn1.bias torch.Size([256])\n",
      "backbone.resnet.layer3.4.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "backbone.resnet.layer3.4.bn2.weight torch.Size([256])\n",
      "backbone.resnet.layer3.4.bn2.bias torch.Size([256])\n",
      "backbone.resnet.layer3.4.conv3.weight torch.Size([1024, 256, 1, 1])\n",
      "backbone.resnet.layer3.4.bn3.weight torch.Size([1024])\n",
      "backbone.resnet.layer3.4.bn3.bias torch.Size([1024])\n",
      "backbone.resnet.layer3.5.conv1.weight torch.Size([256, 1024, 1, 1])\n",
      "backbone.resnet.layer3.5.bn1.weight torch.Size([256])\n",
      "backbone.resnet.layer3.5.bn1.bias torch.Size([256])\n",
      "backbone.resnet.layer3.5.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "backbone.resnet.layer3.5.bn2.weight torch.Size([256])\n",
      "backbone.resnet.layer3.5.bn2.bias torch.Size([256])\n",
      "backbone.resnet.layer3.5.conv3.weight torch.Size([1024, 256, 1, 1])\n",
      "backbone.resnet.layer3.5.bn3.weight torch.Size([1024])\n",
      "backbone.resnet.layer3.5.bn3.bias torch.Size([1024])\n",
      "backbone.resnet.layer4.0.conv1.weight torch.Size([512, 1024, 1, 1])\n",
      "backbone.resnet.layer4.0.bn1.weight torch.Size([512])\n",
      "backbone.resnet.layer4.0.bn1.bias torch.Size([512])\n",
      "backbone.resnet.layer4.0.conv2.weight torch.Size([512, 512, 3, 3])\n",
      "backbone.resnet.layer4.0.bn2.weight torch.Size([512])\n",
      "backbone.resnet.layer4.0.bn2.bias torch.Size([512])\n",
      "backbone.resnet.layer4.0.conv3.weight torch.Size([2048, 512, 1, 1])\n",
      "backbone.resnet.layer4.0.bn3.weight torch.Size([2048])\n",
      "backbone.resnet.layer4.0.bn3.bias torch.Size([2048])\n",
      "backbone.resnet.layer4.0.downsample.0.weight torch.Size([2048, 1024, 1, 1])\n",
      "backbone.resnet.layer4.0.downsample.1.weight torch.Size([2048])\n",
      "backbone.resnet.layer4.0.downsample.1.bias torch.Size([2048])\n",
      "backbone.resnet.layer4.1.conv1.weight torch.Size([512, 2048, 1, 1])\n",
      "backbone.resnet.layer4.1.bn1.weight torch.Size([512])\n",
      "backbone.resnet.layer4.1.bn1.bias torch.Size([512])\n",
      "backbone.resnet.layer4.1.conv2.weight torch.Size([512, 512, 3, 3])\n",
      "backbone.resnet.layer4.1.bn2.weight torch.Size([512])\n",
      "backbone.resnet.layer4.1.bn2.bias torch.Size([512])\n",
      "backbone.resnet.layer4.1.conv3.weight torch.Size([2048, 512, 1, 1])\n",
      "backbone.resnet.layer4.1.bn3.weight torch.Size([2048])\n",
      "backbone.resnet.layer4.1.bn3.bias torch.Size([2048])\n",
      "backbone.resnet.layer4.2.conv1.weight torch.Size([512, 2048, 1, 1])\n",
      "backbone.resnet.layer4.2.bn1.weight torch.Size([512])\n",
      "backbone.resnet.layer4.2.bn1.bias torch.Size([512])\n",
      "backbone.resnet.layer4.2.conv2.weight torch.Size([512, 512, 3, 3])\n",
      "backbone.resnet.layer4.2.bn2.weight torch.Size([512])\n",
      "backbone.resnet.layer4.2.bn2.bias torch.Size([512])\n",
      "backbone.resnet.layer4.2.conv3.weight torch.Size([2048, 512, 1, 1])\n",
      "backbone.resnet.layer4.2.bn3.weight torch.Size([2048])\n",
      "backbone.resnet.layer4.2.bn3.bias torch.Size([2048])\n",
      "nn.global_context.context.squeeze.0.weight torch.Size([128, 2048, 1, 1])\n",
      "nn.global_context.context.squeeze.0.bias torch.Size([128])\n",
      "nn.global_context.context.context5_1.0.weight torch.Size([128, 128, 3, 3])\n",
      "nn.global_context.context.context5_1.0.bias torch.Size([128])\n",
      "nn.global_context.context.context5_2.0.weight torch.Size([128, 128, 3, 3])\n",
      "nn.global_context.context.context5_2.0.bias torch.Size([128])\n",
      "nn.global_context.context.context5_3.0.weight torch.Size([128, 128, 3, 3])\n",
      "nn.global_context.context.context5_3.0.bias torch.Size([128])\n",
      "nn.global_context.context.context5_4.0.weight torch.Size([128, 128, 3, 3])\n",
      "nn.global_context.context.context5_4.0.bias torch.Size([128])\n",
      "nn.global_context.context.squeeze2.0.weight torch.Size([64, 128, 1, 1])\n",
      "nn.global_context.context.squeeze2.0.bias torch.Size([64])\n",
      "nn.global_regressor.regressor.fc1_trans.0.weight torch.Size([4096, 6400])\n",
      "nn.global_regressor.regressor.fc1_trans.0.bias torch.Size([4096])\n",
      "nn.global_regressor.regressor.fc2_trans.0.weight torch.Size([4096, 4096])\n",
      "nn.global_regressor.regressor.fc2_trans.0.bias torch.Size([4096])\n",
      "nn.global_regressor.regressor.fc3_trans.0.weight torch.Size([128, 4096])\n",
      "nn.global_regressor.regressor.fc3_trans.0.bias torch.Size([128])\n",
      "nn.global_regressor.regressor.logits_t.weight torch.Size([3, 128])\n",
      "nn.global_regressor.regressor.logits_t.bias torch.Size([3])\n",
      "nn.global_regressor.regressor.fc1_rot.0.weight torch.Size([4096, 6400])\n",
      "nn.global_regressor.regressor.fc1_rot.0.bias torch.Size([4096])\n",
      "nn.global_regressor.regressor.fc2_rot.0.weight torch.Size([4096, 4096])\n",
      "nn.global_regressor.regressor.fc2_rot.0.bias torch.Size([4096])\n",
      "nn.global_regressor.regressor.fc3_rot.0.weight torch.Size([128, 4096])\n",
      "nn.global_regressor.regressor.fc3_rot.0.bias torch.Size([128])\n",
      "nn.global_regressor.regressor.logits_r.weight torch.Size([4, 128])\n",
      "nn.global_regressor.regressor.logits_r.bias torch.Size([4])\n",
      "gps.0.gp.variational_strategy.base_variational_strategy.inducing_points torch.Size([3, 300, 85])\n",
      "gps.0.gp.variational_strategy.base_variational_strategy._variational_distribution.variational_mean torch.Size([3, 300])\n",
      "gps.0.gp.variational_strategy.base_variational_strategy._variational_distribution.chol_variational_covar torch.Size([3, 300, 300])\n",
      "gps.0.gp.mean_module.constant torch.Size([3, 1])\n",
      "gps.0.gp.covar_module.raw_outputscale torch.Size([3])\n",
      "gps.0.gp.covar_module.base_kernel.raw_lengthscale torch.Size([3, 1, 1])\n",
      "gps.0.likelihood.raw_noise torch.Size([1])\n",
      "gps.0.likelihood.noise_covar.raw_noise torch.Size([3])\n",
      "gps.1.gp.variational_strategy.base_variational_strategy.inducing_points torch.Size([3, 300, 85])\n",
      "gps.1.gp.variational_strategy.base_variational_strategy._variational_distribution.variational_mean torch.Size([3, 300])\n",
      "gps.1.gp.variational_strategy.base_variational_strategy._variational_distribution.chol_variational_covar torch.Size([3, 300, 300])\n",
      "gps.1.gp.mean_module.constant torch.Size([3, 1])\n",
      "gps.1.gp.covar_module.raw_outputscale torch.Size([3])\n",
      "gps.1.gp.covar_module.base_kernel.raw_lengthscale torch.Size([3, 1, 1])\n",
      "gps.1.likelihood.raw_noise torch.Size([1])\n",
      "gps.1.likelihood.noise_covar.raw_noise torch.Size([3])\n",
      "gps.2.gp.variational_strategy.base_variational_strategy.inducing_points torch.Size([3, 300, 85])\n",
      "gps.2.gp.variational_strategy.base_variational_strategy._variational_distribution.variational_mean torch.Size([3, 300])\n",
      "gps.2.gp.variational_strategy.base_variational_strategy._variational_distribution.chol_variational_covar torch.Size([3, 300, 300])\n",
      "gps.2.gp.mean_module.constant torch.Size([3, 1])\n",
      "gps.2.gp.covar_module.raw_outputscale torch.Size([3])\n",
      "gps.2.gp.covar_module.base_kernel.raw_lengthscale torch.Size([3, 1, 1])\n",
      "gps.2.likelihood.raw_noise torch.Size([1])\n",
      "gps.2.likelihood.noise_covar.raw_noise torch.Size([3])\n",
      "gps.3.gp.variational_strategy.base_variational_strategy.inducing_points torch.Size([3, 300, 85])\n",
      "gps.3.gp.variational_strategy.base_variational_strategy._variational_distribution.variational_mean torch.Size([3, 300])\n",
      "gps.3.gp.variational_strategy.base_variational_strategy._variational_distribution.chol_variational_covar torch.Size([3, 300, 300])\n",
      "gps.3.gp.mean_module.constant torch.Size([3, 1])\n",
      "gps.3.gp.covar_module.raw_outputscale torch.Size([3])\n",
      "gps.3.gp.covar_module.base_kernel.raw_lengthscale torch.Size([3, 1, 1])\n",
      "gps.3.likelihood.raw_noise torch.Size([1])\n",
      "gps.3.likelihood.noise_covar.raw_noise torch.Size([3])\n",
      "gps.4.gp.variational_strategy.base_variational_strategy.inducing_points torch.Size([3, 300, 85])\n",
      "gps.4.gp.variational_strategy.base_variational_strategy._variational_distribution.variational_mean torch.Size([3, 300])\n",
      "gps.4.gp.variational_strategy.base_variational_strategy._variational_distribution.chol_variational_covar torch.Size([3, 300, 300])\n",
      "gps.4.gp.mean_module.constant torch.Size([3, 1])\n",
      "gps.4.gp.covar_module.raw_outputscale torch.Size([3])\n",
      "gps.4.gp.covar_module.base_kernel.raw_lengthscale torch.Size([3, 1, 1])\n",
      "gps.4.likelihood.raw_noise torch.Size([1])\n",
      "gps.4.likelihood.noise_covar.raw_noise torch.Size([3])\n",
      "gps.5.gp.variational_strategy.base_variational_strategy.inducing_points torch.Size([3, 300, 85])\n",
      "gps.5.gp.variational_strategy.base_variational_strategy._variational_distribution.variational_mean torch.Size([3, 300])\n",
      "gps.5.gp.variational_strategy.base_variational_strategy._variational_distribution.chol_variational_covar torch.Size([3, 300, 300])\n",
      "gps.5.gp.mean_module.constant torch.Size([3, 1])\n",
      "gps.5.gp.covar_module.raw_outputscale torch.Size([3])\n",
      "gps.5.gp.covar_module.base_kernel.raw_lengthscale torch.Size([3, 1, 1])\n",
      "gps.5.likelihood.raw_noise torch.Size([1])\n",
      "gps.5.likelihood.noise_covar.raw_noise torch.Size([3])\n",
      "gps.6.gp.variational_strategy.base_variational_strategy.inducing_points torch.Size([3, 300, 85])\n",
      "gps.6.gp.variational_strategy.base_variational_strategy._variational_distribution.variational_mean torch.Size([3, 300])\n",
      "gps.6.gp.variational_strategy.base_variational_strategy._variational_distribution.chol_variational_covar torch.Size([3, 300, 300])\n",
      "gps.6.gp.mean_module.constant torch.Size([3, 1])\n",
      "gps.6.gp.covar_module.raw_outputscale torch.Size([3])\n",
      "gps.6.gp.covar_module.base_kernel.raw_lengthscale torch.Size([3, 1, 1])\n",
      "gps.6.likelihood.raw_noise torch.Size([1])\n",
      "gps.6.likelihood.noise_covar.raw_noise torch.Size([3])\n",
      "gps.7.gp.variational_strategy.base_variational_strategy.inducing_points torch.Size([3, 300, 85])\n",
      "gps.7.gp.variational_strategy.base_variational_strategy._variational_distribution.variational_mean torch.Size([3, 300])\n",
      "gps.7.gp.variational_strategy.base_variational_strategy._variational_distribution.chol_variational_covar torch.Size([3, 300, 300])\n",
      "gps.7.gp.mean_module.constant torch.Size([3, 1])\n",
      "gps.7.gp.covar_module.raw_outputscale torch.Size([3])\n",
      "gps.7.gp.covar_module.base_kernel.raw_lengthscale torch.Size([3, 1, 1])\n",
      "gps.7.likelihood.raw_noise torch.Size([1])\n",
      "gps.7.likelihood.noise_covar.raw_noise torch.Size([3])\n",
      "gps.8.gp.variational_strategy.base_variational_strategy.inducing_points torch.Size([3, 300, 85])\n",
      "gps.8.gp.variational_strategy.base_variational_strategy._variational_distribution.variational_mean torch.Size([3, 300])\n",
      "gps.8.gp.variational_strategy.base_variational_strategy._variational_distribution.chol_variational_covar torch.Size([3, 300, 300])\n",
      "gps.8.gp.mean_module.constant torch.Size([3, 1])\n",
      "gps.8.gp.covar_module.raw_outputscale torch.Size([3])\n",
      "gps.8.gp.covar_module.base_kernel.raw_lengthscale torch.Size([3, 1, 1])\n",
      "gps.8.likelihood.raw_noise torch.Size([1])\n",
      "gps.8.likelihood.noise_covar.raw_noise torch.Size([3])\n",
      "gps.9.gp.variational_strategy.base_variational_strategy.inducing_points torch.Size([3, 300, 85])\n",
      "gps.9.gp.variational_strategy.base_variational_strategy._variational_distribution.variational_mean torch.Size([3, 300])\n",
      "gps.9.gp.variational_strategy.base_variational_strategy._variational_distribution.chol_variational_covar torch.Size([3, 300, 300])\n",
      "gps.9.gp.mean_module.constant torch.Size([3, 1])\n",
      "gps.9.gp.covar_module.raw_outputscale torch.Size([3])\n",
      "gps.9.gp.covar_module.base_kernel.raw_lengthscale torch.Size([3, 1, 1])\n",
      "gps.9.likelihood.raw_noise torch.Size([1])\n",
      "gps.9.likelihood.noise_covar.raw_noise torch.Size([3])\n",
      "gps.10.gp.variational_strategy.base_variational_strategy.inducing_points torch.Size([3, 300, 85])\n",
      "gps.10.gp.variational_strategy.base_variational_strategy._variational_distribution.variational_mean torch.Size([3, 300])\n",
      "gps.10.gp.variational_strategy.base_variational_strategy._variational_distribution.chol_variational_covar torch.Size([3, 300, 300])\n",
      "gps.10.gp.mean_module.constant torch.Size([3, 1])\n",
      "gps.10.gp.covar_module.raw_outputscale torch.Size([3])\n",
      "gps.10.gp.covar_module.base_kernel.raw_lengthscale torch.Size([3, 1, 1])\n",
      "gps.10.likelihood.raw_noise torch.Size([1])\n",
      "gps.10.likelihood.noise_covar.raw_noise torch.Size([3])\n",
      "gps.11.gp.variational_strategy.base_variational_strategy.inducing_points torch.Size([3, 300, 85])\n",
      "gps.11.gp.variational_strategy.base_variational_strategy._variational_distribution.variational_mean torch.Size([3, 300])\n",
      "gps.11.gp.variational_strategy.base_variational_strategy._variational_distribution.chol_variational_covar torch.Size([3, 300, 300])\n",
      "gps.11.gp.mean_module.constant torch.Size([3, 1])\n",
      "gps.11.gp.covar_module.raw_outputscale torch.Size([3])\n",
      "gps.11.gp.covar_module.base_kernel.raw_lengthscale torch.Size([3, 1, 1])\n",
      "gps.11.likelihood.raw_noise torch.Size([1])\n",
      "gps.11.likelihood.noise_covar.raw_noise torch.Size([3])\n",
      "gps.12.gp.variational_strategy.base_variational_strategy.inducing_points torch.Size([3, 300, 85])\n",
      "gps.12.gp.variational_strategy.base_variational_strategy._variational_distribution.variational_mean torch.Size([3, 300])\n",
      "gps.12.gp.variational_strategy.base_variational_strategy._variational_distribution.chol_variational_covar torch.Size([3, 300, 300])\n",
      "gps.12.gp.mean_module.constant torch.Size([3, 1])\n",
      "gps.12.gp.covar_module.raw_outputscale torch.Size([3])\n",
      "gps.12.gp.covar_module.base_kernel.raw_lengthscale torch.Size([3, 1, 1])\n",
      "gps.12.likelihood.raw_noise torch.Size([1])\n",
      "gps.12.likelihood.noise_covar.raw_noise torch.Size([3])\n",
      "gps.13.gp.variational_strategy.base_variational_strategy.inducing_points torch.Size([3, 300, 85])\n",
      "gps.13.gp.variational_strategy.base_variational_strategy._variational_distribution.variational_mean torch.Size([3, 300])\n",
      "gps.13.gp.variational_strategy.base_variational_strategy._variational_distribution.chol_variational_covar torch.Size([3, 300, 300])\n",
      "gps.13.gp.mean_module.constant torch.Size([3, 1])\n",
      "gps.13.gp.covar_module.raw_outputscale torch.Size([3])\n",
      "gps.13.gp.covar_module.base_kernel.raw_lengthscale torch.Size([3, 1, 1])\n",
      "gps.13.likelihood.raw_noise torch.Size([1])\n",
      "gps.13.likelihood.noise_covar.raw_noise torch.Size([3])\n",
      "gps.14.gp.variational_strategy.base_variational_strategy.inducing_points torch.Size([3, 300, 85])\n",
      "gps.14.gp.variational_strategy.base_variational_strategy._variational_distribution.variational_mean torch.Size([3, 300])\n",
      "gps.14.gp.variational_strategy.base_variational_strategy._variational_distribution.chol_variational_covar torch.Size([3, 300, 300])\n",
      "gps.14.gp.mean_module.constant torch.Size([3, 1])\n",
      "gps.14.gp.covar_module.raw_outputscale torch.Size([3])\n",
      "gps.14.gp.covar_module.base_kernel.raw_lengthscale torch.Size([3, 1, 1])\n",
      "gps.14.likelihood.raw_noise torch.Size([1])\n",
      "gps.14.likelihood.noise_covar.raw_noise torch.Size([3])\n",
      "gps.15.gp.variational_strategy.base_variational_strategy.inducing_points torch.Size([3, 300, 85])\n",
      "gps.15.gp.variational_strategy.base_variational_strategy._variational_distribution.variational_mean torch.Size([3, 300])\n",
      "gps.15.gp.variational_strategy.base_variational_strategy._variational_distribution.chol_variational_covar torch.Size([3, 300, 300])\n",
      "gps.15.gp.mean_module.constant torch.Size([3, 1])\n",
      "gps.15.gp.covar_module.raw_outputscale torch.Size([3])\n",
      "gps.15.gp.covar_module.base_kernel.raw_lengthscale torch.Size([3, 1, 1])\n",
      "gps.15.likelihood.raw_noise torch.Size([1])\n",
      "gps.15.likelihood.noise_covar.raw_noise torch.Size([3])\n",
      "gps.16.gp.variational_strategy.base_variational_strategy.inducing_points torch.Size([3, 300, 85])\n",
      "gps.16.gp.variational_strategy.base_variational_strategy._variational_distribution.variational_mean torch.Size([3, 300])\n",
      "gps.16.gp.variational_strategy.base_variational_strategy._variational_distribution.chol_variational_covar torch.Size([3, 300, 300])\n",
      "gps.16.gp.mean_module.constant torch.Size([3, 1])\n",
      "gps.16.gp.covar_module.raw_outputscale torch.Size([3])\n",
      "gps.16.gp.covar_module.base_kernel.raw_lengthscale torch.Size([3, 1, 1])\n",
      "gps.16.likelihood.raw_noise torch.Size([1])\n",
      "gps.16.likelihood.noise_covar.raw_noise torch.Size([3])\n",
      "gps.17.gp.variational_strategy.base_variational_strategy.inducing_points torch.Size([3, 300, 85])\n",
      "gps.17.gp.variational_strategy.base_variational_strategy._variational_distribution.variational_mean torch.Size([3, 300])\n",
      "gps.17.gp.variational_strategy.base_variational_strategy._variational_distribution.chol_variational_covar torch.Size([3, 300, 300])\n",
      "gps.17.gp.mean_module.constant torch.Size([3, 1])\n",
      "gps.17.gp.covar_module.raw_outputscale torch.Size([3])\n",
      "gps.17.gp.covar_module.base_kernel.raw_lengthscale torch.Size([3, 1, 1])\n",
      "gps.17.likelihood.raw_noise torch.Size([1])\n",
      "gps.17.likelihood.noise_covar.raw_noise torch.Size([3])\n",
      "gps.18.gp.variational_strategy.base_variational_strategy.inducing_points torch.Size([3, 300, 85])\n",
      "gps.18.gp.variational_strategy.base_variational_strategy._variational_distribution.variational_mean torch.Size([3, 300])\n",
      "gps.18.gp.variational_strategy.base_variational_strategy._variational_distribution.chol_variational_covar torch.Size([3, 300, 300])\n",
      "gps.18.gp.mean_module.constant torch.Size([3, 1])\n",
      "gps.18.gp.covar_module.raw_outputscale torch.Size([3])\n",
      "gps.18.gp.covar_module.base_kernel.raw_lengthscale torch.Size([3, 1, 1])\n",
      "gps.18.likelihood.raw_noise torch.Size([1])\n",
      "gps.18.likelihood.noise_covar.raw_noise torch.Size([3])\n",
      "gps.19.gp.variational_strategy.base_variational_strategy.inducing_points torch.Size([3, 300, 85])\n",
      "gps.19.gp.variational_strategy.base_variational_strategy._variational_distribution.variational_mean torch.Size([3, 300])\n",
      "gps.19.gp.variational_strategy.base_variational_strategy._variational_distribution.chol_variational_covar torch.Size([3, 300, 300])\n",
      "gps.19.gp.mean_module.constant torch.Size([3, 1])\n",
      "gps.19.gp.covar_module.raw_outputscale torch.Size([3])\n",
      "gps.19.gp.covar_module.base_kernel.raw_lengthscale torch.Size([3, 1, 1])\n",
      "gps.19.likelihood.raw_noise torch.Size([1])\n",
      "gps.19.likelihood.noise_covar.raw_noise torch.Size([3])\n",
      "Parameters layer: 546\n"
     ]
    }
   ],
   "source": [
    "class Trainer:\n",
    "    def __init__(self,gp_args,regressor_context_rate = [0.0,0.0]):\n",
    "        self.model = Model(gp_args).cuda()\n",
    "        self.norm_mean = args.norm_mean.cuda()\n",
    "        self.norm_std = args.norm_std.cuda()\n",
    "        \n",
    "        # disable learning backbone\n",
    "        for param in self.model.backbone.parameters():\n",
    "            param.requires_grad = False\n",
    "        '''\n",
    "        # training tool\n",
    "        self.optimizer = optim.Adam(self._optimize(regressor_context_rate))\n",
    "        self.scheduler = optim.lr_scheduler.LambdaLR(optimizer=self.optimizer,\n",
    "                                                         lr_lambda=lambda epoch: args.decay_rate**epoch)\n",
    "        '''\n",
    "    def load_model(self, file_name = 'pretrained.pth'):\n",
    "        # load file info\n",
    "        state_dict = torch.load(os.path.join(args.model_dir, file_name))\n",
    "        if 'net.resnet.conv1.weight' in state_dict:\n",
    "            print('Transform from old model.')\n",
    "            # Part 1: backbone\n",
    "            backbone_state_dict = self._from_old_model(state_dict,'backbone')\n",
    "            print('Backbone parameters layer:',len(backbone_state_dict.keys()))\n",
    "            self.model.backbone.load_state_dict(backbone_state_dict,strict = True)\n",
    "            # Part 2: nn\n",
    "            nn_state_dict = self._from_old_model(torch.load(os.path.join(args.model_dir, file_name)),'nn')\n",
    "            print('NN parameters layer:',len(nn_state_dict.keys()))\n",
    "            self.model.nn.load_state_dict(nn_state_dict,strict = True)\n",
    "        else:\n",
    "            print('Parameters layer:',len(state_dict.keys()))\n",
    "            # load file to model\n",
    "            self.model.load_state_dict(state_dict,strict = True)\n",
    "        print('Model Structure:')\n",
    "        # Display model structure\n",
    "        for name, param in self.model.named_parameters():\n",
    "            print(name, param.shape)\n",
    "        print('Parameters layer:',len(self.model.state_dict().keys()))\n",
    "    \n",
    "    def _from_old_model(self, state_dict, select = 'backbone'):\n",
    "        if select == 'backbone':\n",
    "            for key in list(state_dict):\n",
    "                if 'net.resnet.' in key:\n",
    "                    state_dict[key.replace('net.resnet.','resnet.')] = state_dict.pop(key)\n",
    "                else:\n",
    "                    state_dict.pop(key)\n",
    "        elif select == 'nn':\n",
    "            for key in list(state_dict):\n",
    "                if 'net.global_regressor.' in key:\n",
    "                    state_dict[key.replace('net.global_regressor.','global_regressor.')] = state_dict.pop(key)\n",
    "                elif 'net.global_context.' in key:\n",
    "                    state_dict[key.replace('net.global_context.','global_context.')] = state_dict.pop(key)\n",
    "                else:\n",
    "                    state_dict.pop(key)\n",
    "        return state_dict\n",
    "    \n",
    "    def save_model(self, file_name = 'model-{}-{}.pth'):\n",
    "        checkpoint_path = os.path.join(args.model_dir, file_name)\n",
    "        torch.save(self.model.state_dict(),checkpoint_path)\n",
    "        print('Saving model to ' +  file_name)\n",
    "        \n",
    "    def _optimize(self,regressor_context_rate = [0.0,0.0]):\n",
    "        optimizer = [\n",
    "                {'params': self.model.gps.parameters(), \\\n",
    "                 'lr': args.learning_rate,'weight_decay':args.weight_decay}]\n",
    "            \n",
    "        if regressor_context_rate[0]!=0:\n",
    "            optimizer += [{'params': self.model.nn.global_regressor.parameters(), \\\n",
    "                 'lr': args.learning_rate * regressor_context_rate[0],'weight_decay':args.weight_decay}]\n",
    "            print('Regressor learn rate:',regressor_context_rate[0])\n",
    "        else:\n",
    "            for param in self.model.nn.global_regressor.parameters():\n",
    "                param.requires_grad = False\n",
    "                \n",
    "        if regressor_context_rate[1]!=0:\n",
    "            optimizer += [{'params': self.model.nn.global_context.parameters(), \\\n",
    "                 'lr': args.learning_rate * regressor_context_rate[1],'weight_decay':args.weight_decay}]\n",
    "            print('Context learn rate:',regressor_context_rate[1])\n",
    "        else:\n",
    "            for param in self.model.nn.global_context.parameters():\n",
    "                param.requires_grad = False\n",
    "                \n",
    "        return optimizer\n",
    "            \n",
    "    def train(self,x,y):\n",
    "        # Step 0: zero grad\n",
    "        self.optimizer.zero_grad()\n",
    "        \n",
    "        start = time.time()\n",
    "        # Step 1: get data\n",
    "        x,y = x.cuda(),y.cuda()\n",
    "        if args.is_normalization:\n",
    "            y = normalize(y,self.norm_mean, self.norm_std)\n",
    "            \n",
    "        # Step 2: training\n",
    "        assert self.model.training == True\n",
    "        \n",
    "        trans_loss = torch.tensor(0.).cuda()\n",
    "        \n",
    "        trans_target, rot_target = torch.split(y, [3, 4], dim=1)\n",
    "        trans_feat, rot_pred = self.model.forward_nn(x)\n",
    "        rot_loss = self._nn_loss(rot_pred,rot_target)\n",
    "        for i,gp in enumerate(self.model.gps):\n",
    "            #torch.manual_seed(i)\n",
    "            #sampled_mask = torch.randint(high=args.batch_size, size=(self.model.sub_batch_size,))\n",
    "            sampled_mask = torch.randint(high=args.batch_size, size=(args.batch_size,))\n",
    "            sub_x = trans_feat[sampled_mask]\n",
    "            sub_y = trans_target[sampled_mask]\n",
    "            gp_loss = self._gp_loss(gp,sub_x,sub_y)\n",
    "            trans_loss += gp_loss\n",
    "        trans_loss = trans_loss/self.model.num_gp\n",
    "        \n",
    "        total_loss = trans_loss + args.lamda_weights * rot_loss\n",
    "        \n",
    "        batch_time = time.time() - start\n",
    "        \n",
    "        #Step 3: update\n",
    "        total_loss.backward()\n",
    "        self.optimizer.step()\n",
    "        \n",
    "        return float(total_loss), batch_time    \n",
    "    \n",
    "    def _nn_loss(self,rot_pred,rot_target):\n",
    "        rot_loss = 1. - torch.mean(torch.square(torch.sum(torch.mul(rot_pred,rot_target),dim=1)))\n",
    "        return rot_loss\n",
    "        \n",
    "    def _gp_loss(self,gp,trans_feat,trans_target):\n",
    "        # predict\n",
    "        trans_pred = self.model.forward_gp(gp,trans_feat)\n",
    "        #sub_trans_feat = trans_feat[:,gp.feat_index]\n",
    "        #trans_pred = gp(sub_trans_feat)\n",
    "        \n",
    "        #num_data = int(min(len(dataloader)*args.batch_size,len(dataset))*self.model.sub_batch_rate)\n",
    "        num_data = min(len(dataloader)*args.batch_size,len(dataset))\n",
    "        mll = gpytorch.mlls.PredictiveLogLikelihood(gp.likelihood, gp.gp, num_data = num_data)\n",
    "        \n",
    "        # trans loss\n",
    "        trans_loss = -1.*mll(trans_pred, trans_target)\n",
    "        \n",
    "        return trans_loss\n",
    "    \n",
    "    def _eval_gp(self, gp, trans_pred):\n",
    "        c_mean, c_var = trans_pred.mean, trans_pred.variance\n",
    "        y_mean, y_var = gp.likelihood(trans_pred).mean, gp.likelihood(trans_pred).variance\n",
    "        \n",
    "        return y_mean, c_mean, c_var\n",
    "    \n",
    "    def _sample(self, mean, var, num_sample = 100):\n",
    "        dist = Normal(mean, var)\n",
    "        samples = dist.sample([num_sample])\n",
    "        return samples\n",
    "\n",
    "    def eval_forward(self,x,y,num_sample = 100,output_denormalize = True):\n",
    "        # Step 1: get data\n",
    "        x,y = x.cuda(),y.cuda()\n",
    "        if args.is_normalization:\n",
    "            y = normalize(y,self.norm_mean, self.norm_std)\n",
    "        \n",
    "        # Step 2: forward\n",
    "        assert self.model.training == False\n",
    "        trans_feat, rot_pred = self.model.forward_nn(x)\n",
    "        \n",
    "        trans_preds = 0\n",
    "        trans_means = 0\n",
    "        trans_vars = 0\n",
    "        for gp in self.model.gps:\n",
    "            trans_pred = self.model.forward_gp(gp,trans_feat)\n",
    "            trans_pred, trans_mean, trans_var = self._eval_gp(gp, trans_pred)\n",
    "            trans_preds += trans_pred\n",
    "            trans_means += trans_mean\n",
    "            trans_vars += trans_var\n",
    "            \n",
    "        trans_preds /= self.model.num_gp\n",
    "        trans_means /= self.model.num_gp\n",
    "        trans_vars /= self.model.num_gp\n",
    "        \n",
    "        if args.is_normalization and output_denormalize:\n",
    "            trans_preds = denormalize_navie(trans_preds, self.norm_mean, self.norm_std)\n",
    "            trans_means = denormalize_navie(trans_means, self.norm_mean, self.norm_std)\n",
    "            trans_vars = trans_vars.mul(self.norm_std)\n",
    "            y = denormalize(y, self.norm_mean, self.norm_std)\n",
    "        \n",
    "        samples = self._sample(trans_means, trans_vars, num_sample)\n",
    "            \n",
    "        # Step 3: split output\n",
    "        trans_target, rot_target = torch.split(y, [3, 4], dim=1)\n",
    "        \n",
    "        return trans_preds, rot_pred, trans_target, rot_target, samples\n",
    "\n",
    "num_gp = 20\n",
    "gp_args = {\n",
    "    'feat_rate':1-1/3,\n",
    "    'num_gp':num_gp\n",
    "}    \n",
    "\n",
    "#trainer = Trainer(gp_args,regressor_context_rate = [0.1,0.01])\n",
    "trainer = Trainer(gp_args)\n",
    "#trainer.load_model('model-2-1000.pth')\n",
    "trainer.load_model('pretrained_gp20_fix.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-25T19:51:30.041059Z",
     "start_time": "2020-07-25T19:51:30.035861Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "for param in trainer.model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-25T19:51:30.082680Z",
     "start_time": "2020-07-25T19:51:30.042741Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "trans_errors = []\n",
    "rot_errors = []\n",
    "uncertainties = []\n",
    "pose_map = []\n",
    "\n",
    "total_trans_error = 0.\n",
    "total_rot_error = 0.\n",
    "\n",
    "count = 0.\n",
    "\n",
    "is_save_map = False\n",
    "is_read_map = False\n",
    "\n",
    "trans_preds = []\n",
    "trans_gts = []\n",
    "\n",
    "rot_preds = []\n",
    "rot_gts = []\n",
    "\n",
    "pred_uncertainties = []\n",
    "\n",
    "pred_time = []\n",
    "\n",
    "br = tf_ros.TransformBroadcaster()\n",
    "\n",
    "GT_POSE_TOPIC = '/gt_pose'\n",
    "BIRDVIEW_TOPIC_PUB = '/bird_view'\n",
    "MAP_TOPIC_PUB = '/pose_map'\n",
    "PARTICLES_PUB = '/particles'\n",
    "NN_LOCALIZASION_PUB = '/nn_pose'\n",
    "gt_pose_pub = rospy.Publisher(GT_POSE_TOPIC, Odometry, queue_size=1)\n",
    "bird_view_pub = rospy.Publisher(BIRDVIEW_TOPIC_PUB, Image, queue_size=1)\n",
    "map_pub = rospy.Publisher(MAP_TOPIC_PUB, Path, queue_size=1)\n",
    "particles_pub = rospy.Publisher(PARTICLES_PUB, PoseArray, queue_size=1)\n",
    "nn_pose_pub = rospy.Publisher(NN_LOCALIZASION_PUB, Odometry, queue_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-25T19:57:11.163909Z",
     "start_time": "2020-07-25T19:51:30.088948Z"
    },
    "code_folding": [
     15
    ],
    "run_control": {
     "marked": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/92100, translation error = 2.333, rotation error = 3.709, time/batch = 4.447\n",
      "600/92100, translation error = 7.158, rotation error = 4.374, time/batch = 0.944\n",
      "900/92100, translation error = 7.878, rotation error = 4.335, time/batch = 0.965\n",
      "1200/92100, translation error = 6.753, rotation error = 4.530, time/batch = 0.930\n",
      "1500/92100, translation error = 6.010, rotation error = 4.641, time/batch = 0.973\n",
      "1800/92100, translation error = 5.256, rotation error = 4.576, time/batch = 0.937\n",
      "2100/92100, translation error = 4.993, rotation error = 5.149, time/batch = 0.970\n",
      "2400/92100, translation error = 4.576, rotation error = 4.921, time/batch = 0.945\n",
      "2700/92100, translation error = 4.321, rotation error = 5.160, time/batch = 0.968\n",
      "3000/92100, translation error = 4.194, rotation error = 5.127, time/batch = 0.934\n",
      "3300/92100, translation error = 3.939, rotation error = 4.927, time/batch = 0.971\n",
      "3600/92100, translation error = 3.881, rotation error = 4.897, time/batch = 0.935\n",
      "3900/92100, translation error = 3.688, rotation error = 4.775, time/batch = 0.960\n",
      "4200/92100, translation error = 3.488, rotation error = 4.641, time/batch = 0.947\n",
      "4500/92100, translation error = 3.325, rotation error = 4.542, time/batch = 0.964\n",
      "4800/92100, translation error = 3.186, rotation error = 4.481, time/batch = 0.951\n",
      "5100/92100, translation error = 3.129, rotation error = 4.592, time/batch = 0.968\n",
      "5400/92100, translation error = 3.062, rotation error = 4.536, time/batch = 0.940\n",
      "5700/92100, translation error = 2.979, rotation error = 4.443, time/batch = 0.970\n",
      "6000/92100, translation error = 2.955, rotation error = 4.394, time/batch = 0.944\n",
      "6300/92100, translation error = 2.909, rotation error = 4.308, time/batch = 0.968\n",
      "6600/92100, translation error = 2.921, rotation error = 4.355, time/batch = 0.943\n",
      "6900/92100, translation error = 5.171, rotation error = 4.757, time/batch = 0.967\n",
      "7200/92100, translation error = 5.126, rotation error = 4.855, time/batch = 0.936\n",
      "7500/92100, translation error = 4.974, rotation error = 4.892, time/batch = 0.964\n",
      "7800/92100, translation error = 4.987, rotation error = 4.931, time/batch = 0.933\n",
      "8100/92100, translation error = 5.048, rotation error = 4.919, time/batch = 0.977\n",
      "8400/92100, translation error = 5.551, rotation error = 5.100, time/batch = 0.941\n",
      "8700/92100, translation error = 5.434, rotation error = 5.053, time/batch = 0.971\n",
      "9000/92100, translation error = 5.309, rotation error = 4.997, time/batch = 0.941\n",
      "9300/92100, translation error = 5.229, rotation error = 4.966, time/batch = 0.968\n",
      "9600/92100, translation error = 5.152, rotation error = 4.887, time/batch = 0.943\n",
      "9900/92100, translation error = 5.060, rotation error = 4.927, time/batch = 0.979\n",
      "10200/92100, translation error = 4.991, rotation error = 4.886, time/batch = 0.939\n",
      "10500/92100, translation error = 4.897, rotation error = 4.957, time/batch = 0.966\n",
      "10800/92100, translation error = 4.812, rotation error = 4.983, time/batch = 0.940\n",
      "11100/92100, translation error = 4.746, rotation error = 4.994, time/batch = 0.969\n",
      "11400/92100, translation error = 4.664, rotation error = 4.924, time/batch = 0.943\n",
      "11700/92100, translation error = 4.575, rotation error = 4.864, time/batch = 0.970\n",
      "12000/92100, translation error = 4.495, rotation error = 4.808, time/batch = 0.943\n",
      "12300/92100, translation error = 4.412, rotation error = 4.752, time/batch = 0.970\n",
      "12600/92100, translation error = 4.343, rotation error = 4.716, time/batch = 0.942\n",
      "12900/92100, translation error = 4.275, rotation error = 4.781, time/batch = 0.975\n",
      "13200/92100, translation error = 4.212, rotation error = 4.762, time/batch = 0.943\n",
      "13500/92100, translation error = 4.225, rotation error = 4.757, time/batch = 0.976\n",
      "13800/92100, translation error = 4.176, rotation error = 4.739, time/batch = 0.948\n",
      "14100/92100, translation error = 4.131, rotation error = 4.739, time/batch = 0.985\n",
      "14400/92100, translation error = 4.104, rotation error = 4.778, time/batch = 0.941\n",
      "14700/92100, translation error = 4.059, rotation error = 4.753, time/batch = 0.981\n",
      "15000/92100, translation error = 4.039, rotation error = 4.769, time/batch = 0.941\n",
      "15300/92100, translation error = 4.011, rotation error = 4.742, time/batch = 0.981\n",
      "15600/92100, translation error = 4.012, rotation error = 4.750, time/batch = 0.948\n",
      "15900/92100, translation error = 4.975, rotation error = 4.818, time/batch = 0.974\n",
      "16200/92100, translation error = 4.932, rotation error = 4.864, time/batch = 0.949\n",
      "16500/92100, translation error = 4.883, rotation error = 4.856, time/batch = 0.974\n",
      "16800/92100, translation error = 4.841, rotation error = 4.881, time/batch = 0.954\n",
      "17100/92100, translation error = 4.792, rotation error = 4.877, time/batch = 0.974\n",
      "17400/92100, translation error = 4.735, rotation error = 4.859, time/batch = 0.939\n",
      "17700/92100, translation error = 4.681, rotation error = 4.850, time/batch = 0.978\n",
      "18000/92100, translation error = 4.650, rotation error = 4.894, time/batch = 0.943\n",
      "18300/92100, translation error = 4.611, rotation error = 4.937, time/batch = 0.979\n",
      "18600/92100, translation error = 4.568, rotation error = 4.911, time/batch = 0.942\n",
      "18900/92100, translation error = 4.523, rotation error = 4.909, time/batch = 0.974\n",
      "19200/92100, translation error = 4.484, rotation error = 4.891, time/batch = 0.945\n",
      "19500/92100, translation error = 4.468, rotation error = 4.880, time/batch = 0.970\n",
      "19800/92100, translation error = 4.436, rotation error = 4.887, time/batch = 0.943\n",
      "20100/92100, translation error = 4.402, rotation error = 4.858, time/batch = 0.981\n",
      "20400/92100, translation error = 4.357, rotation error = 4.828, time/batch = 0.945\n",
      "20700/92100, translation error = 4.316, rotation error = 4.814, time/batch = 0.982\n",
      "21000/92100, translation error = 4.277, rotation error = 4.807, time/batch = 0.943\n",
      "21300/92100, translation error = 4.236, rotation error = 4.844, time/batch = 0.974\n",
      "21600/92100, translation error = 4.287, rotation error = 4.841, time/batch = 0.944\n",
      "21900/92100, translation error = 6.225, rotation error = 5.094, time/batch = 0.979\n",
      "22200/92100, translation error = 9.481, rotation error = 5.799, time/batch = 0.950\n",
      "22500/92100, translation error = 9.598, rotation error = 5.760, time/batch = 0.976\n",
      "22800/92100, translation error = 9.507, rotation error = 5.735, time/batch = 0.942\n",
      "23100/92100, translation error = 9.434, rotation error = 5.759, time/batch = 0.980\n",
      "23400/92100, translation error = 9.345, rotation error = 5.750, time/batch = 0.944\n",
      "23700/92100, translation error = 9.252, rotation error = 5.735, time/batch = 0.984\n",
      "24000/92100, translation error = 9.164, rotation error = 5.716, time/batch = 0.957\n",
      "24300/92100, translation error = 9.116, rotation error = 5.714, time/batch = 0.989\n",
      "24600/92100, translation error = 9.039, rotation error = 5.702, time/batch = 0.946\n",
      "24900/92100, translation error = 8.981, rotation error = 5.689, time/batch = 0.983\n",
      "25200/92100, translation error = 8.897, rotation error = 5.676, time/batch = 0.950\n",
      "25500/92100, translation error = 8.812, rotation error = 5.675, time/batch = 0.981\n",
      "25800/92100, translation error = 8.727, rotation error = 5.701, time/batch = 0.949\n",
      "26100/92100, translation error = 8.650, rotation error = 5.699, time/batch = 0.978\n",
      "26400/92100, translation error = 8.567, rotation error = 5.668, time/batch = 0.949\n",
      "26700/92100, translation error = 8.490, rotation error = 5.647, time/batch = 0.974\n",
      "27000/92100, translation error = 8.479, rotation error = 5.648, time/batch = 0.943\n",
      "27300/92100, translation error = 8.414, rotation error = 5.613, time/batch = 0.975\n",
      "27600/92100, translation error = 8.352, rotation error = 5.583, time/batch = 0.945\n",
      "27900/92100, translation error = 8.286, rotation error = 5.568, time/batch = 0.977\n",
      "28200/92100, translation error = 8.219, rotation error = 5.541, time/batch = 0.945\n",
      "28500/92100, translation error = 8.168, rotation error = 5.537, time/batch = 0.975\n",
      "28800/92100, translation error = 8.124, rotation error = 5.518, time/batch = 0.948\n",
      "29100/92100, translation error = 8.117, rotation error = 5.596, time/batch = 0.987\n",
      "29400/92100, translation error = 8.209, rotation error = 5.641, time/batch = 0.950\n",
      "29700/92100, translation error = 8.145, rotation error = 5.610, time/batch = 0.978\n",
      "30000/92100, translation error = 8.105, rotation error = 5.605, time/batch = 0.953\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30300/92100, translation error = 8.063, rotation error = 5.586, time/batch = 0.976\n",
      "30600/92100, translation error = 8.010, rotation error = 5.576, time/batch = 0.951\n",
      "30900/92100, translation error = 7.945, rotation error = 5.555, time/batch = 0.978\n",
      "31200/92100, translation error = 7.891, rotation error = 5.583, time/batch = 0.943\n",
      "31500/92100, translation error = 7.836, rotation error = 5.567, time/batch = 0.978\n",
      "31800/92100, translation error = 7.779, rotation error = 5.556, time/batch = 0.945\n",
      "32100/92100, translation error = 7.732, rotation error = 5.534, time/batch = 0.982\n",
      "32400/92100, translation error = 7.680, rotation error = 5.523, time/batch = 0.946\n",
      "32700/92100, translation error = 7.626, rotation error = 5.503, time/batch = 0.973\n",
      "33000/92100, translation error = 7.569, rotation error = 5.484, time/batch = 0.943\n",
      "33300/92100, translation error = 7.521, rotation error = 5.474, time/batch = 0.977\n",
      "33600/92100, translation error = 7.476, rotation error = 5.463, time/batch = 0.946\n",
      "33900/92100, translation error = 7.440, rotation error = 5.444, time/batch = 0.974\n",
      "34200/92100, translation error = 7.598, rotation error = 5.505, time/batch = 0.948\n",
      "34500/92100, translation error = 8.550, rotation error = 5.723, time/batch = 0.974\n",
      "34800/92100, translation error = 8.502, rotation error = 5.703, time/batch = 0.950\n",
      "35100/92100, translation error = 8.452, rotation error = 5.702, time/batch = 0.981\n",
      "35400/92100, translation error = 9.369, rotation error = 5.841, time/batch = 0.955\n",
      "35700/92100, translation error = 9.584, rotation error = 5.831, time/batch = 0.977\n",
      "36000/92100, translation error = 9.528, rotation error = 5.813, time/batch = 0.952\n",
      "36300/92100, translation error = 9.480, rotation error = 5.829, time/batch = 0.978\n",
      "36600/92100, translation error = 9.429, rotation error = 5.825, time/batch = 0.945\n",
      "36900/92100, translation error = 9.370, rotation error = 5.815, time/batch = 0.978\n",
      "37200/92100, translation error = 9.311, rotation error = 5.800, time/batch = 0.946\n",
      "37500/92100, translation error = 9.249, rotation error = 5.789, time/batch = 0.984\n",
      "37800/92100, translation error = 9.190, rotation error = 5.779, time/batch = 0.943\n",
      "38100/92100, translation error = 9.137, rotation error = 5.793, time/batch = 0.983\n",
      "38400/92100, translation error = 9.081, rotation error = 5.785, time/batch = 0.944\n",
      "38700/92100, translation error = 9.022, rotation error = 5.772, time/batch = 0.981\n",
      "39000/92100, translation error = 8.972, rotation error = 5.758, time/batch = 0.945\n",
      "39300/92100, translation error = 8.920, rotation error = 5.744, time/batch = 0.978\n",
      "39600/92100, translation error = 8.872, rotation error = 5.741, time/batch = 0.948\n",
      "39900/92100, translation error = 8.829, rotation error = 5.727, time/batch = 0.978\n",
      "40200/92100, translation error = 8.773, rotation error = 5.719, time/batch = 0.947\n",
      "40500/92100, translation error = 8.723, rotation error = 5.710, time/batch = 0.980\n",
      "40800/92100, translation error = 8.670, rotation error = 5.715, time/batch = 0.949\n",
      "41100/92100, translation error = 8.621, rotation error = 5.731, time/batch = 0.977\n",
      "41400/92100, translation error = 8.572, rotation error = 5.731, time/batch = 0.949\n",
      "41700/92100, translation error = 8.524, rotation error = 5.724, time/batch = 0.977\n",
      "42000/92100, translation error = 8.477, rotation error = 5.721, time/batch = 0.942\n",
      "42300/92100, translation error = 8.499, rotation error = 5.726, time/batch = 0.981\n",
      "42600/92100, translation error = 8.466, rotation error = 5.702, time/batch = 0.947\n",
      "42900/92100, translation error = 8.427, rotation error = 5.682, time/batch = 0.978\n",
      "43200/92100, translation error = 8.381, rotation error = 5.681, time/batch = 0.947\n",
      "43500/92100, translation error = 8.347, rotation error = 5.665, time/batch = 0.977\n",
      "43800/92100, translation error = 8.364, rotation error = 5.687, time/batch = 0.944\n",
      "44100/92100, translation error = 8.326, rotation error = 5.681, time/batch = 0.982\n",
      "44400/92100, translation error = 8.322, rotation error = 5.692, time/batch = 0.947\n",
      "44700/92100, translation error = 8.289, rotation error = 5.692, time/batch = 0.980\n",
      "45000/92100, translation error = 8.250, rotation error = 5.682, time/batch = 0.948\n",
      "45300/92100, translation error = 8.211, rotation error = 5.677, time/batch = 0.976\n",
      "45600/92100, translation error = 8.180, rotation error = 5.683, time/batch = 0.944\n",
      "45900/92100, translation error = 8.138, rotation error = 5.673, time/batch = 0.974\n",
      "46200/92100, translation error = 8.104, rotation error = 5.686, time/batch = 0.943\n",
      "46500/92100, translation error = 8.073, rotation error = 5.684, time/batch = 0.975\n",
      "46800/92100, translation error = 8.040, rotation error = 5.674, time/batch = 0.947\n",
      "47100/92100, translation error = 8.011, rotation error = 5.673, time/batch = 0.979\n",
      "47400/92100, translation error = 7.990, rotation error = 5.665, time/batch = 0.948\n",
      "47700/92100, translation error = 7.950, rotation error = 5.662, time/batch = 0.976\n",
      "48000/92100, translation error = 7.908, rotation error = 5.694, time/batch = 0.947\n",
      "48300/92100, translation error = 7.873, rotation error = 5.685, time/batch = 0.976\n",
      "48600/92100, translation error = 7.842, rotation error = 5.673, time/batch = 0.947\n",
      "48900/92100, translation error = 7.811, rotation error = 5.657, time/batch = 0.976\n",
      "49200/92100, translation error = 7.780, rotation error = 5.644, time/batch = 0.946\n",
      "49500/92100, translation error = 7.745, rotation error = 5.653, time/batch = 0.975\n",
      "49800/92100, translation error = 7.712, rotation error = 5.637, time/batch = 0.943\n",
      "50100/92100, translation error = 7.691, rotation error = 5.635, time/batch = 0.975\n",
      "50400/92100, translation error = 7.660, rotation error = 5.626, time/batch = 0.948\n",
      "50700/92100, translation error = 8.457, rotation error = 5.783, time/batch = 0.984\n",
      "51000/92100, translation error = 8.971, rotation error = 5.829, time/batch = 0.947\n",
      "51300/92100, translation error = 8.932, rotation error = 5.823, time/batch = 0.981\n",
      "51600/92100, translation error = 8.890, rotation error = 5.813, time/batch = 0.949\n",
      "51900/92100, translation error = 8.850, rotation error = 5.826, time/batch = 0.977\n",
      "52200/92100, translation error = 8.829, rotation error = 5.846, time/batch = 0.947\n",
      "52500/92100, translation error = 8.790, rotation error = 5.844, time/batch = 0.977\n",
      "52800/92100, translation error = 8.753, rotation error = 5.826, time/batch = 0.945\n",
      "53100/92100, translation error = 8.716, rotation error = 5.807, time/batch = 0.981\n",
      "53400/92100, translation error = 8.685, rotation error = 5.842, time/batch = 0.947\n",
      "53700/92100, translation error = 8.652, rotation error = 5.834, time/batch = 0.978\n",
      "54000/92100, translation error = 8.611, rotation error = 5.828, time/batch = 0.946\n",
      "54300/92100, translation error = 8.636, rotation error = 5.842, time/batch = 0.972\n",
      "54600/92100, translation error = 8.608, rotation error = 5.834, time/batch = 0.949\n",
      "54900/92100, translation error = 8.574, rotation error = 5.828, time/batch = 0.978\n",
      "55200/92100, translation error = 8.536, rotation error = 5.816, time/batch = 0.948\n",
      "55500/92100, translation error = 8.507, rotation error = 5.821, time/batch = 0.978\n",
      "55800/92100, translation error = 8.665, rotation error = 5.834, time/batch = 0.947\n",
      "56100/92100, translation error = 8.791, rotation error = 5.978, time/batch = 0.977\n",
      "56400/92100, translation error = 8.840, rotation error = 5.990, time/batch = 0.949\n",
      "56700/92100, translation error = 8.810, rotation error = 6.000, time/batch = 0.978\n",
      "57000/92100, translation error = 8.786, rotation error = 5.994, time/batch = 0.946\n",
      "57300/92100, translation error = 8.757, rotation error = 6.006, time/batch = 0.975\n",
      "57600/92100, translation error = 9.506, rotation error = 6.036, time/batch = 0.945\n",
      "57900/92100, translation error = 9.474, rotation error = 6.026, time/batch = 0.980\n",
      "58200/92100, translation error = 9.440, rotation error = 6.039, time/batch = 0.946\n",
      "58500/92100, translation error = 9.443, rotation error = 6.050, time/batch = 0.977\n",
      "58800/92100, translation error = 9.405, rotation error = 6.036, time/batch = 0.949\n",
      "59100/92100, translation error = 9.366, rotation error = 6.028, time/batch = 0.978\n",
      "59400/92100, translation error = 9.329, rotation error = 6.043, time/batch = 0.946\n",
      "59700/92100, translation error = 9.296, rotation error = 6.031, time/batch = 0.979\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/92100, translation error = 9.260, rotation error = 6.017, time/batch = 0.947\n",
      "60300/92100, translation error = 9.225, rotation error = 6.007, time/batch = 0.983\n",
      "60600/92100, translation error = 9.193, rotation error = 6.003, time/batch = 0.952\n",
      "60900/92100, translation error = 9.160, rotation error = 5.993, time/batch = 0.983\n",
      "61200/92100, translation error = 9.135, rotation error = 5.985, time/batch = 0.946\n",
      "61500/92100, translation error = 9.188, rotation error = 6.011, time/batch = 0.980\n",
      "61800/92100, translation error = 9.462, rotation error = 6.161, time/batch = 0.948\n",
      "62100/92100, translation error = 9.428, rotation error = 6.161, time/batch = 0.982\n",
      "62400/92100, translation error = 9.408, rotation error = 6.160, time/batch = 0.951\n",
      "62700/92100, translation error = 9.372, rotation error = 6.156, time/batch = 0.979\n",
      "63000/92100, translation error = 9.337, rotation error = 6.151, time/batch = 0.948\n",
      "63300/92100, translation error = 9.336, rotation error = 6.163, time/batch = 0.976\n",
      "63600/92100, translation error = 9.300, rotation error = 6.157, time/batch = 0.952\n",
      "63900/92100, translation error = 9.268, rotation error = 6.147, time/batch = 0.975\n",
      "64200/92100, translation error = 10.041, rotation error = 6.300, time/batch = 0.947\n",
      "64500/92100, translation error = 10.226, rotation error = 6.456, time/batch = 0.977\n",
      "64800/92100, translation error = 10.189, rotation error = 6.454, time/batch = 0.943\n",
      "65100/92100, translation error = 10.166, rotation error = 6.461, time/batch = 0.979\n",
      "65400/92100, translation error = 10.129, rotation error = 6.443, time/batch = 0.949\n",
      "65700/92100, translation error = 10.096, rotation error = 6.434, time/batch = 0.979\n",
      "66000/92100, translation error = 10.069, rotation error = 6.445, time/batch = 0.949\n",
      "66300/92100, translation error = 10.034, rotation error = 6.439, time/batch = 0.981\n",
      "66600/92100, translation error = 10.000, rotation error = 6.427, time/batch = 0.949\n",
      "66900/92100, translation error = 10.007, rotation error = 6.443, time/batch = 0.976\n",
      "67200/92100, translation error = 9.985, rotation error = 6.448, time/batch = 0.945\n",
      "67500/92100, translation error = 9.958, rotation error = 6.473, time/batch = 0.977\n",
      "67800/92100, translation error = 9.922, rotation error = 6.461, time/batch = 0.947\n",
      "68100/92100, translation error = 9.888, rotation error = 6.441, time/batch = 0.979\n",
      "68400/92100, translation error = 9.855, rotation error = 6.451, time/batch = 0.947\n",
      "68700/92100, translation error = 9.825, rotation error = 6.442, time/batch = 0.979\n",
      "69000/92100, translation error = 9.798, rotation error = 6.433, time/batch = 0.948\n",
      "69300/92100, translation error = 9.791, rotation error = 6.438, time/batch = 0.978\n",
      "69600/92100, translation error = 9.779, rotation error = 6.434, time/batch = 0.948\n",
      "69900/92100, translation error = 9.781, rotation error = 6.429, time/batch = 0.983\n",
      "70200/92100, translation error = 9.749, rotation error = 6.416, time/batch = 0.949\n",
      "70500/92100, translation error = 9.714, rotation error = 6.410, time/batch = 0.978\n",
      "70800/92100, translation error = 9.681, rotation error = 6.399, time/batch = 0.949\n",
      "71100/92100, translation error = 9.650, rotation error = 6.392, time/batch = 0.980\n",
      "71400/92100, translation error = 9.616, rotation error = 6.380, time/batch = 0.950\n",
      "71700/92100, translation error = 9.585, rotation error = 6.370, time/batch = 0.981\n",
      "72000/92100, translation error = 9.557, rotation error = 6.357, time/batch = 0.950\n",
      "72300/92100, translation error = 9.529, rotation error = 6.352, time/batch = 0.978\n",
      "72600/92100, translation error = 9.496, rotation error = 6.341, time/batch = 0.946\n",
      "72900/92100, translation error = 9.467, rotation error = 6.339, time/batch = 0.978\n",
      "73200/92100, translation error = 9.440, rotation error = 6.332, time/batch = 0.948\n",
      "73500/92100, translation error = 9.410, rotation error = 6.333, time/batch = 0.980\n",
      "73800/92100, translation error = 9.410, rotation error = 6.333, time/batch = 0.949\n",
      "74100/92100, translation error = 9.387, rotation error = 6.324, time/batch = 0.979\n",
      "74400/92100, translation error = 9.423, rotation error = 6.341, time/batch = 0.950\n",
      "74700/92100, translation error = 9.622, rotation error = 6.504, time/batch = 0.980\n",
      "75000/92100, translation error = 9.595, rotation error = 6.514, time/batch = 0.948\n",
      "75300/92100, translation error = 9.749, rotation error = 6.582, time/batch = 0.981\n",
      "75600/92100, translation error = 9.761, rotation error = 6.587, time/batch = 0.949\n",
      "75900/92100, translation error = 9.735, rotation error = 6.575, time/batch = 0.985\n",
      "76200/92100, translation error = 9.711, rotation error = 6.563, time/batch = 0.947\n",
      "76500/92100, translation error = 9.682, rotation error = 6.548, time/batch = 0.980\n",
      "76800/92100, translation error = 9.672, rotation error = 6.546, time/batch = 0.949\n",
      "77100/92100, translation error = 9.688, rotation error = 6.543, time/batch = 0.981\n",
      "77400/92100, translation error = 9.795, rotation error = 6.562, time/batch = 0.948\n",
      "77700/92100, translation error = 10.110, rotation error = 6.629, time/batch = 0.981\n",
      "78000/92100, translation error = 10.241, rotation error = 6.720, time/batch = 0.949\n",
      "78300/92100, translation error = 10.273, rotation error = 6.721, time/batch = 0.979\n",
      "78600/92100, translation error = 10.293, rotation error = 6.741, time/batch = 0.946\n",
      "78900/92100, translation error = 10.294, rotation error = 6.742, time/batch = 0.977\n",
      "79200/92100, translation error = 10.495, rotation error = 6.847, time/batch = 0.945\n",
      "79500/92100, translation error = 11.010, rotation error = 6.873, time/batch = 0.983\n",
      "79800/92100, translation error = 10.982, rotation error = 6.878, time/batch = 0.945\n",
      "80100/92100, translation error = 10.959, rotation error = 6.890, time/batch = 0.989\n",
      "80400/92100, translation error = 10.928, rotation error = 6.884, time/batch = 0.944\n",
      "80700/92100, translation error = 11.027, rotation error = 6.967, time/batch = 0.978\n",
      "81000/92100, translation error = 10.999, rotation error = 6.961, time/batch = 0.949\n",
      "81300/92100, translation error = 11.005, rotation error = 7.044, time/batch = 0.975\n",
      "81600/92100, translation error = 11.042, rotation error = 7.068, time/batch = 0.944\n",
      "81900/92100, translation error = 11.018, rotation error = 7.069, time/batch = 0.980\n",
      "82200/92100, translation error = 10.995, rotation error = 7.066, time/batch = 0.949\n",
      "82500/92100, translation error = 10.978, rotation error = 7.057, time/batch = 0.978\n",
      "82800/92100, translation error = 10.972, rotation error = 7.078, time/batch = 0.948\n",
      "83100/92100, translation error = 10.948, rotation error = 7.081, time/batch = 0.979\n",
      "83400/92100, translation error = 10.939, rotation error = 7.071, time/batch = 0.946\n",
      "83700/92100, translation error = 10.919, rotation error = 7.060, time/batch = 0.982\n",
      "84000/92100, translation error = 10.913, rotation error = 7.077, time/batch = 0.947\n",
      "84300/92100, translation error = 10.919, rotation error = 7.154, time/batch = 0.978\n",
      "84600/92100, translation error = 10.890, rotation error = 7.149, time/batch = 0.947\n",
      "84900/92100, translation error = 10.862, rotation error = 7.143, time/batch = 0.979\n",
      "85200/92100, translation error = 10.834, rotation error = 7.138, time/batch = 0.944\n",
      "85500/92100, translation error = 10.803, rotation error = 7.125, time/batch = 0.982\n",
      "85800/92100, translation error = 10.774, rotation error = 7.117, time/batch = 0.947\n",
      "86100/92100, translation error = 10.904, rotation error = 7.203, time/batch = 0.979\n",
      "86400/92100, translation error = 10.875, rotation error = 7.194, time/batch = 0.949\n",
      "86700/92100, translation error = 10.849, rotation error = 7.179, time/batch = 0.976\n",
      "87000/92100, translation error = 10.821, rotation error = 7.164, time/batch = 0.947\n",
      "87300/92100, translation error = 10.806, rotation error = 7.157, time/batch = 0.976\n",
      "87600/92100, translation error = 10.840, rotation error = 7.177, time/batch = 0.944\n",
      "87900/92100, translation error = 10.835, rotation error = 7.205, time/batch = 0.980\n",
      "88200/92100, translation error = 10.928, rotation error = 7.273, time/batch = 0.946\n",
      "88500/92100, translation error = 10.897, rotation error = 7.273, time/batch = 0.981\n",
      "88800/92100, translation error = 10.983, rotation error = 7.276, time/batch = 0.949\n",
      "89100/92100, translation error = 11.076, rotation error = 7.297, time/batch = 0.979\n",
      "89400/92100, translation error = 11.049, rotation error = 7.294, time/batch = 0.945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89700/92100, translation error = 11.022, rotation error = 7.295, time/batch = 0.980\n",
      "90000/92100, translation error = 11.064, rotation error = 7.293, time/batch = 0.948\n",
      "90300/92100, translation error = 11.035, rotation error = 7.278, time/batch = 0.978\n",
      "90600/92100, translation error = 11.016, rotation error = 7.285, time/batch = 0.947\n",
      "90900/92100, translation error = 10.989, rotation error = 7.281, time/batch = 0.978\n",
      "91200/92100, translation error = 10.971, rotation error = 7.285, time/batch = 0.946\n",
      "91500/92100, translation error = 10.950, rotation error = 7.289, time/batch = 0.976\n",
      "91800/92100, translation error = 10.920, rotation error = 7.280, time/batch = 0.946\n",
      "92100/92100, translation error = 10.909, rotation error = 7.285, time/batch = 2.282\n"
     ]
    }
   ],
   "source": [
    "trainer.model.eval()\n",
    "\n",
    "for b, data in enumerate(dataloader, 0):\n",
    "    start = time.time()\n",
    "    x,y = data.values()\n",
    "    trans_pred, rot_pred, trans_gt, rot_gt, samples = trainer.eval_forward(x,y)\n",
    "    \n",
    "    # transform data\n",
    "    trans_pred = trans_pred.cpu().numpy()\n",
    "    rot_pred = rot_pred.cpu().numpy()\n",
    "    trans_gt = trans_gt.cpu().numpy()\n",
    "    rot_gt = rot_gt.cpu().numpy()\n",
    "    \n",
    "    end = time.time()\n",
    "    \n",
    "    if args.enable_ros:\n",
    "        particles = PoseArray()\n",
    "        particles.header.stamp = rospy.Time.now()\n",
    "        particles.header.frame_id = 'world'\n",
    "        for s in samples:\n",
    "            pose = Pose()\n",
    "            [pose.position.x, pose.position.y, pose.position.z] = s\n",
    "            [pose.orientation.x, pose.orientation.y, pose.orientation.z, pose.orientation.w] = rot_pred[0]\n",
    "            particles.poses.append(pose)\n",
    "        particles_pub.publish(particles)\n",
    "\n",
    "        [px_pred, py_pred, pz_pred] = trans_pred[0]\n",
    "        [qx_pred, qy_pred, qz_pred, qw_pred] = rot_pred[0]\n",
    "\n",
    "        br.sendTransform((px_pred, py_pred, pz_pred),\n",
    "                         (qx_pred, qy_pred, qz_pred, qw_pred), rospy.Time.now(),\n",
    "                         \"estimation\", \"world\")\n",
    "\n",
    "        [px_gt, py_gt, pz_gt] = trans_gt[0]\n",
    "        [qx_gt, qy_gt, qz_gt, qw_gt] = rot_gt[0]\n",
    "\n",
    "        br.sendTransform((px_gt, py_gt, pz_gt),\n",
    "                         (qx_gt, qy_gt, qz_gt, qw_gt),\n",
    "                         rospy.Time.now(), \"gt\", \"world\")\n",
    "\n",
    "        timestamp = rospy.Time.now()\n",
    "\n",
    "        nn_pose_msg = Odometry()\n",
    "        nn_pose_msg.header.frame_id = 'world'\n",
    "        nn_pose_msg.header.stamp = timestamp\n",
    "        nn_pose_msg.child_frame_id = 'base_link'\n",
    "        nn_pose_msg.pose.pose.position.x = px_pred\n",
    "        nn_pose_msg.pose.pose.position.y = py_pred\n",
    "        nn_pose_msg.pose.pose.position.z = pz_pred\n",
    "        [nn_pose_msg.pose.pose.orientation.x, nn_pose_msg.pose.pose.orientation.y, nn_pose_msg.pose.pose.orientation.z, nn_pose_msg.pose.pose.orientation.w] = [qx_pred, qy_pred, qz_pred, qw_pred]\n",
    "\n",
    "        conv = np.zeros((6,6), dtype=np.float32)\n",
    "        [conv[0][0], conv[1][1], conv[2][2]] = trans_cov[0]\n",
    "        nn_pose_msg.pose.covariance = conv.flatten().tolist()\n",
    "        nn_pose_pub.publish(nn_pose_msg)\n",
    "\n",
    "        bridge = CvBridge()\n",
    "\n",
    "        bird_view_img_msg = bridge.cv2_to_imgmsg(np.asarray(x[0].cpu(), dtype=np.float32), encoding=\"passthrough\")\n",
    "        stamp_now = rospy.Time.now()\n",
    "        bird_view_img_msg.header.stamp = stamp_now\n",
    "\n",
    "        bird_view_pub.publish(bird_view_img_msg)\n",
    "\n",
    "        rospy.sleep(.0)\n",
    "        cv2.waitKey(0)\n",
    "\n",
    "        count += 1\n",
    "    else:\n",
    "        count += y.shape[0]\n",
    "    \n",
    "    trans_preds += [x for x in trans_pred]\n",
    "    rot_preds += [x for x in rot_pred]\n",
    "    trans_gts += [x for x in trans_gt]\n",
    "    rot_gts += [x for x in rot_gt]\n",
    "\n",
    "    trans_error = np.sqrt(np.sum((trans_pred - trans_gt)**2,axis=1))\n",
    "    rot_error_1 = np.arccos(np.sum(np.multiply(rot_pred,rot_gt),axis=1))/math.pi*180\n",
    "    rot_error_2 = np.arccos(np.sum(np.multiply(rot_pred,-rot_gt),axis=1))/math.pi*180\n",
    "    rot_error = np.minimum(rot_error_1,rot_error_2)\n",
    "\n",
    "    trans_errors += [x for x in trans_error]\n",
    "    rot_errors += [x for x in rot_error]\n",
    "\n",
    "    total_trans_error += np.sum(trans_error)\n",
    "    total_rot_error += np.sum(rot_error)\n",
    "    \n",
    "    display = 1\n",
    "\n",
    "    if b % display == 0:\n",
    "        print(\n",
    "            \"{}/{}, translation error = {:.3f}, rotation error = {:.3f}, time/batch = {:.3f}\"\n",
    "            .format(\n",
    "             (b+1)*args.batch_size,\n",
    "            len(dataloader)*args.batch_size,\n",
    "            total_trans_error / count,\n",
    "            total_rot_error / count,\n",
    "            end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-25T19:58:56.395572Z",
     "start_time": "2020-07-25T19:58:37.951808Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "median translation error = 2.113\n",
      "median rotation error = 3.710\n",
      "mean translation error = 10.909\n",
      "mean rotation error = 7.285\n"
     ]
    }
   ],
   "source": [
    "sio.savemat('results.mat', {'trans_pred': np.array(trans_preds), 'trans_gt': np.array(trans_gts), 'uncertainty': np.array(pred_uncertainties)})\n",
    "\n",
    "if len(pose_map):\n",
    "    np.savetxt(os.path.join(args.map_dataset, 'map.txt'), np.asarray(pose_map, dtype=np.float32))\n",
    "    print(\"map is saved!\")\n",
    "\n",
    "plt.hist(trans_errors, bins='auto')\n",
    "plt.title(\"Translation errors\")\n",
    "plt.xlabel(\"translational error in meters\")\n",
    "plt.ylabel(\"number of frames\")\n",
    "plt.savefig('terror.png', bbox_inches='tight')\n",
    "\n",
    "plt.hist(rot_errors, bins='auto')\n",
    "plt.title(\"Rotation errors\")\n",
    "plt.xlabel(\"rotational error in degree\")\n",
    "plt.ylabel(\"number of frames\")\n",
    "plt.savefig('rerror.png', bbox_inches='tight')\n",
    "\n",
    "median_trans_errors = np.median(trans_errors)\n",
    "median_rot_errors = np.median(rot_errors)\n",
    "mean_trans_errors = np.mean(trans_errors)\n",
    "mean_rot_errors = np.mean(rot_errors)\n",
    "\n",
    "print(\"median translation error = {:.3f}\".format(median_trans_errors))\n",
    "print(\"median rotation error = {:.3f}\".format(median_rot_errors))\n",
    "print(\"mean translation error = {:.3f}\".format(mean_trans_errors))\n",
    "print(\"mean rotation error = {:.3f}\".format(mean_rot_errors))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-25T12:36:01.454086Z",
     "start_time": "2020-07-25T12:36:01.439777Z"
    }
   },
   "outputs": [],
   "source": [
    "np.save('trans_errors_gp10.npy',trans_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-25T20:44:41.236805Z",
     "start_time": "2020-07-25T20:44:41.220535Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2233.9624"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.var(trans_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-25T19:59:18.421497Z",
     "start_time": "2020-07-25T19:59:18.281833Z"
    },
    "code_folding": [],
    "run_control": {
     "marked": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================== var translation error ==================\n",
      "var translation error = 390.652\n",
      "var translation error = 437.647\n",
      "var translation error = 2256.500\n",
      "var translation error = 2251.426\n",
      "var translation error = 2630.908\n",
      "var translation error = 3876.378\n",
      "var translation error = 2269.889\n",
      "var translation error = 2763.553\n",
      "================== median translation error ==================\n",
      "median translation error = 1.622\n",
      "median translation error = 1.739\n",
      "median translation error = 1.977\n",
      "median translation error = 1.967\n",
      "median translation error = 2.063\n",
      "median translation error = 2.200\n",
      "median translation error = 3.484\n",
      "median translation error = 2.972\n",
      "================== median rotation error ==================\n",
      "median rotation error = 3.070\n",
      "median rotation error = 3.356\n",
      "median rotation error = 3.379\n",
      "median rotation error = 3.422\n",
      "median rotation error = 3.907\n",
      "median rotation error = 3.701\n",
      "median rotation error = 5.095\n",
      "median rotation error = 4.944\n",
      "================== mean translation error ==================\n",
      "mean translation error = 4.118\n",
      "mean translation error = 4.474\n",
      "mean translation error = 12.654\n",
      "mean translation error = 11.844\n",
      "mean translation error = 9.985\n",
      "mean translation error = 12.584\n",
      "mean translation error = 20.377\n",
      "mean translation error = 13.369\n",
      "================== mean rotation error ==================\n",
      "mean rotation error = 4.790\n",
      "mean rotation error = 4.952\n",
      "mean rotation error = 6.394\n",
      "mean rotation error = 6.643\n",
      "mean rotation error = 7.022\n",
      "mean rotation error = 7.695\n",
      "mean rotation error = 12.116\n",
      "mean rotation error = 9.865\n"
     ]
    }
   ],
   "source": [
    "def evaluate(trans_errors,rot_errors):\n",
    "    t = [14301,7008,12852,9567,13580,14835,7114,12683]\n",
    "    for i in range(len(t)):\n",
    "        if i >0:\n",
    "            t[i] += t[i-1]\n",
    "    trans_errors_month = list()\n",
    "    trans_errors_month.append(trans_errors[:t[0]])\n",
    "    trans_errors_month.append(trans_errors[t[0]:t[1]])\n",
    "    trans_errors_month.append(trans_errors[t[1]:t[2]])\n",
    "    trans_errors_month.append(trans_errors[t[2]:t[3]])\n",
    "    trans_errors_month.append(trans_errors[t[3]:t[4]])\n",
    "    trans_errors_month.append(trans_errors[t[4]:t[5]])\n",
    "    trans_errors_month.append(trans_errors[t[5]:t[6]])\n",
    "    trans_errors_month.append(trans_errors[t[6]:])\n",
    "\n",
    "    rot_errors_month = list()\n",
    "    rot_errors_month.append(rot_errors[:t[0]])\n",
    "    rot_errors_month.append(rot_errors[t[0]:t[1]])\n",
    "    rot_errors_month.append(rot_errors[t[1]:t[2]])\n",
    "    rot_errors_month.append(rot_errors[t[2]:t[3]])\n",
    "    rot_errors_month.append(rot_errors[t[3]:t[4]])\n",
    "    rot_errors_month.append(rot_errors[t[4]:t[5]])\n",
    "    rot_errors_month.append(rot_errors[t[5]:t[6]])\n",
    "    rot_errors_month.append(rot_errors[t[6]:])\n",
    "    \n",
    "    print('================== var translation error ==================')\n",
    "    for trans_errors_i in trans_errors_month:\n",
    "        print(\"var translation error = {:.3f}\".format(np.var(trans_errors_i)))\n",
    "    \n",
    "    print('================== median translation error ==================')\n",
    "    for trans_errors_i in trans_errors_month:\n",
    "        print(\"median translation error = {:.3f}\".format(np.median(trans_errors_i)))\n",
    "        \n",
    "    print('================== median rotation error ==================')\n",
    "    for rot_errors_i in rot_errors_month:\n",
    "        print(\"median rotation error = {:.3f}\".format(np.median(rot_errors_i)))\n",
    "    \n",
    "    print('================== mean translation error ==================')\n",
    "    for trans_errors_i in trans_errors_month:\n",
    "        print(\"mean translation error = {:.3f}\".format(np.mean(trans_errors_i)))\n",
    "        \n",
    "    print('================== mean rotation error ==================')  \n",
    "    for rot_errors_i in rot_errors_month:\n",
    "        print(\"mean rotation error = {:.3f}\".format(np.mean(rot_errors_i)))\n",
    "        \n",
    "evaluate(trans_errors,rot_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "nbTranslate": {
   "displayLangs": [
    "en"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
