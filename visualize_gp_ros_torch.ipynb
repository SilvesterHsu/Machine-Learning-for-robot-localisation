{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T09:00:20.565552Z",
     "start_time": "2020-06-17T09:00:19.122720Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "the rosdep view is empty: call 'sudo rosdep init' and 'rosdep update'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#import os\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\"\n",
    "import torch\n",
    "import argparse\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "#from src.self_awareness.networks import utils\n",
    "#from src.self_awareness.learning.tf_cnn_auxiliary_gp import Model\n",
    "from torch.distributions import Normal\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "import roslib\n",
    "import rospy\n",
    "import tf as tf_ros\n",
    "from nav_msgs.msg import Odometry, Path\n",
    "from sensor_msgs.msg import Image\n",
    "from cv_bridge import CvBridge\n",
    "from geometry_msgs.msg import PoseStamped, PoseArray, Pose\n",
    "import math\n",
    "import cv2\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T09:00:21.017928Z",
     "start_time": "2020-06-17T09:00:20.567207Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TITAN Xp\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(torch.cuda.get_device_name(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set torch default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T09:00:21.024559Z",
     "start_time": "2020-06-17T09:00:21.020149Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "torch.set_default_dtype(torch.float32)\n",
    "torch.set_printoptions(precision=4,sci_mode=False)\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init ROS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T09:00:21.174132Z",
     "start_time": "2020-06-17T09:00:21.026295Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "rospy.init_node('global_localization_tf_broadcaster_cnn_gp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T09:00:21.188401Z",
     "start_time": "2020-06-17T09:00:21.176575Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--batch_size', type=int, default=1, help='size of mini batch')\n",
    "parser.add_argument('--target_image_size', default=[300, 300], nargs=2, type=int, help='Input images will be resized to this for data argumentation.')\n",
    "\n",
    "parser.add_argument('--model_dir', type=str, default='/notebooks/global_localization/gp_net_torch', help='model directory')\n",
    "\n",
    "parser.add_argument('--test_dataset', type=str, default=[# '/notebooks/michigan_nn_data/2012_01_08',\n",
    "                                                         # '/notebooks/michigan_nn_data/2012_01_15',\n",
    "                                                         # '/notebooks/michigan_nn_data/2012_01_22',\n",
    "                                                         # '/notebooks/michigan_nn_data/2012_02_02',\n",
    "                                                         # '/notebooks/michigan_nn_data/2012_02_04',\n",
    "                                                         # '/notebooks/michigan_nn_data/2012_02_05',\n",
    "                                                         '/notebooks/michigan_nn_data/2012_02_12',\n",
    "                                                         # '/notebooks/michigan_nn_data/2012_03_31',\n",
    "                                                         '/notebooks/michigan_nn_data/2012_04_29',\n",
    "                                                         '/notebooks/michigan_nn_data/2012_05_11',\n",
    "                                                         '/notebooks/michigan_nn_data/2012_06_15',\n",
    "                                                         '/notebooks/michigan_nn_data/2012_08_04',\n",
    "                                                         # '/notebooks/michigan_nn_data/2012_09_28'])\n",
    "                                                         '/notebooks/michigan_nn_data/2012_10_28',\n",
    "                                                         '/notebooks/michigan_nn_data/2012_11_16',\n",
    "                                                         '/notebooks/michigan_nn_data/2012_12_01'\n",
    "                                                        ] )\n",
    "\n",
    "parser.add_argument('--train_dataset', type=str, default = ['/notebooks/michigan_nn_data/test'])\n",
    "#parser.add_argument('--map_dataset', type=str, default='/home/kevin/data/michigan_gt/training')\n",
    "sys.argv = ['']\n",
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T09:02:22.704909Z",
     "start_time": "2020-06-17T09:00:21.190118Z"
    },
    "run_control": {
     "marked": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14301/14301 [00:18<00:00, 756.50it/s]\n",
      "100%|██████████| 7008/7008 [00:09<00:00, 756.50it/s]\n",
      "100%|██████████| 12852/12852 [00:16<00:00, 760.33it/s]\n",
      "100%|██████████| 9567/9567 [00:12<00:00, 756.37it/s]\n",
      "100%|██████████| 13580/13580 [00:17<00:00, 770.30it/s]\n",
      "100%|██████████| 14835/14835 [00:19<00:00, 765.20it/s]\n",
      "100%|██████████| 7114/7114 [00:09<00:00, 755.54it/s]\n",
      "100%|██████████| 12683/12683 [00:16<00:00, 751.54it/s]\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import tf.transformations as tf_tran\n",
    "from tqdm import tqdm\n",
    "#from PIL import Image\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "#import gpflow.multioutput.kernels as mk\n",
    "import gpytorch\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchlib import resnet, vggnet\n",
    "from torchlib.utils import LocalizationDataset\n",
    "import time\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "dataset = LocalizationDataset(dataset_dirs = args.test_dataset, \\\n",
    "                              image_size = args.target_image_size, \\\n",
    "                              transform = transform,\n",
    "                              get_pair = False, mode='evaluate')\n",
    "#[args.norm_mean, args.norm_std] = [torch.tensor(x) for x in dataset.get_norm()]\n",
    "args.norm_mean = torch.Tensor([-114.69805908,  405.21035767,   -8.72568321])\n",
    "args.norm_std = torch.Tensor([119.66057587, 176.14263916,   4.68300915])\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=args.batch_size, \\\n",
    "                        shuffle=False, num_workers=0, \\\n",
    "                        drop_last=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T09:02:22.825264Z",
     "start_time": "2020-06-17T09:02:22.731378Z"
    },
    "code_folding": [
     0,
     6,
     13,
     19,
     32,
     67
    ],
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "def denormalize_navie(normed_target, norm_mean, norm_std):\n",
    "    target_trans_unscaled = normed_target * norm_std\n",
    "    target_trans_uncentered = target_trans_unscaled + norm_mean\n",
    "    \n",
    "    return target_trans_uncentered\n",
    "\n",
    "def denormalize(normed_target, norm_mean, norm_std):\n",
    "    normed_target_trans, normed_target_rot = torch.split(normed_target, [3,4], dim=1)\n",
    "    target_trans_unscaled = normed_target_trans * norm_std\n",
    "    target_trans_uncentered = target_trans_unscaled + norm_mean\n",
    "    target = torch.cat([target_trans_uncentered, normed_target_rot],dim=1)\n",
    "    return target\n",
    "\n",
    "def normalize(target, norm_mean, norm_std):\n",
    "    target_trans = target[:,:3]\n",
    "    target_trans = torch.div(torch.sub(target_trans,norm_mean),norm_std)\n",
    "    target_normed = torch.cat([target_trans,target[:,3:]],dim=1)\n",
    "    return target_normed \n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.resnet = resnet.resnet50(pretrained=True)\n",
    "        self.global_context = vggnet.vggnet(input_channel=2048,opt=\"context\")\n",
    "        self.global_regressor = vggnet.vggnet(opt=\"regressor\")\n",
    "        \n",
    "    def forward(self,input_data):\n",
    "        dense_feat = self.resnet(input_data)\n",
    "        global_context_feat = self.global_context(dense_feat)\n",
    "        global_output, trans_feat, rot_feat = self.global_regressor(global_context_feat)\n",
    "        return global_output, trans_feat, rot_feat\n",
    "    \n",
    "class MultitaskGPModel(gpytorch.models.ApproximateGP):\n",
    "    def __init__(self, inducing_points):\n",
    "        # We have to mark the CholeskyVariationalDistribution as batch\n",
    "        # so that we learn a variational distribution for each task\n",
    "        variational_distribution = gpytorch.variational.CholeskyVariationalDistribution(\n",
    "            inducing_points.size(-2), batch_shape=torch.Size([3])\n",
    "        )\n",
    "\n",
    "        # We have to wrap the VariationalStrategy in a MultitaskVariationalStrategy\n",
    "        # so that the output will be a MultitaskMultivariateNormal rather than a batch output\n",
    "        variational_strategy = gpytorch.variational.MultitaskVariationalStrategy(\n",
    "            gpytorch.variational.VariationalStrategy(\n",
    "                self, inducing_points, variational_distribution, learn_inducing_locations=True\n",
    "            ), num_tasks=3\n",
    "        )\n",
    "\n",
    "        super().__init__(variational_strategy)\n",
    "\n",
    "        # The mean and covariance modules should be marked as batch\n",
    "        # so we learn a different set of hyperparameters\n",
    "        #self.net = Model()\n",
    "        #self.net.load_state_dict(torch.load(os.path.join(args.model_dir,'model-23-96000.pth')))\n",
    "        self.mean_module = gpytorch.means.ConstantMean(batch_shape=torch.Size([3]))\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(\n",
    "            gpytorch.kernels.RBFKernel(batch_shape=torch.Size([3])),\n",
    "            batch_shape=torch.Size([3])\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # The forward function should be written as if we were dealing with each output\n",
    "        # dimension in batch\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "    \n",
    "class GPModel(gpytorch.Module):\n",
    "    def __init__(self, inducing_points):\n",
    "        super(GPModel, self).__init__()\n",
    "        self.net = Model()\n",
    "        #self.net.load_state_dict(torch.load(os.path.join('/notebooks/global_localization/dual_resnet_torch','model-23-96000.pth')))\n",
    "        self.gp = MultitaskGPModel(inducing_points)\n",
    "        self.likelihood = gpytorch.likelihoods.MultitaskGaussianLikelihood(num_tasks=3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        global_output, trans_feat, _ = self.net(x)\n",
    "        _, rot_pred = torch.split(global_output, [3, 4], dim=1)\n",
    "        output = self.gp(trans_feat)\n",
    "        \n",
    "        return output,rot_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T09:02:28.163213Z",
     "start_time": "2020-06-17T09:02:22.835691Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = torch.device(\"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.set_device(device)\n",
    "\n",
    "#model = GPModel(torch.zeros(3, args.batch_size, 128)).to(device)\n",
    "model = GPModel(torch.zeros(3, 300, 128)).to(device)\n",
    "model.load_state_dict(torch.load(os.path.join(args.model_dir,'model-111-47500.pth')))\n",
    "\n",
    "# Disable resnet\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T09:02:28.179600Z",
     "start_time": "2020-06-17T09:02:28.174852Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "args.norm_mean = args.norm_mean.to(device)\n",
    "args.norm_std = args.norm_std.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T09:02:28.200419Z",
     "start_time": "2020-06-17T09:02:28.181220Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "trans_errors = []\n",
    "rot_errors = []\n",
    "uncertainties = []\n",
    "pose_map = []\n",
    "\n",
    "total_trans_error = 0.\n",
    "total_rot_error = 0.\n",
    "\n",
    "count = 0.\n",
    "\n",
    "is_save_map = False\n",
    "is_read_map = False\n",
    "\n",
    "trans_preds = []\n",
    "trans_gts = []\n",
    "\n",
    "rot_preds = []\n",
    "rot_gts = []\n",
    "\n",
    "pred_uncertainties = []\n",
    "\n",
    "pred_time = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T09:02:28.332559Z",
     "start_time": "2020-06-17T09:02:28.206669Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "br = tf_ros.TransformBroadcaster()\n",
    "\n",
    "GT_POSE_TOPIC = '/gt_pose'\n",
    "BIRDVIEW_TOPIC_PUB = '/bird_view'\n",
    "MAP_TOPIC_PUB = '/pose_map'\n",
    "PARTICLES_PUB = '/particles'\n",
    "NN_LOCALIZASION_PUB = '/nn_pose'\n",
    "gt_pose_pub = rospy.Publisher(GT_POSE_TOPIC, Odometry, queue_size=1)\n",
    "bird_view_pub = rospy.Publisher(BIRDVIEW_TOPIC_PUB, Image, queue_size=1)\n",
    "map_pub = rospy.Publisher(MAP_TOPIC_PUB, Path, queue_size=1)\n",
    "particles_pub = rospy.Publisher(PARTICLES_PUB, PoseArray, queue_size=1)\n",
    "nn_pose_pub = rospy.Publisher(NN_LOCALIZASION_PUB, Odometry, queue_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T09:02:28.389798Z",
     "start_time": "2020-06-17T09:02:28.338297Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPModel(\n",
       "  (net): Model(\n",
       "    (resnet): ResNet(\n",
       "      (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (layer1): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (global_context): vggnet(\n",
       "      (context): Context(\n",
       "        (squeeze): Sequential(\n",
       "          (0): Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ReLU()\n",
       "        )\n",
       "        (context5_1): Sequential(\n",
       "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "        )\n",
       "        (context5_2): Sequential(\n",
       "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "        )\n",
       "        (context5_3): Sequential(\n",
       "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "        )\n",
       "        (context5_4): Sequential(\n",
       "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU()\n",
       "        )\n",
       "        (squeeze2): Sequential(\n",
       "          (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (1): ReLU()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (global_regressor): vggnet(\n",
       "      (regressor): Regressor(\n",
       "        (flatten): Flatten()\n",
       "        (fc1_trans): Sequential(\n",
       "          (0): Linear(in_features=6400, out_features=4096, bias=True)\n",
       "          (1): ReLU()\n",
       "        )\n",
       "        (fc2_trans): Sequential(\n",
       "          (0): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "          (1): ReLU()\n",
       "        )\n",
       "        (fc3_trans): Sequential(\n",
       "          (0): Linear(in_features=4096, out_features=128, bias=True)\n",
       "          (1): ReLU()\n",
       "        )\n",
       "        (logits_t): Linear(in_features=128, out_features=3, bias=True)\n",
       "        (fc1_rot): Sequential(\n",
       "          (0): Linear(in_features=6400, out_features=4096, bias=True)\n",
       "          (1): ReLU()\n",
       "        )\n",
       "        (fc2_rot): Sequential(\n",
       "          (0): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "          (1): ReLU()\n",
       "        )\n",
       "        (fc3_rot): Sequential(\n",
       "          (0): Linear(in_features=4096, out_features=128, bias=True)\n",
       "          (1): ReLU()\n",
       "        )\n",
       "        (logits_r): Linear(in_features=128, out_features=4, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (gp): MultitaskGPModel(\n",
       "    (variational_strategy): MultitaskVariationalStrategy(\n",
       "      (base_variational_strategy): VariationalStrategy(\n",
       "        (_variational_distribution): CholeskyVariationalDistribution()\n",
       "      )\n",
       "    )\n",
       "    (mean_module): ConstantMean()\n",
       "    (covar_module): ScaleKernel(\n",
       "      (base_kernel): RBFKernel(\n",
       "        (raw_lengthscale_constraint): Positive()\n",
       "      )\n",
       "      (raw_outputscale_constraint): Positive()\n",
       "    )\n",
       "  )\n",
       "  (likelihood): MultitaskGaussianLikelihood(\n",
       "    (noise_covar): MultitaskHomoskedasticNoise(\n",
       "      (raw_noise_constraint): GreaterThan(1.000E-04)\n",
       "    )\n",
       "    (raw_noise_constraint): GreaterThan(1.000E-04)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T09:26:08.529659Z",
     "start_time": "2020-06-17T09:02:28.394991Z"
    },
    "code_folding": [],
    "run_control": {
     "marked": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_output(output,rot_pred,model,i=0):\n",
    "    c_mean, c_var = output.mean,output.variance\n",
    "    y_mean, y_var = model.likelihood(output).mean, model.likelihood(output).variance\n",
    "    \n",
    "    dist = Normal(c_mean, c_var.mul(args.norm_std))\n",
    "    samples = dist.sample([100]).view(100,3)\n",
    "\n",
    "    distribution_mean = c_mean\n",
    "    distribution_cov = c_var.mul(args.norm_std)\n",
    "    trans_prediction = denormalize_navie(y_mean,args.norm_mean,args.norm_std)\n",
    "    rot_prediction = rot_pred\n",
    "    #samples = denormalize_navie(samples,args.norm_mean,args.norm_std)\n",
    "    return trans_prediction, rot_prediction, distribution_mean, distribution_cov, samples\n",
    "\n",
    "for b, data in enumerate(dataloader, 0):\n",
    "    start = time.time()\n",
    "    x,y = data.values()\n",
    "    x,y = x.to(device),y.to(device)\n",
    "    #y = normalize(y,args.norm_mean, args.norm_std)\n",
    "    \n",
    "    # Get single data & transform data type\n",
    "    output,rot_pred = model(x)\n",
    "    rot_pred = rot_pred.cpu()\n",
    "    trans_pred, rot_pred, trans_mean, trans_cov, samples = get_output(output,rot_pred,model)\n",
    "    trans_pred = np.asarray(trans_pred.cpu())\n",
    "    rot_pred = np.asarray(rot_pred.cpu())\n",
    "    trans_mean = np.asarray(trans_mean.cpu())\n",
    "    trans_cov = np.asarray(trans_cov.cpu())\n",
    "    samples = np.asarray(samples.cpu())\n",
    "    \n",
    "    end = time.time()\n",
    "    pred_time.append(end-start)\n",
    "    \n",
    "    particles = PoseArray()\n",
    "    particles.header.stamp = rospy.Time.now()\n",
    "    particles.header.frame_id = 'world'\n",
    "    for s in samples:\n",
    "        pose = Pose()\n",
    "        [pose.position.x, pose.position.y, pose.position.z] = s\n",
    "        [pose.orientation.x, pose.orientation.y, pose.orientation.z, pose.orientation.w] = rot_pred[0]\n",
    "        particles.poses.append(pose)\n",
    "    particles_pub.publish(particles)\n",
    "    \n",
    "    y = np.asarray(y.cpu())\n",
    "    trans_gt = y[:, :3]\n",
    "    rot_gt = y[:, -4:]\n",
    "    [px_pred, py_pred, pz_pred] = trans_pred[0]\n",
    "    [qx_pred, qy_pred, qz_pred, qw_pred] = rot_pred[0]\n",
    "    \n",
    "    br.sendTransform((px_pred, py_pred, pz_pred),\n",
    "                     (qx_pred, qy_pred, qz_pred, qw_pred), rospy.Time.now(),\n",
    "                     \"estimation\", \"world\")\n",
    "    \n",
    "    [px_gt, py_gt, pz_gt] = trans_gt[0]\n",
    "    [qx_gt, qy_gt, qz_gt, qw_gt] = rot_gt[0]\n",
    "    \n",
    "    br.sendTransform((px_gt, py_gt, pz_gt),\n",
    "                     (qx_gt, qy_gt, qz_gt, qw_gt),\n",
    "                     rospy.Time.now(), \"gt\", \"world\")\n",
    "\n",
    "    timestamp = rospy.Time.now()\n",
    "    \n",
    "    nn_pose_msg = Odometry()\n",
    "    nn_pose_msg.header.frame_id = 'world'\n",
    "    nn_pose_msg.header.stamp = timestamp\n",
    "    nn_pose_msg.child_frame_id = 'base_link'\n",
    "    nn_pose_msg.pose.pose.position.x = px_pred\n",
    "    nn_pose_msg.pose.pose.position.y = py_pred\n",
    "    nn_pose_msg.pose.pose.position.z = pz_pred\n",
    "    [nn_pose_msg.pose.pose.orientation.x, nn_pose_msg.pose.pose.orientation.y, nn_pose_msg.pose.pose.orientation.z, nn_pose_msg.pose.pose.orientation.w] = [qx_pred, qy_pred, qz_pred, qw_pred]\n",
    "    \n",
    "    conv = np.zeros((6,6), dtype=np.float32)\n",
    "    [conv[0][0], conv[1][1], conv[2][2]] = trans_cov[0]\n",
    "    nn_pose_msg.pose.covariance = conv.flatten().tolist()\n",
    "    nn_pose_pub.publish(nn_pose_msg)\n",
    "    \n",
    "    bridge = CvBridge()\n",
    "\n",
    "    bird_view_img_msg = bridge.cv2_to_imgmsg(np.asarray(x[0].cpu(), dtype=np.float32), encoding=\"passthrough\")\n",
    "    stamp_now = rospy.Time.now()\n",
    "    bird_view_img_msg.header.stamp = stamp_now\n",
    "\n",
    "    bird_view_pub.publish(bird_view_img_msg)\n",
    "\n",
    "    rospy.sleep(.0)\n",
    "    cv2.waitKey(0)\n",
    "\n",
    "    count += 1\n",
    "    \n",
    "    trans_preds.append(trans_pred[0])\n",
    "    rot_preds.append(rot_pred[0])\n",
    "    trans_gts.append(trans_gt[0])\n",
    "    rot_gts.append(rot_gt[0])\n",
    "    \n",
    "    trans_error = np.sum((trans_pred[0] - trans_gt[0])**2)**0.5\n",
    "    rot_error_1 = np.arccos(np.dot(rot_pred[0], rot_gt[0])) / math.pi*180\n",
    "    rot_error_2 = np.arccos(np.dot(rot_pred[0], -rot_gt[0])) / math.pi * 180\n",
    "    rot_error = min(rot_error_1, rot_error_2)\n",
    "    \n",
    "    trans_errors.append(trans_error)\n",
    "    rot_errors.append(rot_error)\n",
    "    uncertainties.append(np.mean(np.sum(trans_cov[0]**2)**0.5) * 1000)\n",
    "    pred_uncertainties.append(trans_cov[0])\n",
    "    \n",
    "    total_trans_error += trans_error\n",
    "    total_rot_error += rot_error\n",
    "    \n",
    "    display = 50\n",
    "\n",
    "    if b % display == 0 and b > 0:\n",
    "        print(\n",
    "            \"{}/{}, translation error = {:.3f}, rotation error = {:.3f}, time/batch = {:.3f}\"\n",
    "            .format(\n",
    "             b,\n",
    "            len(dataloader),\n",
    "            total_trans_error / count,\n",
    "            total_rot_error / count,\n",
    "            end - start))\n",
    "\n",
    "print(\"pred time\", np.mean(np.array(pred_time)))\n",
    "print(\"time std\", np.std(np.array(pred_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T09:26:22.690137Z",
     "start_time": "2020-06-17T09:26:08.532968Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "median translation error = 2.869\n",
      "median rotation error = 2.385\n",
      "mean translation error = 12.665\n",
      "mean rotation error = 5.339\n"
     ]
    }
   ],
   "source": [
    "import scipy.io as sio\n",
    "\n",
    "sio.savemat('results.mat', {'trans_pred': np.array(trans_preds), 'trans_gt': np.array(trans_gts), 'uncertainty': np.array(pred_uncertainties)})\n",
    "\n",
    "if len(pose_map):\n",
    "    np.savetxt(os.path.join(args.map_dataset, 'map.txt'), np.asarray(pose_map, dtype=np.float32))\n",
    "    print(\"map is saved!\")\n",
    "\n",
    "plt.hist(trans_errors, bins='auto')\n",
    "plt.title(\"Translation errors\")\n",
    "plt.xlabel(\"translational error in meters\")\n",
    "plt.ylabel(\"number of frames\")\n",
    "plt.savefig('terror.png', bbox_inches='tight')\n",
    "\n",
    "plt.hist(rot_errors, bins='auto')\n",
    "plt.title(\"Rotation errors\")\n",
    "plt.xlabel(\"rotational error in degree\")\n",
    "plt.ylabel(\"number of frames\")\n",
    "plt.savefig('rerror.png', bbox_inches='tight')\n",
    "\n",
    "median_trans_errors = np.median(trans_errors)\n",
    "median_rot_errors = np.median(rot_errors)\n",
    "mean_trans_errors = np.mean(trans_errors)\n",
    "mean_rot_errors = np.mean(rot_errors)\n",
    "\n",
    "print(\"median translation error = {:.3f}\".format(median_trans_errors))\n",
    "print(\"median rotation error = {:.3f}\".format(median_rot_errors))\n",
    "print(\"mean translation error = {:.3f}\".format(mean_trans_errors))\n",
    "print(\"mean rotation error = {:.3f}\".format(mean_rot_errors))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T09:26:22.696176Z",
     "start_time": "2020-06-17T09:26:22.691881Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters: 111798088\n"
     ]
    }
   ],
   "source": [
    "print('Model parameters:', sum(param.numel() for param in model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T09:26:22.704805Z",
     "start_time": "2020-06-17T09:26:22.697804Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[14301, 21309, 34161, 43728, 57308, 72143, 79257, 91940]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = [14301,7008,12852,9567,13580,14835,7114,12683]\n",
    "for i in range(len(t)):\n",
    "    if i >0:\n",
    "        t[i] += t[i-1]\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T09:26:22.756360Z",
     "start_time": "2020-06-17T09:26:22.706363Z"
    }
   },
   "outputs": [],
   "source": [
    "trans_errors_month = list()\n",
    "trans_errors_month.append(trans_errors[:t[0]])\n",
    "trans_errors_month.append(trans_errors[t[0]:t[1]])\n",
    "trans_errors_month.append(trans_errors[t[1]:t[2]])\n",
    "trans_errors_month.append(trans_errors[t[2]:t[3]])\n",
    "trans_errors_month.append(trans_errors[t[3]:t[4]])\n",
    "trans_errors_month.append(trans_errors[t[4]:t[5]])\n",
    "trans_errors_month.append(trans_errors[t[5]:t[6]])\n",
    "trans_errors_month.append(trans_errors[t[6]:])\n",
    "\n",
    "rot_errors_month = list()\n",
    "rot_errors_month.append(rot_errors[:t[0]])\n",
    "rot_errors_month.append(rot_errors[t[0]:t[1]])\n",
    "rot_errors_month.append(rot_errors[t[1]:t[2]])\n",
    "rot_errors_month.append(rot_errors[t[2]:t[3]])\n",
    "rot_errors_month.append(rot_errors[t[3]:t[4]])\n",
    "rot_errors_month.append(rot_errors[t[4]:t[5]])\n",
    "rot_errors_month.append(rot_errors[t[5]:t[6]])\n",
    "rot_errors_month.append(rot_errors[t[6]:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T09:26:22.779811Z",
     "start_time": "2020-06-17T09:26:22.758021Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "median translation error = 2.374\n",
      "median translation error = 2.419\n",
      "median translation error = 2.604\n",
      "median translation error = 2.670\n",
      "median translation error = 2.740\n",
      "median translation error = 2.852\n",
      "median translation error = 4.313\n",
      "median translation error = 4.277\n"
     ]
    }
   ],
   "source": [
    "for trans_errors_i in trans_errors_month:\n",
    "    print(\"median translation error = {:.3f}\".format(np.median(trans_errors_i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T09:26:22.800753Z",
     "start_time": "2020-06-17T09:26:22.781389Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "median rotation error = 2.126\n",
      "median rotation error = 2.148\n",
      "median rotation error = 2.228\n",
      "median rotation error = 2.178\n",
      "median rotation error = 2.416\n",
      "median rotation error = 2.476\n",
      "median rotation error = 3.075\n",
      "median rotation error = 2.811\n"
     ]
    }
   ],
   "source": [
    "for rot_errors_i in rot_errors_month:\n",
    "    print(\"median rotation error = {:.3f}\".format(np.median(rot_errors_i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T09:26:22.818549Z",
     "start_time": "2020-06-17T09:26:22.802792Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean translation error = 6.121\n",
      "mean translation error = 3.765\n",
      "mean translation error = 12.955\n",
      "mean translation error = 12.409\n",
      "mean translation error = 10.259\n",
      "mean translation error = 12.323\n",
      "mean translation error = 27.868\n",
      "mean translation error = 19.310\n"
     ]
    }
   ],
   "source": [
    "for trans_errors_i in trans_errors_month:\n",
    "    print(\"mean translation error = {:.3f}\".format(np.mean(trans_errors_i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-17T09:26:22.842699Z",
     "start_time": "2020-06-17T09:26:22.820568Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean rotation error = 3.370\n",
      "mean rotation error = 3.043\n",
      "mean rotation error = 5.300\n",
      "mean rotation error = 4.736\n",
      "mean rotation error = 4.273\n",
      "mean rotation error = 5.851\n",
      "mean rotation error = 9.917\n",
      "mean rotation error = 7.293\n"
     ]
    }
   ],
   "source": [
    "for rot_errors_i in rot_errors_month:\n",
    "    print(\"mean rotation error = {:.3f}\".format(np.mean(rot_errors_i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
