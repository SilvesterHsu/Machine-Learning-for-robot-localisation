{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-28T08:56:42.888787Z",
     "start_time": "2020-06-28T08:56:41.641495Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "the rosdep view is empty: call 'sudo rosdep init' and 'rosdep update'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#import os\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\"\n",
    "import torch\n",
    "import argparse\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "#from src.self_awareness.networks import utils\n",
    "#from src.self_awareness.learning.tf_cnn_auxiliary_gp import Model\n",
    "from torch.distributions import Normal\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "import roslib\n",
    "import rospy\n",
    "import tf as tf_ros\n",
    "from nav_msgs.msg import Odometry, Path\n",
    "from sensor_msgs.msg import Image\n",
    "from cv_bridge import CvBridge\n",
    "from geometry_msgs.msg import PoseStamped, PoseArray, Pose\n",
    "import math\n",
    "import cv2\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-28T08:56:43.280942Z",
     "start_time": "2020-06-28T08:56:42.890263Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TITAN Xp\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(torch.cuda.get_device_name(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set torch default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-28T08:56:43.286347Z",
     "start_time": "2020-06-28T08:56:43.282653Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.set_default_dtype(torch.float32)\n",
    "torch.set_printoptions(precision=4,sci_mode=False)\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init ROS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-28T08:56:43.425429Z",
     "start_time": "2020-06-28T08:56:43.287769Z"
    }
   },
   "outputs": [],
   "source": [
    "rospy.init_node('global_localization_tf_broadcaster_cnn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-28T08:56:43.433926Z",
     "start_time": "2020-06-28T08:56:43.426913Z"
    }
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--batch_size', type=int, default=1, help='size of mini batch')\n",
    "parser.add_argument('--target_image_size', default=[300, 300], nargs=2, type=int, help='Input images will be resized to this for data argumentation.')\n",
    "\n",
    "parser.add_argument('--model_dir', type=str, default='/notebooks/global_localization/dual_resnet_torch', help='model directory')\n",
    "\n",
    "parser.add_argument('--test_dataset', type=str, default=[# '/notebooks/michigan_nn_data/2012_01_08',\n",
    "                                                         # '/notebooks/michigan_nn_data/2012_01_15',\n",
    "                                                         # '/notebooks/michigan_nn_data/2012_01_22',\n",
    "                                                         # '/notebooks/michigan_nn_data/2012_02_02',\n",
    "                                                         # '/notebooks/michigan_nn_data/2012_02_04',\n",
    "                                                         # '/notebooks/michigan_nn_data/2012_02_05',\n",
    "                                                         '/notebooks/michigan_nn_data/2012_02_12',\n",
    "                                                         # '/notebooks/michigan_nn_data/2012_03_31',\n",
    "                                                         '/notebooks/michigan_nn_data/2012_04_29',\n",
    "                                                         '/notebooks/michigan_nn_data/2012_05_11',\n",
    "                                                         '/notebooks/michigan_nn_data/2012_06_15',\n",
    "                                                         '/notebooks/michigan_nn_data/2012_08_04',\n",
    "                                                         # '/notebooks/michigan_nn_data/2012_09_28'])\n",
    "                                                         '/notebooks/michigan_nn_data/2012_10_28',\n",
    "                                                         '/notebooks/michigan_nn_data/2012_11_16',\n",
    "                                                         '/notebooks/michigan_nn_data/2012_12_01'\n",
    "                                                        ] )\n",
    "\n",
    "parser.add_argument('--train_dataset', type=str, default = ['/notebooks/michigan_nn_data/test'])\n",
    "#parser.add_argument('--map_dataset', type=str, default='/home/kevin/data/michigan_gt/training')\n",
    "sys.argv = ['']\n",
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-28T08:47:50.801713Z",
     "start_time": "2020-06-28T08:47:50.799680Z"
    }
   },
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-28T09:51:07.389865Z",
     "start_time": "2020-06-28T09:51:01.570984Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5593/5593 [00:05<00:00, 967.67it/s] \n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import tf.transformations as tf_tran\n",
    "from tqdm import tqdm\n",
    "#from PIL import Image\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "#import gpflow.multioutput.kernels as mk\n",
    "import gpytorch\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchlib import resnet, vggnet\n",
    "from torchlib.utils import LocalizationDataset\n",
    "import time\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "dataset = LocalizationDataset(dataset_dirs = args.train_dataset, \\\n",
    "                              image_size = args.target_image_size, \\\n",
    "                              transform = transform,\n",
    "                              get_pair = False, mode='evaluate')\n",
    "#[args.norm_mean, args.norm_std] = [torch.tensor(x) for x in dataset.get_norm()]\n",
    "#args.norm_mean = torch.Tensor([-114.69805908,  405.21035767,   -8.72568321])\n",
    "#args.norm_std = torch.Tensor([119.66057587, 176.14263916,   4.68300915])\n",
    "[args.norm_mean, args.norm_std] = torch.load('/notebooks/global_localization/norm_mean_std.pt')\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=args.batch_size, \\\n",
    "                        shuffle=False, num_workers=0, \\\n",
    "                        drop_last=False, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-28T09:52:28.821355Z",
     "start_time": "2020-06-28T09:52:28.812954Z"
    },
    "code_folding": [
     0,
     6,
     13,
     20,
     28
    ]
   },
   "outputs": [],
   "source": [
    "def denormalize_navie(normed_target, norm_mean, norm_std):\n",
    "    target_trans_unscaled = normed_target * norm_std\n",
    "    target_trans_uncentered = target_trans_unscaled + norm_mean\n",
    "    \n",
    "    return target_trans_uncentered\n",
    "\n",
    "def denormalize(normed_target, norm_mean, norm_std):\n",
    "    normed_target_trans, normed_target_rot = torch.split(normed_target, [3,4], dim=1)\n",
    "    target_trans_unscaled = normed_target_trans * norm_std\n",
    "    target_trans_uncentered = target_trans_unscaled + norm_mean\n",
    "    target = torch.cat([target_trans_uncentered, normed_target_rot],dim=1)\n",
    "    return target\n",
    "\n",
    "def normalize(target, norm_mean, norm_std):\n",
    "    target_trans = target[:,:3]\n",
    "    target_trans = torch.div(torch.sub(target_trans,norm_mean),norm_std)\n",
    "    target_normed = torch.cat([target_trans,target[:,3:]],dim=1)\n",
    "    return target_normed \n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self,training=True):\n",
    "        super().__init__()\n",
    "        self.resnet = resnet.resnet50(pretrained=True) # dense_feat\n",
    "        self.global_context = vggnet.vggnet(input_channel=2048,opt=\"context\")\n",
    "        #self.relative_context = vggnet(input_channel=4096,opt=\"context\")\n",
    "        self.global_regressor = vggnet.vggnet(opt=\"regressor\")\n",
    "        self.training = training\n",
    "        \n",
    "    def forward(self, input_data_t0, input_data_t1=None):\n",
    "        if self.training:\n",
    "            dense_feat0 = self.resnet(input_data_t0)\n",
    "            dense_feat1 = self.resnet(input_data_t1)\n",
    "            #dense_feat_relative = torch.cat([dense_feat0,dense_feat1],dim=1)\n",
    "\n",
    "            global_context_feat0 = self.global_context(dense_feat0)\n",
    "            global_context_feat1 = self.global_context(dense_feat1)\n",
    "            #relative_context_feat = self.relative_context(dense_feat_relative)\n",
    "\n",
    "            global_output0,_,_ = self.global_regressor(global_context_feat0)\n",
    "            global_output1,_,_ = self.global_regressor(global_context_feat1)\n",
    "\n",
    "            return global_output0,global_output1#,relative_context_feat \n",
    "        else:\n",
    "            dense_feat = self.resnet(input_data_t0)\n",
    "            global_context_feat = self.global_context(dense_feat)\n",
    "            global_output,_,_ = self.global_regressor(global_context_feat)\n",
    "            return global_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     1,
     17,
     25,
     30,
     35,
     45,
     55,
     65,
     70
    ]
   },
   "outputs": [],
   "source": [
    "class CNN_Model:\n",
    "    def __init__(self, training = True, device = \"cpu\"):\n",
    "        # device\n",
    "        self.device = torch.device(device)\n",
    "        \n",
    "        # data\n",
    "        self.model = Model(training).to(device)\n",
    "        self.norm_mean = args.norm_mean.to(device)\n",
    "        self.norm_std = args.norm_std.to(device)\n",
    "        \n",
    "        # training tool\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), \n",
    "                                    lr=args.learning_rate, \n",
    "                                    weight_decay=args.weight_decay)\n",
    "        self.scheduler = optim.lr_scheduler.LambdaLR(optimizer=self.optimizer,\n",
    "                                                     lr_lambda=lambda epoch: args.decay_rate**epoch)\n",
    "        \n",
    "    def load_model(self, file_name = 'pretrained.pth', display_info = True):\n",
    "        state_dict = torch.load(os.path.join(args.model_dir, file_name))\n",
    "        if display_info:\n",
    "            for name,param in state_dict.items():\n",
    "                print(name, param.shape)\n",
    "            print('Parameters layer:',len(state_dict.keys()))\n",
    "        self.model.load_state_dict(state_dict,strict = False)\n",
    "        \n",
    "    def display_structure(self):\n",
    "        for name, param in self.model.named_parameters():\n",
    "            print(name, param.shape)\n",
    "        print('Parameters layer:',len(self.model.state_dict().keys()))\n",
    "    \n",
    "    def display_require_grad(self):\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                print(name, param.shape)\n",
    "    \n",
    "    def power_resnet(self, status = False):\n",
    "        if status = 'off':\n",
    "            for param in self.model.resnet.parameters():\n",
    "                param.requires_grad = False\n",
    "        elif status = 'on':\n",
    "            for param in self.model.resnet.parameters():\n",
    "                param.requires_grad = True\n",
    "        else:\n",
    "            raise Exception(\"status must be 'on' or 'off'.\")\n",
    "            \n",
    "    def power_context(self, status = False):\n",
    "        if status = 'off':\n",
    "            for param in self.model.global_context.parameters():\n",
    "                param.requires_grad = False\n",
    "        elif status = 'on':\n",
    "            for param in self.model.global_context.parameters():\n",
    "                param.requires_grad = True\n",
    "        else:\n",
    "            raise Exception(\"status must be 'on' or 'off'.\")\n",
    "    \n",
    "    def power_regressor(self, status = False):\n",
    "        if status = 'off':\n",
    "            for param in self.model.global_regressor.parameters():\n",
    "                param.requires_grad = False\n",
    "        elif status = 'on':\n",
    "            for param in self.model.global_regressor.parameters():\n",
    "                param.requires_grad = True\n",
    "        else:\n",
    "            raise Exception(\"status must be 'on' or 'off'.\")\n",
    "            \n",
    "    def save_model(self, file_name = 'model-{}-{}.pth'):\n",
    "        checkpoint_path = os.path.join(args.model_dir, file_name)\n",
    "        torch.save(self.model.state_dict(),checkpoint_path)\n",
    "        print('saving model to' +  file_name)\n",
    "            \n",
    "    def loss(self,x0, x1, y0, y1):\n",
    "        start = time.time()\n",
    "        \n",
    "        x0,x1,y0,y1 = x0.to(device),x1.to(device),y0.to(device),y1.to(device)\n",
    "        y0_norm, y1_norm = [normalize(y,args.norm_mean, args.norm_std) for y in [y0,y1]]\n",
    "        \n",
    "        relative_target_normed = get_relative_pose(y0_norm, y1_norm)\n",
    "        \n",
    "        self.optimizer.zero_grad()\n",
    "        \n",
    "        global_output0,global_output1 = self.model(x0, x1)\n",
    "        relative_consistence = get_relative_pose(global_output0,global_output1)\n",
    "        global_loss = translational_rotational_loss(pred=global_output1, \\\n",
    "                                                    gt=y1_norm, \\\n",
    "                                                    lamda=args.lamda_weights)\n",
    "        geometry_consistent_loss = translational_rotational_loss(pred=relative_consistence, \\\n",
    "                                                                 gt=relative_target_normed, \\\n",
    "                                                                 lamda=args.lamda_weights)\n",
    "        total_loss = global_loss + geometry_consistent_loss        \n",
    "        total_loss.backward()\n",
    "        self.optimizer.step()\n",
    "        \n",
    "        end = time.time()\n",
    "        batch_time = end - start\n",
    "        return batch_time, float(total_loss)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-28T09:52:32.489856Z",
     "start_time": "2020-06-28T09:52:30.962996Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resnet.conv1.weight torch.Size([64, 1, 7, 7])\n",
      "resnet.bn1.weight torch.Size([64])\n",
      "resnet.bn1.bias torch.Size([64])\n",
      "resnet.bn1.running_mean torch.Size([64])\n",
      "resnet.bn1.running_var torch.Size([64])\n",
      "resnet.bn1.num_batches_tracked torch.Size([])\n",
      "resnet.layer1.0.conv1.weight torch.Size([64, 64, 1, 1])\n",
      "resnet.layer1.0.bn1.weight torch.Size([64])\n",
      "resnet.layer1.0.bn1.bias torch.Size([64])\n",
      "resnet.layer1.0.bn1.running_mean torch.Size([64])\n",
      "resnet.layer1.0.bn1.running_var torch.Size([64])\n",
      "resnet.layer1.0.bn1.num_batches_tracked torch.Size([])\n",
      "resnet.layer1.0.conv2.weight torch.Size([64, 64, 3, 3])\n",
      "resnet.layer1.0.bn2.weight torch.Size([64])\n",
      "resnet.layer1.0.bn2.bias torch.Size([64])\n",
      "resnet.layer1.0.bn2.running_mean torch.Size([64])\n",
      "resnet.layer1.0.bn2.running_var torch.Size([64])\n",
      "resnet.layer1.0.bn2.num_batches_tracked torch.Size([])\n",
      "resnet.layer1.0.conv3.weight torch.Size([256, 64, 1, 1])\n",
      "resnet.layer1.0.bn3.weight torch.Size([256])\n",
      "resnet.layer1.0.bn3.bias torch.Size([256])\n",
      "resnet.layer1.0.bn3.running_mean torch.Size([256])\n",
      "resnet.layer1.0.bn3.running_var torch.Size([256])\n",
      "resnet.layer1.0.bn3.num_batches_tracked torch.Size([])\n",
      "resnet.layer1.0.downsample.0.weight torch.Size([256, 64, 1, 1])\n",
      "resnet.layer1.0.downsample.1.weight torch.Size([256])\n",
      "resnet.layer1.0.downsample.1.bias torch.Size([256])\n",
      "resnet.layer1.0.downsample.1.running_mean torch.Size([256])\n",
      "resnet.layer1.0.downsample.1.running_var torch.Size([256])\n",
      "resnet.layer1.0.downsample.1.num_batches_tracked torch.Size([])\n",
      "resnet.layer1.1.conv1.weight torch.Size([64, 256, 1, 1])\n",
      "resnet.layer1.1.bn1.weight torch.Size([64])\n",
      "resnet.layer1.1.bn1.bias torch.Size([64])\n",
      "resnet.layer1.1.bn1.running_mean torch.Size([64])\n",
      "resnet.layer1.1.bn1.running_var torch.Size([64])\n",
      "resnet.layer1.1.bn1.num_batches_tracked torch.Size([])\n",
      "resnet.layer1.1.conv2.weight torch.Size([64, 64, 3, 3])\n",
      "resnet.layer1.1.bn2.weight torch.Size([64])\n",
      "resnet.layer1.1.bn2.bias torch.Size([64])\n",
      "resnet.layer1.1.bn2.running_mean torch.Size([64])\n",
      "resnet.layer1.1.bn2.running_var torch.Size([64])\n",
      "resnet.layer1.1.bn2.num_batches_tracked torch.Size([])\n",
      "resnet.layer1.1.conv3.weight torch.Size([256, 64, 1, 1])\n",
      "resnet.layer1.1.bn3.weight torch.Size([256])\n",
      "resnet.layer1.1.bn3.bias torch.Size([256])\n",
      "resnet.layer1.1.bn3.running_mean torch.Size([256])\n",
      "resnet.layer1.1.bn3.running_var torch.Size([256])\n",
      "resnet.layer1.1.bn3.num_batches_tracked torch.Size([])\n",
      "resnet.layer1.2.conv1.weight torch.Size([64, 256, 1, 1])\n",
      "resnet.layer1.2.bn1.weight torch.Size([64])\n",
      "resnet.layer1.2.bn1.bias torch.Size([64])\n",
      "resnet.layer1.2.bn1.running_mean torch.Size([64])\n",
      "resnet.layer1.2.bn1.running_var torch.Size([64])\n",
      "resnet.layer1.2.bn1.num_batches_tracked torch.Size([])\n",
      "resnet.layer1.2.conv2.weight torch.Size([64, 64, 3, 3])\n",
      "resnet.layer1.2.bn2.weight torch.Size([64])\n",
      "resnet.layer1.2.bn2.bias torch.Size([64])\n",
      "resnet.layer1.2.bn2.running_mean torch.Size([64])\n",
      "resnet.layer1.2.bn2.running_var torch.Size([64])\n",
      "resnet.layer1.2.bn2.num_batches_tracked torch.Size([])\n",
      "resnet.layer1.2.conv3.weight torch.Size([256, 64, 1, 1])\n",
      "resnet.layer1.2.bn3.weight torch.Size([256])\n",
      "resnet.layer1.2.bn3.bias torch.Size([256])\n",
      "resnet.layer1.2.bn3.running_mean torch.Size([256])\n",
      "resnet.layer1.2.bn3.running_var torch.Size([256])\n",
      "resnet.layer1.2.bn3.num_batches_tracked torch.Size([])\n",
      "resnet.layer2.0.conv1.weight torch.Size([128, 256, 1, 1])\n",
      "resnet.layer2.0.bn1.weight torch.Size([128])\n",
      "resnet.layer2.0.bn1.bias torch.Size([128])\n",
      "resnet.layer2.0.bn1.running_mean torch.Size([128])\n",
      "resnet.layer2.0.bn1.running_var torch.Size([128])\n",
      "resnet.layer2.0.bn1.num_batches_tracked torch.Size([])\n",
      "resnet.layer2.0.conv2.weight torch.Size([128, 128, 3, 3])\n",
      "resnet.layer2.0.bn2.weight torch.Size([128])\n",
      "resnet.layer2.0.bn2.bias torch.Size([128])\n",
      "resnet.layer2.0.bn2.running_mean torch.Size([128])\n",
      "resnet.layer2.0.bn2.running_var torch.Size([128])\n",
      "resnet.layer2.0.bn2.num_batches_tracked torch.Size([])\n",
      "resnet.layer2.0.conv3.weight torch.Size([512, 128, 1, 1])\n",
      "resnet.layer2.0.bn3.weight torch.Size([512])\n",
      "resnet.layer2.0.bn3.bias torch.Size([512])\n",
      "resnet.layer2.0.bn3.running_mean torch.Size([512])\n",
      "resnet.layer2.0.bn3.running_var torch.Size([512])\n",
      "resnet.layer2.0.bn3.num_batches_tracked torch.Size([])\n",
      "resnet.layer2.0.downsample.0.weight torch.Size([512, 256, 1, 1])\n",
      "resnet.layer2.0.downsample.1.weight torch.Size([512])\n",
      "resnet.layer2.0.downsample.1.bias torch.Size([512])\n",
      "resnet.layer2.0.downsample.1.running_mean torch.Size([512])\n",
      "resnet.layer2.0.downsample.1.running_var torch.Size([512])\n",
      "resnet.layer2.0.downsample.1.num_batches_tracked torch.Size([])\n",
      "resnet.layer2.1.conv1.weight torch.Size([128, 512, 1, 1])\n",
      "resnet.layer2.1.bn1.weight torch.Size([128])\n",
      "resnet.layer2.1.bn1.bias torch.Size([128])\n",
      "resnet.layer2.1.bn1.running_mean torch.Size([128])\n",
      "resnet.layer2.1.bn1.running_var torch.Size([128])\n",
      "resnet.layer2.1.bn1.num_batches_tracked torch.Size([])\n",
      "resnet.layer2.1.conv2.weight torch.Size([128, 128, 3, 3])\n",
      "resnet.layer2.1.bn2.weight torch.Size([128])\n",
      "resnet.layer2.1.bn2.bias torch.Size([128])\n",
      "resnet.layer2.1.bn2.running_mean torch.Size([128])\n",
      "resnet.layer2.1.bn2.running_var torch.Size([128])\n",
      "resnet.layer2.1.bn2.num_batches_tracked torch.Size([])\n",
      "resnet.layer2.1.conv3.weight torch.Size([512, 128, 1, 1])\n",
      "resnet.layer2.1.bn3.weight torch.Size([512])\n",
      "resnet.layer2.1.bn3.bias torch.Size([512])\n",
      "resnet.layer2.1.bn3.running_mean torch.Size([512])\n",
      "resnet.layer2.1.bn3.running_var torch.Size([512])\n",
      "resnet.layer2.1.bn3.num_batches_tracked torch.Size([])\n",
      "resnet.layer2.2.conv1.weight torch.Size([128, 512, 1, 1])\n",
      "resnet.layer2.2.bn1.weight torch.Size([128])\n",
      "resnet.layer2.2.bn1.bias torch.Size([128])\n",
      "resnet.layer2.2.bn1.running_mean torch.Size([128])\n",
      "resnet.layer2.2.bn1.running_var torch.Size([128])\n",
      "resnet.layer2.2.bn1.num_batches_tracked torch.Size([])\n",
      "resnet.layer2.2.conv2.weight torch.Size([128, 128, 3, 3])\n",
      "resnet.layer2.2.bn2.weight torch.Size([128])\n",
      "resnet.layer2.2.bn2.bias torch.Size([128])\n",
      "resnet.layer2.2.bn2.running_mean torch.Size([128])\n",
      "resnet.layer2.2.bn2.running_var torch.Size([128])\n",
      "resnet.layer2.2.bn2.num_batches_tracked torch.Size([])\n",
      "resnet.layer2.2.conv3.weight torch.Size([512, 128, 1, 1])\n",
      "resnet.layer2.2.bn3.weight torch.Size([512])\n",
      "resnet.layer2.2.bn3.bias torch.Size([512])\n",
      "resnet.layer2.2.bn3.running_mean torch.Size([512])\n",
      "resnet.layer2.2.bn3.running_var torch.Size([512])\n",
      "resnet.layer2.2.bn3.num_batches_tracked torch.Size([])\n",
      "resnet.layer2.3.conv1.weight torch.Size([128, 512, 1, 1])\n",
      "resnet.layer2.3.bn1.weight torch.Size([128])\n",
      "resnet.layer2.3.bn1.bias torch.Size([128])\n",
      "resnet.layer2.3.bn1.running_mean torch.Size([128])\n",
      "resnet.layer2.3.bn1.running_var torch.Size([128])\n",
      "resnet.layer2.3.bn1.num_batches_tracked torch.Size([])\n",
      "resnet.layer2.3.conv2.weight torch.Size([128, 128, 3, 3])\n",
      "resnet.layer2.3.bn2.weight torch.Size([128])\n",
      "resnet.layer2.3.bn2.bias torch.Size([128])\n",
      "resnet.layer2.3.bn2.running_mean torch.Size([128])\n",
      "resnet.layer2.3.bn2.running_var torch.Size([128])\n",
      "resnet.layer2.3.bn2.num_batches_tracked torch.Size([])\n",
      "resnet.layer2.3.conv3.weight torch.Size([512, 128, 1, 1])\n",
      "resnet.layer2.3.bn3.weight torch.Size([512])\n",
      "resnet.layer2.3.bn3.bias torch.Size([512])\n",
      "resnet.layer2.3.bn3.running_mean torch.Size([512])\n",
      "resnet.layer2.3.bn3.running_var torch.Size([512])\n",
      "resnet.layer2.3.bn3.num_batches_tracked torch.Size([])\n",
      "resnet.layer3.0.conv1.weight torch.Size([256, 512, 1, 1])\n",
      "resnet.layer3.0.bn1.weight torch.Size([256])\n",
      "resnet.layer3.0.bn1.bias torch.Size([256])\n",
      "resnet.layer3.0.bn1.running_mean torch.Size([256])\n",
      "resnet.layer3.0.bn1.running_var torch.Size([256])\n",
      "resnet.layer3.0.bn1.num_batches_tracked torch.Size([])\n",
      "resnet.layer3.0.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "resnet.layer3.0.bn2.weight torch.Size([256])\n",
      "resnet.layer3.0.bn2.bias torch.Size([256])\n",
      "resnet.layer3.0.bn2.running_mean torch.Size([256])\n",
      "resnet.layer3.0.bn2.running_var torch.Size([256])\n",
      "resnet.layer3.0.bn2.num_batches_tracked torch.Size([])\n",
      "resnet.layer3.0.conv3.weight torch.Size([1024, 256, 1, 1])\n",
      "resnet.layer3.0.bn3.weight torch.Size([1024])\n",
      "resnet.layer3.0.bn3.bias torch.Size([1024])\n",
      "resnet.layer3.0.bn3.running_mean torch.Size([1024])\n",
      "resnet.layer3.0.bn3.running_var torch.Size([1024])\n",
      "resnet.layer3.0.bn3.num_batches_tracked torch.Size([])\n",
      "resnet.layer3.0.downsample.0.weight torch.Size([1024, 512, 1, 1])\n",
      "resnet.layer3.0.downsample.1.weight torch.Size([1024])\n",
      "resnet.layer3.0.downsample.1.bias torch.Size([1024])\n",
      "resnet.layer3.0.downsample.1.running_mean torch.Size([1024])\n",
      "resnet.layer3.0.downsample.1.running_var torch.Size([1024])\n",
      "resnet.layer3.0.downsample.1.num_batches_tracked torch.Size([])\n",
      "resnet.layer3.1.conv1.weight torch.Size([256, 1024, 1, 1])\n",
      "resnet.layer3.1.bn1.weight torch.Size([256])\n",
      "resnet.layer3.1.bn1.bias torch.Size([256])\n",
      "resnet.layer3.1.bn1.running_mean torch.Size([256])\n",
      "resnet.layer3.1.bn1.running_var torch.Size([256])\n",
      "resnet.layer3.1.bn1.num_batches_tracked torch.Size([])\n",
      "resnet.layer3.1.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "resnet.layer3.1.bn2.weight torch.Size([256])\n",
      "resnet.layer3.1.bn2.bias torch.Size([256])\n",
      "resnet.layer3.1.bn2.running_mean torch.Size([256])\n",
      "resnet.layer3.1.bn2.running_var torch.Size([256])\n",
      "resnet.layer3.1.bn2.num_batches_tracked torch.Size([])\n",
      "resnet.layer3.1.conv3.weight torch.Size([1024, 256, 1, 1])\n",
      "resnet.layer3.1.bn3.weight torch.Size([1024])\n",
      "resnet.layer3.1.bn3.bias torch.Size([1024])\n",
      "resnet.layer3.1.bn3.running_mean torch.Size([1024])\n",
      "resnet.layer3.1.bn3.running_var torch.Size([1024])\n",
      "resnet.layer3.1.bn3.num_batches_tracked torch.Size([])\n",
      "resnet.layer3.2.conv1.weight torch.Size([256, 1024, 1, 1])\n",
      "resnet.layer3.2.bn1.weight torch.Size([256])\n",
      "resnet.layer3.2.bn1.bias torch.Size([256])\n",
      "resnet.layer3.2.bn1.running_mean torch.Size([256])\n",
      "resnet.layer3.2.bn1.running_var torch.Size([256])\n",
      "resnet.layer3.2.bn1.num_batches_tracked torch.Size([])\n",
      "resnet.layer3.2.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "resnet.layer3.2.bn2.weight torch.Size([256])\n",
      "resnet.layer3.2.bn2.bias torch.Size([256])\n",
      "resnet.layer3.2.bn2.running_mean torch.Size([256])\n",
      "resnet.layer3.2.bn2.running_var torch.Size([256])\n",
      "resnet.layer3.2.bn2.num_batches_tracked torch.Size([])\n",
      "resnet.layer3.2.conv3.weight torch.Size([1024, 256, 1, 1])\n",
      "resnet.layer3.2.bn3.weight torch.Size([1024])\n",
      "resnet.layer3.2.bn3.bias torch.Size([1024])\n",
      "resnet.layer3.2.bn3.running_mean torch.Size([1024])\n",
      "resnet.layer3.2.bn3.running_var torch.Size([1024])\n",
      "resnet.layer3.2.bn3.num_batches_tracked torch.Size([])\n",
      "resnet.layer3.3.conv1.weight torch.Size([256, 1024, 1, 1])\n",
      "resnet.layer3.3.bn1.weight torch.Size([256])\n",
      "resnet.layer3.3.bn1.bias torch.Size([256])\n",
      "resnet.layer3.3.bn1.running_mean torch.Size([256])\n",
      "resnet.layer3.3.bn1.running_var torch.Size([256])\n",
      "resnet.layer3.3.bn1.num_batches_tracked torch.Size([])\n",
      "resnet.layer3.3.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "resnet.layer3.3.bn2.weight torch.Size([256])\n",
      "resnet.layer3.3.bn2.bias torch.Size([256])\n",
      "resnet.layer3.3.bn2.running_mean torch.Size([256])\n",
      "resnet.layer3.3.bn2.running_var torch.Size([256])\n",
      "resnet.layer3.3.bn2.num_batches_tracked torch.Size([])\n",
      "resnet.layer3.3.conv3.weight torch.Size([1024, 256, 1, 1])\n",
      "resnet.layer3.3.bn3.weight torch.Size([1024])\n",
      "resnet.layer3.3.bn3.bias torch.Size([1024])\n",
      "resnet.layer3.3.bn3.running_mean torch.Size([1024])\n",
      "resnet.layer3.3.bn3.running_var torch.Size([1024])\n",
      "resnet.layer3.3.bn3.num_batches_tracked torch.Size([])\n",
      "resnet.layer3.4.conv1.weight torch.Size([256, 1024, 1, 1])\n",
      "resnet.layer3.4.bn1.weight torch.Size([256])\n",
      "resnet.layer3.4.bn1.bias torch.Size([256])\n",
      "resnet.layer3.4.bn1.running_mean torch.Size([256])\n",
      "resnet.layer3.4.bn1.running_var torch.Size([256])\n",
      "resnet.layer3.4.bn1.num_batches_tracked torch.Size([])\n",
      "resnet.layer3.4.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "resnet.layer3.4.bn2.weight torch.Size([256])\n",
      "resnet.layer3.4.bn2.bias torch.Size([256])\n",
      "resnet.layer3.4.bn2.running_mean torch.Size([256])\n",
      "resnet.layer3.4.bn2.running_var torch.Size([256])\n",
      "resnet.layer3.4.bn2.num_batches_tracked torch.Size([])\n",
      "resnet.layer3.4.conv3.weight torch.Size([1024, 256, 1, 1])\n",
      "resnet.layer3.4.bn3.weight torch.Size([1024])\n",
      "resnet.layer3.4.bn3.bias torch.Size([1024])\n",
      "resnet.layer3.4.bn3.running_mean torch.Size([1024])\n",
      "resnet.layer3.4.bn3.running_var torch.Size([1024])\n",
      "resnet.layer3.4.bn3.num_batches_tracked torch.Size([])\n",
      "resnet.layer3.5.conv1.weight torch.Size([256, 1024, 1, 1])\n",
      "resnet.layer3.5.bn1.weight torch.Size([256])\n",
      "resnet.layer3.5.bn1.bias torch.Size([256])\n",
      "resnet.layer3.5.bn1.running_mean torch.Size([256])\n",
      "resnet.layer3.5.bn1.running_var torch.Size([256])\n",
      "resnet.layer3.5.bn1.num_batches_tracked torch.Size([])\n",
      "resnet.layer3.5.conv2.weight torch.Size([256, 256, 3, 3])\n",
      "resnet.layer3.5.bn2.weight torch.Size([256])\n",
      "resnet.layer3.5.bn2.bias torch.Size([256])\n",
      "resnet.layer3.5.bn2.running_mean torch.Size([256])\n",
      "resnet.layer3.5.bn2.running_var torch.Size([256])\n",
      "resnet.layer3.5.bn2.num_batches_tracked torch.Size([])\n",
      "resnet.layer3.5.conv3.weight torch.Size([1024, 256, 1, 1])\n",
      "resnet.layer3.5.bn3.weight torch.Size([1024])\n",
      "resnet.layer3.5.bn3.bias torch.Size([1024])\n",
      "resnet.layer3.5.bn3.running_mean torch.Size([1024])\n",
      "resnet.layer3.5.bn3.running_var torch.Size([1024])\n",
      "resnet.layer3.5.bn3.num_batches_tracked torch.Size([])\n",
      "resnet.layer4.0.conv1.weight torch.Size([512, 1024, 1, 1])\n",
      "resnet.layer4.0.bn1.weight torch.Size([512])\n",
      "resnet.layer4.0.bn1.bias torch.Size([512])\n",
      "resnet.layer4.0.bn1.running_mean torch.Size([512])\n",
      "resnet.layer4.0.bn1.running_var torch.Size([512])\n",
      "resnet.layer4.0.bn1.num_batches_tracked torch.Size([])\n",
      "resnet.layer4.0.conv2.weight torch.Size([512, 512, 3, 3])\n",
      "resnet.layer4.0.bn2.weight torch.Size([512])\n",
      "resnet.layer4.0.bn2.bias torch.Size([512])\n",
      "resnet.layer4.0.bn2.running_mean torch.Size([512])\n",
      "resnet.layer4.0.bn2.running_var torch.Size([512])\n",
      "resnet.layer4.0.bn2.num_batches_tracked torch.Size([])\n",
      "resnet.layer4.0.conv3.weight torch.Size([2048, 512, 1, 1])\n",
      "resnet.layer4.0.bn3.weight torch.Size([2048])\n",
      "resnet.layer4.0.bn3.bias torch.Size([2048])\n",
      "resnet.layer4.0.bn3.running_mean torch.Size([2048])\n",
      "resnet.layer4.0.bn3.running_var torch.Size([2048])\n",
      "resnet.layer4.0.bn3.num_batches_tracked torch.Size([])\n",
      "resnet.layer4.0.downsample.0.weight torch.Size([2048, 1024, 1, 1])\n",
      "resnet.layer4.0.downsample.1.weight torch.Size([2048])\n",
      "resnet.layer4.0.downsample.1.bias torch.Size([2048])\n",
      "resnet.layer4.0.downsample.1.running_mean torch.Size([2048])\n",
      "resnet.layer4.0.downsample.1.running_var torch.Size([2048])\n",
      "resnet.layer4.0.downsample.1.num_batches_tracked torch.Size([])\n",
      "resnet.layer4.1.conv1.weight torch.Size([512, 2048, 1, 1])\n",
      "resnet.layer4.1.bn1.weight torch.Size([512])\n",
      "resnet.layer4.1.bn1.bias torch.Size([512])\n",
      "resnet.layer4.1.bn1.running_mean torch.Size([512])\n",
      "resnet.layer4.1.bn1.running_var torch.Size([512])\n",
      "resnet.layer4.1.bn1.num_batches_tracked torch.Size([])\n",
      "resnet.layer4.1.conv2.weight torch.Size([512, 512, 3, 3])\n",
      "resnet.layer4.1.bn2.weight torch.Size([512])\n",
      "resnet.layer4.1.bn2.bias torch.Size([512])\n",
      "resnet.layer4.1.bn2.running_mean torch.Size([512])\n",
      "resnet.layer4.1.bn2.running_var torch.Size([512])\n",
      "resnet.layer4.1.bn2.num_batches_tracked torch.Size([])\n",
      "resnet.layer4.1.conv3.weight torch.Size([2048, 512, 1, 1])\n",
      "resnet.layer4.1.bn3.weight torch.Size([2048])\n",
      "resnet.layer4.1.bn3.bias torch.Size([2048])\n",
      "resnet.layer4.1.bn3.running_mean torch.Size([2048])\n",
      "resnet.layer4.1.bn3.running_var torch.Size([2048])\n",
      "resnet.layer4.1.bn3.num_batches_tracked torch.Size([])\n",
      "resnet.layer4.2.conv1.weight torch.Size([512, 2048, 1, 1])\n",
      "resnet.layer4.2.bn1.weight torch.Size([512])\n",
      "resnet.layer4.2.bn1.bias torch.Size([512])\n",
      "resnet.layer4.2.bn1.running_mean torch.Size([512])\n",
      "resnet.layer4.2.bn1.running_var torch.Size([512])\n",
      "resnet.layer4.2.bn1.num_batches_tracked torch.Size([])\n",
      "resnet.layer4.2.conv2.weight torch.Size([512, 512, 3, 3])\n",
      "resnet.layer4.2.bn2.weight torch.Size([512])\n",
      "resnet.layer4.2.bn2.bias torch.Size([512])\n",
      "resnet.layer4.2.bn2.running_mean torch.Size([512])\n",
      "resnet.layer4.2.bn2.running_var torch.Size([512])\n",
      "resnet.layer4.2.bn2.num_batches_tracked torch.Size([])\n",
      "resnet.layer4.2.conv3.weight torch.Size([2048, 512, 1, 1])\n",
      "resnet.layer4.2.bn3.weight torch.Size([2048])\n",
      "resnet.layer4.2.bn3.bias torch.Size([2048])\n",
      "resnet.layer4.2.bn3.running_mean torch.Size([2048])\n",
      "resnet.layer4.2.bn3.running_var torch.Size([2048])\n",
      "resnet.layer4.2.bn3.num_batches_tracked torch.Size([])\n",
      "global_context.context.squeeze.0.weight torch.Size([128, 2048, 1, 1])\n",
      "global_context.context.squeeze.0.bias torch.Size([128])\n",
      "global_context.context.context5_1.0.weight torch.Size([128, 128, 3, 3])\n",
      "global_context.context.context5_1.0.bias torch.Size([128])\n",
      "global_context.context.context5_2.0.weight torch.Size([128, 128, 3, 3])\n",
      "global_context.context.context5_2.0.bias torch.Size([128])\n",
      "global_context.context.context5_3.0.weight torch.Size([128, 128, 3, 3])\n",
      "global_context.context.context5_3.0.bias torch.Size([128])\n",
      "global_context.context.context5_4.0.weight torch.Size([128, 128, 3, 3])\n",
      "global_context.context.context5_4.0.bias torch.Size([128])\n",
      "global_context.context.squeeze2.0.weight torch.Size([64, 128, 1, 1])\n",
      "global_context.context.squeeze2.0.bias torch.Size([64])\n",
      "global_regressor.regressor.fc1_trans.0.weight torch.Size([4096, 6400])\n",
      "global_regressor.regressor.fc1_trans.0.bias torch.Size([4096])\n",
      "global_regressor.regressor.fc2_trans.0.weight torch.Size([4096, 4096])\n",
      "global_regressor.regressor.fc2_trans.0.bias torch.Size([4096])\n",
      "global_regressor.regressor.fc3_trans.0.weight torch.Size([128, 4096])\n",
      "global_regressor.regressor.fc3_trans.0.bias torch.Size([128])\n",
      "global_regressor.regressor.logits_t.weight torch.Size([3, 128])\n",
      "global_regressor.regressor.logits_t.bias torch.Size([3])\n",
      "global_regressor.regressor.fc1_rot.0.weight torch.Size([4096, 6400])\n",
      "global_regressor.regressor.fc1_rot.0.bias torch.Size([4096])\n",
      "global_regressor.regressor.fc2_rot.0.weight torch.Size([4096, 4096])\n",
      "global_regressor.regressor.fc2_rot.0.bias torch.Size([4096])\n",
      "global_regressor.regressor.fc3_rot.0.weight torch.Size([128, 4096])\n",
      "global_regressor.regressor.fc3_rot.0.bias torch.Size([128])\n",
      "global_regressor.regressor.logits_r.weight torch.Size([4, 128])\n",
      "global_regressor.regressor.logits_r.bias torch.Size([4])\n",
      "Parameters layer: 346\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.set_device(device)\n",
    "\n",
    "# set to cpu\n",
    "#device = torch.device(\"cpu\")\n",
    "model = Model().to(device)\n",
    "state_dict = torch.load(os.path.join(args.model_dir,'pretrained.pth'))\n",
    "# pretrained\n",
    "for name,param in state_dict.items():\n",
    "    print(name, param.shape)\n",
    "print('Parameters layer:',len(state_dict.keys()))\n",
    "\n",
    "model.load_state_dict(state_dict,strict = False)\n",
    "\n",
    "# Disable net\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-28T09:52:34.347408Z",
     "start_time": "2020-06-28T09:52:34.344405Z"
    }
   },
   "outputs": [],
   "source": [
    "args.norm_mean = args.norm_mean.to(device)\n",
    "args.norm_std = args.norm_std.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-28T09:52:34.962302Z",
     "start_time": "2020-06-28T09:52:34.958465Z"
    }
   },
   "outputs": [],
   "source": [
    "trans_errors = []\n",
    "rot_errors = []\n",
    "uncertainties = []\n",
    "pose_map = []\n",
    "\n",
    "total_trans_error = 0.\n",
    "total_rot_error = 0.\n",
    "\n",
    "count = 0.\n",
    "\n",
    "is_save_map = False\n",
    "is_read_map = False\n",
    "\n",
    "trans_preds = []\n",
    "trans_gts = []\n",
    "\n",
    "rot_preds = []\n",
    "rot_gts = []\n",
    "\n",
    "pred_uncertainties = []\n",
    "\n",
    "pred_time = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-28T09:52:36.189997Z",
     "start_time": "2020-06-28T09:52:36.185626Z"
    }
   },
   "outputs": [],
   "source": [
    "br = tf_ros.TransformBroadcaster()\n",
    "\n",
    "GT_POSE_TOPIC = '/gt_pose'\n",
    "BIRDVIEW_TOPIC_PUB = '/bird_view'\n",
    "MAP_TOPIC_PUB = '/pose_map'\n",
    "PARTICLES_PUB = '/particles'\n",
    "NN_LOCALIZASION_PUB = '/nn_pose'\n",
    "gt_pose_pub = rospy.Publisher(GT_POSE_TOPIC, Odometry, queue_size=1)\n",
    "bird_view_pub = rospy.Publisher(BIRDVIEW_TOPIC_PUB, Image, queue_size=1)\n",
    "map_pub = rospy.Publisher(MAP_TOPIC_PUB, Path, queue_size=1)\n",
    "particles_pub = rospy.Publisher(PARTICLES_PUB, PoseArray, queue_size=1)\n",
    "nn_pose_pub = rospy.Publisher(NN_LOCALIZASION_PUB, Odometry, queue_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-28T09:52:37.011398Z",
     "start_time": "2020-06-28T09:52:37.004837Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (resnet): ResNet(\n",
       "    (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (layer1): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (3): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (4): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (5): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): Bottleneck(\n",
       "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "      (2): Bottleneck(\n",
       "        (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (global_context): vggnet(\n",
       "    (context): Context(\n",
       "      (squeeze): Sequential(\n",
       "        (0): Conv2d(2048, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): ReLU()\n",
       "      )\n",
       "      (context5_1): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU()\n",
       "      )\n",
       "      (context5_2): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU()\n",
       "      )\n",
       "      (context5_3): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU()\n",
       "      )\n",
       "      (context5_4): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU()\n",
       "      )\n",
       "      (squeeze2): Sequential(\n",
       "        (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): ReLU()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (global_regressor): vggnet(\n",
       "    (regressor): Regressor(\n",
       "      (flatten): Flatten()\n",
       "      (fc1_trans): Sequential(\n",
       "        (0): Linear(in_features=6400, out_features=4096, bias=True)\n",
       "        (1): ReLU()\n",
       "      )\n",
       "      (fc2_trans): Sequential(\n",
       "        (0): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "        (1): ReLU()\n",
       "      )\n",
       "      (fc3_trans): Sequential(\n",
       "        (0): Linear(in_features=4096, out_features=128, bias=True)\n",
       "        (1): ReLU()\n",
       "      )\n",
       "      (logits_t): Linear(in_features=128, out_features=3, bias=True)\n",
       "      (fc1_rot): Sequential(\n",
       "        (0): Linear(in_features=6400, out_features=4096, bias=True)\n",
       "        (1): ReLU()\n",
       "      )\n",
       "      (fc2_rot): Sequential(\n",
       "        (0): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "        (1): ReLU()\n",
       "      )\n",
       "      (fc3_rot): Sequential(\n",
       "        (0): Linear(in_features=4096, out_features=128, bias=True)\n",
       "        (1): ReLU()\n",
       "      )\n",
       "      (logits_r): Linear(in_features=128, out_features=4, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-28T11:28:11.928072Z",
     "start_time": "2020-06-28T11:17:55.856134Z"
    },
    "code_folding": [
     6
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/5583, translation error = 1.608, rotation error = 3.870, time/batch = 0.009\n",
      "100/5583, translation error = 2.292, rotation error = 4.308, time/batch = 0.009\n",
      "150/5583, translation error = 2.583, rotation error = 4.645, time/batch = 0.009\n",
      "200/5583, translation error = 2.954, rotation error = 4.422, time/batch = 0.009\n",
      "250/5583, translation error = 3.276, rotation error = 4.316, time/batch = 0.009\n",
      "300/5583, translation error = 3.334, rotation error = 4.443, time/batch = 0.009\n",
      "350/5583, translation error = 4.056, rotation error = 4.938, time/batch = 0.009\n",
      "400/5583, translation error = 4.368, rotation error = 4.818, time/batch = 0.009\n",
      "450/5583, translation error = 4.733, rotation error = 4.736, time/batch = 0.009\n",
      "500/5583, translation error = 4.995, rotation error = 4.637, time/batch = 0.009\n",
      "550/5583, translation error = 4.910, rotation error = 4.481, time/batch = 0.009\n",
      "600/5583, translation error = 4.887, rotation error = 4.301, time/batch = 0.009\n",
      "650/5583, translation error = 4.796, rotation error = 4.120, time/batch = 0.009\n",
      "700/5583, translation error = 4.949, rotation error = 4.138, time/batch = 0.009\n",
      "750/5583, translation error = 4.812, rotation error = 4.471, time/batch = 0.009\n",
      "800/5583, translation error = 4.750, rotation error = 5.065, time/batch = 0.009\n",
      "850/5583, translation error = 4.959, rotation error = 5.415, time/batch = 0.009\n",
      "900/5583, translation error = 4.997, rotation error = 5.570, time/batch = 0.009\n",
      "950/5583, translation error = 4.885, rotation error = 5.513, time/batch = 0.010\n",
      "1000/5583, translation error = 4.743, rotation error = 5.409, time/batch = 0.009\n",
      "1050/5583, translation error = 4.775, rotation error = 5.874, time/batch = 0.009\n",
      "1100/5583, translation error = 4.850, rotation error = 6.042, time/batch = 0.009\n",
      "1150/5583, translation error = 4.785, rotation error = 5.953, time/batch = 0.010\n",
      "1200/5583, translation error = 4.754, rotation error = 5.947, time/batch = 0.009\n",
      "1250/5583, translation error = 4.650, rotation error = 5.877, time/batch = 0.009\n",
      "1300/5583, translation error = 4.585, rotation error = 5.742, time/batch = 0.009\n",
      "1350/5583, translation error = 4.510, rotation error = 5.619, time/batch = 0.009\n",
      "1400/5583, translation error = 4.628, rotation error = 5.936, time/batch = 0.010\n",
      "1450/5583, translation error = 4.617, rotation error = 6.046, time/batch = 0.010\n",
      "1500/5583, translation error = 4.594, rotation error = 5.956, time/batch = 0.010\n",
      "1550/5583, translation error = 4.524, rotation error = 5.844, time/batch = 0.009\n",
      "1600/5583, translation error = 4.425, rotation error = 5.791, time/batch = 0.010\n",
      "1650/5583, translation error = 4.362, rotation error = 5.736, time/batch = 0.010\n",
      "1700/5583, translation error = 4.292, rotation error = 5.619, time/batch = 0.009\n",
      "1750/5583, translation error = 4.228, rotation error = 5.497, time/batch = 0.010\n",
      "1800/5583, translation error = 4.171, rotation error = 5.411, time/batch = 0.010\n",
      "1850/5583, translation error = 4.125, rotation error = 5.377, time/batch = 0.010\n",
      "1900/5583, translation error = 4.107, rotation error = 5.342, time/batch = 0.010\n",
      "1950/5583, translation error = 4.050, rotation error = 5.265, time/batch = 0.010\n",
      "2000/5583, translation error = 3.987, rotation error = 5.171, time/batch = 0.010\n",
      "2050/5583, translation error = 3.956, rotation error = 5.095, time/batch = 0.010\n",
      "2100/5583, translation error = 3.897, rotation error = 5.008, time/batch = 0.010\n",
      "2150/5583, translation error = 3.964, rotation error = 4.992, time/batch = 0.010\n",
      "2200/5583, translation error = 4.008, rotation error = 5.026, time/batch = 0.009\n",
      "2250/5583, translation error = 3.969, rotation error = 4.943, time/batch = 0.009\n",
      "2300/5583, translation error = 3.934, rotation error = 4.871, time/batch = 0.010\n",
      "2350/5583, translation error = 3.886, rotation error = 4.806, time/batch = 0.010\n",
      "2400/5583, translation error = 3.848, rotation error = 4.800, time/batch = 0.009\n",
      "2450/5583, translation error = 3.825, rotation error = 4.772, time/batch = 0.010\n",
      "2500/5583, translation error = 3.798, rotation error = 4.741, time/batch = 0.010\n",
      "2550/5583, translation error = 3.838, rotation error = 4.690, time/batch = 0.010\n",
      "2600/5583, translation error = 3.922, rotation error = 4.670, time/batch = 0.010\n",
      "2650/5583, translation error = 3.960, rotation error = 4.658, time/batch = 0.010\n",
      "2700/5583, translation error = 3.958, rotation error = 4.637, time/batch = 0.009\n",
      "2750/5583, translation error = 3.985, rotation error = 4.591, time/batch = 0.009\n",
      "2800/5583, translation error = 3.975, rotation error = 4.538, time/batch = 0.009\n",
      "2850/5583, translation error = 4.016, rotation error = 4.540, time/batch = 0.010\n",
      "2900/5583, translation error = 4.000, rotation error = 4.525, time/batch = 0.010\n",
      "2950/5583, translation error = 4.038, rotation error = 4.526, time/batch = 0.009\n",
      "3000/5583, translation error = 4.020, rotation error = 4.494, time/batch = 0.009\n",
      "3050/5583, translation error = 3.983, rotation error = 4.451, time/batch = 0.010\n",
      "3100/5583, translation error = 3.959, rotation error = 4.428, time/batch = 0.010\n",
      "3150/5583, translation error = 3.938, rotation error = 4.402, time/batch = 0.009\n",
      "3200/5583, translation error = 3.914, rotation error = 4.367, time/batch = 0.010\n",
      "3250/5583, translation error = 3.905, rotation error = 4.327, time/batch = 0.010\n",
      "3300/5583, translation error = 3.867, rotation error = 4.280, time/batch = 0.010\n",
      "3350/5583, translation error = 3.840, rotation error = 4.247, time/batch = 0.010\n",
      "3400/5583, translation error = 3.819, rotation error = 4.212, time/batch = 0.010\n",
      "3450/5583, translation error = 3.799, rotation error = 4.181, time/batch = 0.010\n",
      "3500/5583, translation error = 3.774, rotation error = 4.155, time/batch = 0.010\n",
      "3550/5583, translation error = 3.748, rotation error = 4.115, time/batch = 0.009\n",
      "3600/5583, translation error = 3.723, rotation error = 4.080, time/batch = 0.010\n",
      "3650/5583, translation error = 3.701, rotation error = 4.051, time/batch = 0.010\n",
      "3700/5583, translation error = 3.676, rotation error = 4.014, time/batch = 0.010\n",
      "3750/5583, translation error = 3.668, rotation error = 3.975, time/batch = 0.009\n",
      "3800/5583, translation error = 3.669, rotation error = 3.938, time/batch = 0.010\n",
      "3850/5583, translation error = 3.650, rotation error = 3.930, time/batch = 0.010\n",
      "3900/5583, translation error = 3.635, rotation error = 3.922, time/batch = 0.009\n",
      "3950/5583, translation error = 3.612, rotation error = 3.909, time/batch = 0.010\n",
      "4000/5583, translation error = 3.599, rotation error = 3.903, time/batch = 0.009\n",
      "4050/5583, translation error = 3.597, rotation error = 3.880, time/batch = 0.010\n",
      "4100/5583, translation error = 3.598, rotation error = 3.850, time/batch = 0.009\n",
      "4150/5583, translation error = 3.601, rotation error = 3.827, time/batch = 0.010\n",
      "4200/5583, translation error = 3.584, rotation error = 3.793, time/batch = 0.009\n",
      "4250/5583, translation error = 3.562, rotation error = 3.768, time/batch = 0.010\n",
      "4300/5583, translation error = 3.537, rotation error = 3.753, time/batch = 0.010\n",
      "4350/5583, translation error = 3.524, rotation error = 3.739, time/batch = 0.010\n",
      "4400/5583, translation error = 3.513, rotation error = 3.719, time/batch = 0.010\n",
      "4450/5583, translation error = 3.494, rotation error = 3.702, time/batch = 0.010\n",
      "4500/5583, translation error = 3.475, rotation error = 3.693, time/batch = 0.010\n",
      "4550/5583, translation error = 3.464, rotation error = 3.684, time/batch = 0.010\n",
      "4600/5583, translation error = 3.462, rotation error = 3.690, time/batch = 0.009\n",
      "4650/5583, translation error = 3.448, rotation error = 3.714, time/batch = 0.009\n",
      "4700/5583, translation error = 3.428, rotation error = 3.713, time/batch = 0.009\n",
      "4750/5583, translation error = 3.413, rotation error = 3.717, time/batch = 0.010\n",
      "4800/5583, translation error = 3.391, rotation error = 3.707, time/batch = 0.010\n",
      "4850/5583, translation error = 3.371, rotation error = 3.695, time/batch = 0.010\n",
      "4900/5583, translation error = 3.351, rotation error = 3.683, time/batch = 0.010\n",
      "4950/5583, translation error = 3.329, rotation error = 3.675, time/batch = 0.009\n",
      "5000/5583, translation error = 3.310, rotation error = 3.669, time/batch = 0.010\n",
      "5050/5583, translation error = 3.293, rotation error = 3.663, time/batch = 0.010\n",
      "5100/5583, translation error = 3.287, rotation error = 3.653, time/batch = 0.010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5150/5583, translation error = 3.280, rotation error = 3.638, time/batch = 0.009\n",
      "5200/5583, translation error = 3.266, rotation error = 3.633, time/batch = 0.010\n",
      "5250/5583, translation error = 3.260, rotation error = 3.627, time/batch = 0.009\n",
      "5300/5583, translation error = 3.248, rotation error = 3.609, time/batch = 0.009\n",
      "5350/5583, translation error = 3.234, rotation error = 3.594, time/batch = 0.010\n",
      "5400/5583, translation error = 3.229, rotation error = 3.576, time/batch = 0.010\n",
      "5450/5583, translation error = 3.214, rotation error = 3.559, time/batch = 0.009\n",
      "5500/5583, translation error = 3.214, rotation error = 3.559, time/batch = 0.010\n",
      "5550/5583, translation error = 3.220, rotation error = 3.558, time/batch = 0.009\n",
      "pred time nan\n",
      "time std nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/numpy/core/fromnumeric.py:3335: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:217: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  keepdims=keepdims)\n",
      "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:186: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean, rcount, out=arrmean, casting='unsafe', subok=False)\n",
      "/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py:209: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "def get_output(target_data_t1,global_output1,i=0):\n",
    "    trans_target, rot_target = torch.split(target_data_t1, [3, 4], dim=1)\n",
    "    global_output1_demormed = denormalize(global_output1, args.norm_mean, args.norm_std)\n",
    "    trans_prediction, rot_prediction = torch.split(global_output1_demormed, [3, 4], dim=1)\n",
    "    return trans_prediction, rot_prediction, trans_target, rot_target\n",
    "\n",
    "for b, data in enumerate(dataloader, 0):\n",
    "    start = time.time()\n",
    "    x,y = data.values()\n",
    "    x,y = x.to(device),y.to(device)\n",
    "    #y = normalize(y,args.norm_mean, args.norm_std)\n",
    "    \n",
    "    # Get single data & transform data type\n",
    "    with torch.no_grad():\n",
    "        global_output1 = model(x)\n",
    "    trans_pred, rot_pred, trans_gt, rot_gt = get_output(y,global_output1)\n",
    "    trans_pred = np.asarray(trans_pred.cpu())\n",
    "    rot_pred = np.asarray(rot_pred.cpu())\n",
    "    trans_gt = np.asarray(trans_gt.cpu())\n",
    "    rot_gt = np.asarray(rot_gt.cpu())\n",
    "    x = np.asarray(x.cpu())\n",
    "    \n",
    "    end = time.time()\n",
    "    \n",
    "    br.sendTransform((trans_pred[0][0], trans_pred[0][1], trans_pred[0][2]),\n",
    "                 (rot_pred[0][0], rot_pred[0][1], rot_pred[0][2], rot_pred[0][3]), rospy.Time.now(),\n",
    "                 \"estimation\", \"world\")\n",
    "    \n",
    "    [px_gt, py_gt, pz_gt] = [trans_gt[0][0], trans_gt[0][1], trans_gt[0][2]]\n",
    "    [qx_gt, qy_gt, qz_gt, qw_gt] = [rot_gt[0][0], rot_gt[0][1], rot_gt[0][2], rot_gt[0][3]]\n",
    "\n",
    "    br.sendTransform((px_gt, py_gt, pz_gt),\n",
    "                     (qx_gt, qy_gt, qz_gt, qw_gt),\n",
    "                     rospy.Time.now(), \"gt\", \"world\")\n",
    "\n",
    "    timestamp = rospy.Time.now()\n",
    "    \n",
    "    gt_msg = Odometry()\n",
    "    gt_msg.header.frame_id = 'world'\n",
    "    gt_msg.header.stamp = timestamp\n",
    "    gt_msg.child_frame_id = 'base_link'\n",
    "    gt_msg.pose.pose.position.x = px_gt\n",
    "    gt_msg.pose.pose.position.y = py_gt\n",
    "    gt_msg.pose.pose.position.z = pz_gt\n",
    "    [gt_msg.pose.pose.orientation.x, gt_msg.pose.pose.orientation.y, gt_msg.pose.pose.orientation.z, gt_msg.pose.pose.orientation.w] = [qx_gt, qy_gt, qz_gt, qw_gt]\n",
    "\n",
    "    bridge = CvBridge()\n",
    "\n",
    "    bird_view_img_msg = bridge.cv2_to_imgmsg(np.asarray(x[0], dtype=np.float32), encoding=\"passthrough\")\n",
    "    stamp_now = rospy.Time.now()\n",
    "    bird_view_img_msg.header.stamp = stamp_now\n",
    "\n",
    "    bird_view_pub.publish(bird_view_img_msg)\n",
    "\n",
    "    rospy.sleep(.1)\n",
    "\n",
    "    count += 1\n",
    "    \n",
    "    trans_preds.append(trans_pred[0])\n",
    "    rot_preds.append(rot_pred[0])\n",
    "    trans_gts.append(trans_gt[0])\n",
    "    rot_gts.append(rot_gt[0])\n",
    "\n",
    "    trans_error = np.sum((trans_pred[0] - trans_gt[0])**2)**0.5\n",
    "    rot_error_1 = np.arccos(np.dot(rot_pred[0], rot_gt[0]))/math.pi*180\n",
    "    rot_error_2 = np.arccos(np.dot(rot_pred[0], -rot_gt[0])) / math.pi * 180\n",
    "    rot_error = min(rot_error_1, rot_error_2)\n",
    "\n",
    "    trans_errors.append(trans_error)\n",
    "    rot_errors.append(rot_error)\n",
    "\n",
    "    total_trans_error += trans_error\n",
    "    total_rot_error += rot_error\n",
    "\n",
    "    display = 50\n",
    "\n",
    "    if b % display == 0 and b > 0:\n",
    "        print(\n",
    "            \"{}/{}, translation error = {:.3f}, rotation error = {:.3f}, time/batch = {:.3f}\"\n",
    "            .format(\n",
    "             b,\n",
    "            len(dataloader),\n",
    "            total_trans_error / count,\n",
    "            total_rot_error / count,\n",
    "            end - start))\n",
    "\n",
    "print(\"pred time\", np.mean(np.array(pred_time)))\n",
    "print(\"time std\", np.std(np.array(pred_time)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-28T11:28:49.330516Z",
     "start_time": "2020-06-28T11:28:48.318414Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "median translation error = 2.472\n",
      "median rotation error = 2.535\n",
      "mean translation error = 3.225\n",
      "mean rotation error = 3.547\n"
     ]
    }
   ],
   "source": [
    "import scipy.io as sio\n",
    "\n",
    "sio.savemat('results.mat', {'trans_pred': np.array(trans_preds), 'trans_gt': np.array(trans_gts), 'uncertainty': np.array(pred_uncertainties)})\n",
    "\n",
    "if len(pose_map):\n",
    "    np.savetxt(os.path.join(args.map_dataset, 'map.txt'), np.asarray(pose_map, dtype=np.float32))\n",
    "    print(\"map is saved!\")\n",
    "\n",
    "plt.hist(trans_errors, bins='auto')\n",
    "plt.title(\"Translation errors\")\n",
    "plt.xlabel(\"translational error in meters\")\n",
    "plt.ylabel(\"number of frames\")\n",
    "plt.savefig('terror.png', bbox_inches='tight')\n",
    "\n",
    "plt.hist(rot_errors, bins='auto')\n",
    "plt.title(\"Rotation errors\")\n",
    "plt.xlabel(\"rotational error in degree\")\n",
    "plt.ylabel(\"number of frames\")\n",
    "plt.savefig('rerror.png', bbox_inches='tight')\n",
    "\n",
    "median_trans_errors = np.median(trans_errors)\n",
    "median_rot_errors = np.median(rot_errors)\n",
    "mean_trans_errors = np.mean(trans_errors)\n",
    "mean_rot_errors = np.mean(rot_errors)\n",
    "\n",
    "print(\"median translation error = {:.3f}\".format(median_trans_errors))\n",
    "print(\"median rotation error = {:.3f}\".format(median_rot_errors))\n",
    "print(\"mean translation error = {:.3f}\".format(mean_trans_errors))\n",
    "print(\"mean rotation error = {:.3f}\".format(mean_rot_errors))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
